{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "심리_성향_예측(모델).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OVuGljJpseY6OCpkK7rsHu2PDyvYJtDG",
      "authorship_tag": "ABX9TyOn6UCQNhsQjRyqGSPrrn/K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yunjeong-chang/My_Data_project/blob/main/%EB%8D%B0%EC%9D%B4%EC%BD%98/%EC%8B%AC%EB%A6%AC%20%EC%84%B1%ED%96%A5%20%EC%98%88%EC%B8%A1(%EB%AA%A8%EB%8D%B8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRGj4O-4NbsG"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# 전처리 완료된 데이터 불러오기 \n",
        "final_train_x = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/심리_성향_예측_Data/심리 성향 예측_final_train_x.csv')\n",
        "final_train_y = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/심리_성향_예측_Data/심리 성향 예측_final_train_y.csv')\n",
        "final_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/심리_성향_예측_Data/심리 성향 예측_final_test.csv')\n",
        "sample_submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/심리_성향_예측_Data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es8WPjv4gLVT",
        "outputId": "e7fad0e2-38e2-4eea-b96e-6a928ded5c24"
      },
      "source": [
        "print(final_train_x.shape)\n",
        "print(final_train_y.shape)\n",
        "print(final_test.shape)\n",
        "print(sample_submission.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45532, 77)\n",
            "(45532, 1)\n",
            "(11383, 77)\n",
            "(11383, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojNewTsB48Ol"
      },
      "source": [
        "### **1. 간단한 LGBM 모델**\n",
        "\n",
        "public(0.5788903241) \n",
        "\n",
        "private(0.5750718696)\n",
        "\n",
        "참고 : [코드 공유](https://dacon.io/competitions/official/235647/codeshare/1700?page=1&dtype=recent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n_KRmINdoqV"
      },
      "source": [
        "먼저 베이스라인 코드로 제시된 글에서 쓰인 모델을 써봤습니다.\n",
        "\n",
        "**Light GBM**은 Tree가 수직적으로 확장(leaf-wise)되는 반면에, 다른 알고리즘은 Tree가 수평적으로 확장(level-wise)됩니다. \n",
        "\n",
        "즉, 동일한 leaf를 확장할 때 Light GBM은 더 많은 손실(loss)을 줄일 수 있습니다.\n",
        "\n",
        "- 장점 : 큰 사이즈의 데이터를 다룰 때 속도가 빠르고, 실행 시 적은 메모리를 차지합니다.\n",
        "\n",
        "- 단점 : 과적합에 민감하여 작은 사이즈의 데이터에는 적합하지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw1lObFLgyzq",
        "outputId": "e62fa1ac-7d20-40bb-c3b5-bdf6d58509c0"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier(n_estimators=500) # n_estimators는 너무 커지면 과적합이 발생합니다. 우선은 다른 파라미터는 건드리지 않았습니다.\n",
        "model.fit(final_train_x, final_train_y)  # 모델 학습\n",
        "final_pred = model.predict(final_test)   # 예측\n",
        "sample_submission['voted']=final_pred    # 저장\n",
        "sample_submission.to_csv('test_submit_LGBM_basic.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mH3aAeF5fyF"
      },
      "source": [
        "### **2. NN 모델**\n",
        "\n",
        "제출 횟수 제한 때문에 다양한 파라미터 실험은 못해봤지만, 비교적 성능이 안좋아서 제외 시켰습니다.\n",
        "\n",
        "하지만 코드 공유에서 대다수를 차지하는 보편적인 모델입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgvVVdy95sE6"
      },
      "source": [
        "### **3. CAT+LGBM+XGB 앙상블 모델**\n",
        "\n",
        "public(0.5890179708)\n",
        "\n",
        "private(0.5922709518)\n",
        "\n",
        "생각보다는 좋지 않았지만 그래도 private에서 점수가 더 높아지는 것을 보니 앙상블 한 것이 효과를 본 것 같다.\n",
        "\n",
        "참고 : [코드 공유](https://dacon.io/competitions/official/235647/codeshare/1821?page=1&dtype=recent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsaFvVgOgpNS"
      },
      "source": [
        "코드 공유 중에 부스팅 계열의 세가지 모델을 앙상블 한 것이 있어서 사용해 봤습니다.\n",
        "\n",
        "**XGBoost Classifier + Light GBM Classifier + CatBoostClassifier**\n",
        "\n",
        "- XGBoost Classifier는 분류 정확도는 우수하나, Outlier에 취약합니다. 과적합 방지 기능을 하는 규제가 포함 되어 있습니다.\n",
        "\n",
        "- Light GBM Classifier는 위의 베이스라인 코드에서 사용한 모델입니다.\n",
        "\n",
        "- CatBoostClassifier는 기본 파라미터 최적화가 잘 되어있어 두 모델에 비해서는 복잡한 하이퍼 파라미터 튜닝을 필요로 하지는 않습니다. 학습 데이터에 대한 샘플링을 통해 모델을 만들고, 샘플링이 되지 않은 데이터의 잔차를 추정하면서 학습 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByCj1W7YVzv2"
      },
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import xgboost\n",
        "from xgboost import plot_importance\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upEH6VfLTaYD",
        "outputId": "025e04de-01af-4d3f-b727-49285ae826e0"
      },
      "source": [
        "# 모델에 넣을 하이퍼파라미터를 미리 설정해줍니다. \n",
        "params =  {'colsample_bylevel': 0.92859, 'colsample_bytree': 0.55352, 'eta': 0.015, 'gamma': 0.62587, 'min_child_weight': 48.0, 'reg_alpha': 0.54, 'reg_lambda': 1.062, 'subsample': 0.89}  \n",
        "params['min_child_weight'] = int(params['min_child_weight'])\n",
        "\n",
        "model = XGBClassifier(\n",
        "             **params,\n",
        "             max_depth=11,\n",
        "             booster='gbtree',\n",
        "             n_estimators=5000,\n",
        "             objective= 'binary:logistic',\n",
        "             eval_metric='auc',\n",
        "             n_jobs= -1,\n",
        "             scale_pos_weight= 1.206,\n",
        "             random_state= 55 \n",
        ")\n",
        "\n",
        "# XGBoost 분류 모델로 학습 및 예측\n",
        "model.fit(final_train_x, final_train_y)\n",
        "XGBC_final_pred = model.predict(final_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLlCB3vBS0D4",
        "outputId": "dbb91b01-2483-4242-ad1a-fa547a52ec09"
      },
      "source": [
        "# 모델에 넣을 하이퍼파라미터를 미리 설정해줍니다. \n",
        "params = {'colsample_bytree': 0.675479, 'learning_rate': 0.00645, 'max_depth': 10.3, 'min_child_samples': 88.41, 'min_child_weight': 28.4, 'min_split_gain': 0.025029, 'num_leaves': 86.2, 'reg_alpha': 0.544736, 'reg_lambda': 0.15015, 'subsample': 0.7295}\n",
        "\n",
        "params['num_leaves'] = int(params['num_leaves'])\n",
        "params['max_depth'] = int(params['max_depth'])\n",
        "params['min_child_samples'] = int(params['min_child_samples'])\n",
        "\n",
        "model = LGBMClassifier(\n",
        "        **params,\n",
        "        objective= 'binary',\n",
        "        subsample_for_bin= 240000,\n",
        "        is_unbalance= False,\n",
        "        n_estimators=10000,\n",
        "        n_jobs=-1,\n",
        "        silent= -1,\n",
        "        verbose= -1,\n",
        "        random_state=55     \n",
        ")\n",
        "\n",
        "# LGBM 분류 모델로 학습 및 예측\n",
        "model.fit(final_train_x, final_train_y)\n",
        "LGBM_final_pred = model.predict(final_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfEDtKYTT3E8",
        "outputId": "8aa1df11-7c63-4d38-d0fd-26508642cdb6"
      },
      "source": [
        "# 모델에 넣을 하이퍼파라미터를 미리 설정해줍니다. \n",
        "params = {'bagging_temperature': 0.375906, 'depth': 9.0, 'l2_leaf_reg': 68.8, 'learning_rate': 0.011, 'od_wait': 138.699, 'subsample': 0.76046}\n",
        "\n",
        "params['depth'] = int(params['depth'])\n",
        "params['l2_leaf_reg'] = int(params['l2_leaf_reg'])\n",
        "params['od_wait'] = int(params['od_wait'])\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "                          **params,\n",
        "                          iterations=5000,\n",
        "                          eval_metric='AUC',\n",
        "                          allow_writing_files=False,\n",
        "                          od_type='Iter',\n",
        "                          random_state=55)\n",
        "\n",
        "# CatBoost 분류 모델로 학습 및 예측\n",
        "model.fit(final_train_x, final_train_y)\n",
        "CatBoost_final_pred = model.predict(final_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "0:\ttotal: 174ms\tremaining: 14m 28s\n",
            "1:\ttotal: 259ms\tremaining: 10m 47s\n",
            "2:\ttotal: 342ms\tremaining: 9m 29s\n",
            "3:\ttotal: 425ms\tremaining: 8m 51s\n",
            "4:\ttotal: 510ms\tremaining: 8m 29s\n",
            "5:\ttotal: 596ms\tremaining: 8m 15s\n",
            "6:\ttotal: 680ms\tremaining: 8m 5s\n",
            "7:\ttotal: 765ms\tremaining: 7m 57s\n",
            "8:\ttotal: 855ms\tremaining: 7m 54s\n",
            "9:\ttotal: 946ms\tremaining: 7m 51s\n",
            "10:\ttotal: 1.03s\tremaining: 7m 46s\n",
            "11:\ttotal: 1.11s\tremaining: 7m 40s\n",
            "12:\ttotal: 1.2s\tremaining: 7m 41s\n",
            "13:\ttotal: 1.29s\tremaining: 7m 38s\n",
            "14:\ttotal: 1.37s\tremaining: 7m 35s\n",
            "15:\ttotal: 1.46s\tremaining: 7m 34s\n",
            "16:\ttotal: 1.54s\tremaining: 7m 32s\n",
            "17:\ttotal: 1.63s\tremaining: 7m 29s\n",
            "18:\ttotal: 1.71s\tremaining: 7m 28s\n",
            "19:\ttotal: 1.79s\tremaining: 7m 27s\n",
            "20:\ttotal: 1.87s\tremaining: 7m 24s\n",
            "21:\ttotal: 1.96s\tremaining: 7m 23s\n",
            "22:\ttotal: 2.04s\tremaining: 7m 21s\n",
            "23:\ttotal: 2.12s\tremaining: 7m 19s\n",
            "24:\ttotal: 2.21s\tremaining: 7m 19s\n",
            "25:\ttotal: 2.29s\tremaining: 7m 18s\n",
            "26:\ttotal: 2.37s\tremaining: 7m 17s\n",
            "27:\ttotal: 2.47s\tremaining: 7m 17s\n",
            "28:\ttotal: 2.55s\tremaining: 7m 17s\n",
            "29:\ttotal: 2.63s\tremaining: 7m 16s\n",
            "30:\ttotal: 2.72s\tremaining: 7m 15s\n",
            "31:\ttotal: 2.8s\tremaining: 7m 14s\n",
            "32:\ttotal: 2.88s\tremaining: 7m 14s\n",
            "33:\ttotal: 2.98s\tremaining: 7m 14s\n",
            "34:\ttotal: 3.06s\tremaining: 7m 14s\n",
            "35:\ttotal: 3.15s\tremaining: 7m 13s\n",
            "36:\ttotal: 3.24s\tremaining: 7m 14s\n",
            "37:\ttotal: 3.32s\tremaining: 7m 13s\n",
            "38:\ttotal: 3.4s\tremaining: 7m 12s\n",
            "39:\ttotal: 3.49s\tremaining: 7m 12s\n",
            "40:\ttotal: 3.58s\tremaining: 7m 12s\n",
            "41:\ttotal: 3.66s\tremaining: 7m 12s\n",
            "42:\ttotal: 3.75s\tremaining: 7m 12s\n",
            "43:\ttotal: 3.84s\tremaining: 7m 12s\n",
            "44:\ttotal: 3.92s\tremaining: 7m 12s\n",
            "45:\ttotal: 4.01s\tremaining: 7m 11s\n",
            "46:\ttotal: 4.09s\tremaining: 7m 11s\n",
            "47:\ttotal: 4.17s\tremaining: 7m 10s\n",
            "48:\ttotal: 4.26s\tremaining: 7m 10s\n",
            "49:\ttotal: 4.34s\tremaining: 7m 10s\n",
            "50:\ttotal: 4.43s\tremaining: 7m 9s\n",
            "51:\ttotal: 4.52s\tremaining: 7m 9s\n",
            "52:\ttotal: 4.6s\tremaining: 7m 9s\n",
            "53:\ttotal: 4.68s\tremaining: 7m 9s\n",
            "54:\ttotal: 4.77s\tremaining: 7m 9s\n",
            "55:\ttotal: 4.86s\tremaining: 7m 9s\n",
            "56:\ttotal: 4.95s\tremaining: 7m 9s\n",
            "57:\ttotal: 5.03s\tremaining: 7m 8s\n",
            "58:\ttotal: 5.11s\tremaining: 7m 8s\n",
            "59:\ttotal: 5.2s\tremaining: 7m 7s\n",
            "60:\ttotal: 5.29s\tremaining: 7m 8s\n",
            "61:\ttotal: 5.38s\tremaining: 7m 8s\n",
            "62:\ttotal: 5.47s\tremaining: 7m 8s\n",
            "63:\ttotal: 5.54s\tremaining: 7m 7s\n",
            "64:\ttotal: 5.59s\tremaining: 7m 4s\n",
            "65:\ttotal: 5.68s\tremaining: 7m 4s\n",
            "66:\ttotal: 5.77s\tremaining: 7m 4s\n",
            "67:\ttotal: 5.85s\tremaining: 7m 4s\n",
            "68:\ttotal: 5.93s\tremaining: 7m 3s\n",
            "69:\ttotal: 6.02s\tremaining: 7m 4s\n",
            "70:\ttotal: 6.11s\tremaining: 7m 4s\n",
            "71:\ttotal: 6.2s\tremaining: 7m 4s\n",
            "72:\ttotal: 6.29s\tremaining: 7m 4s\n",
            "73:\ttotal: 6.37s\tremaining: 7m 3s\n",
            "74:\ttotal: 6.45s\tremaining: 7m 3s\n",
            "75:\ttotal: 6.54s\tremaining: 7m 3s\n",
            "76:\ttotal: 6.62s\tremaining: 7m 3s\n",
            "77:\ttotal: 6.7s\tremaining: 7m 2s\n",
            "78:\ttotal: 6.79s\tremaining: 7m 2s\n",
            "79:\ttotal: 6.87s\tremaining: 7m 2s\n",
            "80:\ttotal: 6.96s\tremaining: 7m 2s\n",
            "81:\ttotal: 7.04s\tremaining: 7m 2s\n",
            "82:\ttotal: 7.13s\tremaining: 7m 2s\n",
            "83:\ttotal: 7.21s\tremaining: 7m 1s\n",
            "84:\ttotal: 7.3s\tremaining: 7m 2s\n",
            "85:\ttotal: 7.39s\tremaining: 7m 2s\n",
            "86:\ttotal: 7.47s\tremaining: 7m 2s\n",
            "87:\ttotal: 7.56s\tremaining: 7m 1s\n",
            "88:\ttotal: 7.64s\tremaining: 7m 1s\n",
            "89:\ttotal: 7.72s\tremaining: 7m 1s\n",
            "90:\ttotal: 7.8s\tremaining: 7m 1s\n",
            "91:\ttotal: 7.9s\tremaining: 7m 1s\n",
            "92:\ttotal: 7.98s\tremaining: 7m 1s\n",
            "93:\ttotal: 8.06s\tremaining: 7m\n",
            "94:\ttotal: 8.15s\tremaining: 7m\n",
            "95:\ttotal: 8.23s\tremaining: 7m\n",
            "96:\ttotal: 8.32s\tremaining: 7m\n",
            "97:\ttotal: 8.4s\tremaining: 7m\n",
            "98:\ttotal: 8.49s\tremaining: 7m\n",
            "99:\ttotal: 8.58s\tremaining: 7m\n",
            "100:\ttotal: 8.66s\tremaining: 7m\n",
            "101:\ttotal: 8.75s\tremaining: 7m\n",
            "102:\ttotal: 8.83s\tremaining: 6m 59s\n",
            "103:\ttotal: 8.92s\tremaining: 6m 59s\n",
            "104:\ttotal: 9.01s\tremaining: 6m 59s\n",
            "105:\ttotal: 9.09s\tremaining: 6m 59s\n",
            "106:\ttotal: 9.17s\tremaining: 6m 59s\n",
            "107:\ttotal: 9.25s\tremaining: 6m 59s\n",
            "108:\ttotal: 9.35s\tremaining: 6m 59s\n",
            "109:\ttotal: 9.43s\tremaining: 6m 59s\n",
            "110:\ttotal: 9.52s\tremaining: 6m 59s\n",
            "111:\ttotal: 9.6s\tremaining: 6m 59s\n",
            "112:\ttotal: 9.69s\tremaining: 6m 59s\n",
            "113:\ttotal: 9.78s\tremaining: 6m 59s\n",
            "114:\ttotal: 9.86s\tremaining: 6m 59s\n",
            "115:\ttotal: 9.95s\tremaining: 6m 58s\n",
            "116:\ttotal: 10s\tremaining: 6m 58s\n",
            "117:\ttotal: 10.1s\tremaining: 6m 58s\n",
            "118:\ttotal: 10.2s\tremaining: 6m 58s\n",
            "119:\ttotal: 10.3s\tremaining: 6m 58s\n",
            "120:\ttotal: 10.4s\tremaining: 6m 58s\n",
            "121:\ttotal: 10.5s\tremaining: 6m 58s\n",
            "122:\ttotal: 10.6s\tremaining: 6m 58s\n",
            "123:\ttotal: 10.6s\tremaining: 6m 58s\n",
            "124:\ttotal: 10.7s\tremaining: 6m 57s\n",
            "125:\ttotal: 10.8s\tremaining: 6m 57s\n",
            "126:\ttotal: 10.9s\tremaining: 6m 57s\n",
            "127:\ttotal: 11s\tremaining: 6m 57s\n",
            "128:\ttotal: 11.1s\tremaining: 6m 57s\n",
            "129:\ttotal: 11.1s\tremaining: 6m 57s\n",
            "130:\ttotal: 11.2s\tremaining: 6m 56s\n",
            "131:\ttotal: 11.3s\tremaining: 6m 56s\n",
            "132:\ttotal: 11.4s\tremaining: 6m 57s\n",
            "133:\ttotal: 11.5s\tremaining: 6m 57s\n",
            "134:\ttotal: 11.6s\tremaining: 6m 56s\n",
            "135:\ttotal: 11.6s\tremaining: 6m 56s\n",
            "136:\ttotal: 11.7s\tremaining: 6m 56s\n",
            "137:\ttotal: 11.8s\tremaining: 6m 56s\n",
            "138:\ttotal: 11.9s\tremaining: 6m 56s\n",
            "139:\ttotal: 12s\tremaining: 6m 56s\n",
            "140:\ttotal: 12.1s\tremaining: 6m 56s\n",
            "141:\ttotal: 12.2s\tremaining: 6m 56s\n",
            "142:\ttotal: 12.2s\tremaining: 6m 56s\n",
            "143:\ttotal: 12.3s\tremaining: 6m 55s\n",
            "144:\ttotal: 12.4s\tremaining: 6m 56s\n",
            "145:\ttotal: 12.5s\tremaining: 6m 56s\n",
            "146:\ttotal: 12.6s\tremaining: 6m 56s\n",
            "147:\ttotal: 12.7s\tremaining: 6m 56s\n",
            "148:\ttotal: 12.8s\tremaining: 6m 56s\n",
            "149:\ttotal: 12.9s\tremaining: 6m 55s\n",
            "150:\ttotal: 12.9s\tremaining: 6m 55s\n",
            "151:\ttotal: 13s\tremaining: 6m 55s\n",
            "152:\ttotal: 13.1s\tremaining: 6m 55s\n",
            "153:\ttotal: 13.2s\tremaining: 6m 55s\n",
            "154:\ttotal: 13.3s\tremaining: 6m 55s\n",
            "155:\ttotal: 13.4s\tremaining: 6m 54s\n",
            "156:\ttotal: 13.5s\tremaining: 6m 55s\n",
            "157:\ttotal: 13.5s\tremaining: 6m 54s\n",
            "158:\ttotal: 13.6s\tremaining: 6m 54s\n",
            "159:\ttotal: 13.7s\tremaining: 6m 54s\n",
            "160:\ttotal: 13.8s\tremaining: 6m 54s\n",
            "161:\ttotal: 13.9s\tremaining: 6m 54s\n",
            "162:\ttotal: 14s\tremaining: 6m 54s\n",
            "163:\ttotal: 14s\tremaining: 6m 54s\n",
            "164:\ttotal: 14.1s\tremaining: 6m 54s\n",
            "165:\ttotal: 14.2s\tremaining: 6m 54s\n",
            "166:\ttotal: 14.3s\tremaining: 6m 54s\n",
            "167:\ttotal: 14.4s\tremaining: 6m 53s\n",
            "168:\ttotal: 14.5s\tremaining: 6m 54s\n",
            "169:\ttotal: 14.6s\tremaining: 6m 53s\n",
            "170:\ttotal: 14.6s\tremaining: 6m 53s\n",
            "171:\ttotal: 14.7s\tremaining: 6m 53s\n",
            "172:\ttotal: 14.8s\tremaining: 6m 54s\n",
            "173:\ttotal: 14.9s\tremaining: 6m 54s\n",
            "174:\ttotal: 15s\tremaining: 6m 54s\n",
            "175:\ttotal: 15.1s\tremaining: 6m 54s\n",
            "176:\ttotal: 15.2s\tremaining: 6m 53s\n",
            "177:\ttotal: 15.3s\tremaining: 6m 53s\n",
            "178:\ttotal: 15.4s\tremaining: 6m 53s\n",
            "179:\ttotal: 15.5s\tremaining: 6m 53s\n",
            "180:\ttotal: 15.5s\tremaining: 6m 53s\n",
            "181:\ttotal: 15.6s\tremaining: 6m 53s\n",
            "182:\ttotal: 15.7s\tremaining: 6m 53s\n",
            "183:\ttotal: 15.8s\tremaining: 6m 53s\n",
            "184:\ttotal: 15.9s\tremaining: 6m 53s\n",
            "185:\ttotal: 16s\tremaining: 6m 53s\n",
            "186:\ttotal: 16.1s\tremaining: 6m 53s\n",
            "187:\ttotal: 16.1s\tremaining: 6m 53s\n",
            "188:\ttotal: 16.2s\tremaining: 6m 53s\n",
            "189:\ttotal: 16.3s\tremaining: 6m 52s\n",
            "190:\ttotal: 16.4s\tremaining: 6m 52s\n",
            "191:\ttotal: 16.5s\tremaining: 6m 52s\n",
            "192:\ttotal: 16.6s\tremaining: 6m 52s\n",
            "193:\ttotal: 16.7s\tremaining: 6m 52s\n",
            "194:\ttotal: 16.7s\tremaining: 6m 52s\n",
            "195:\ttotal: 16.8s\tremaining: 6m 52s\n",
            "196:\ttotal: 16.9s\tremaining: 6m 52s\n",
            "197:\ttotal: 17s\tremaining: 6m 52s\n",
            "198:\ttotal: 17.1s\tremaining: 6m 52s\n",
            "199:\ttotal: 17.2s\tremaining: 6m 52s\n",
            "200:\ttotal: 17.3s\tremaining: 6m 51s\n",
            "201:\ttotal: 17.3s\tremaining: 6m 51s\n",
            "202:\ttotal: 17.4s\tremaining: 6m 51s\n",
            "203:\ttotal: 17.5s\tremaining: 6m 51s\n",
            "204:\ttotal: 17.6s\tremaining: 6m 51s\n",
            "205:\ttotal: 17.7s\tremaining: 6m 51s\n",
            "206:\ttotal: 17.8s\tremaining: 6m 51s\n",
            "207:\ttotal: 17.9s\tremaining: 6m 51s\n",
            "208:\ttotal: 17.9s\tremaining: 6m 51s\n",
            "209:\ttotal: 18s\tremaining: 6m 51s\n",
            "210:\ttotal: 18.1s\tremaining: 6m 51s\n",
            "211:\ttotal: 18.2s\tremaining: 6m 51s\n",
            "212:\ttotal: 18.3s\tremaining: 6m 50s\n",
            "213:\ttotal: 18.4s\tremaining: 6m 50s\n",
            "214:\ttotal: 18.5s\tremaining: 6m 50s\n",
            "215:\ttotal: 18.6s\tremaining: 6m 50s\n",
            "216:\ttotal: 18.6s\tremaining: 6m 50s\n",
            "217:\ttotal: 18.7s\tremaining: 6m 50s\n",
            "218:\ttotal: 18.8s\tremaining: 6m 50s\n",
            "219:\ttotal: 18.9s\tremaining: 6m 50s\n",
            "220:\ttotal: 19s\tremaining: 6m 50s\n",
            "221:\ttotal: 19.1s\tremaining: 6m 50s\n",
            "222:\ttotal: 19.1s\tremaining: 6m 50s\n",
            "223:\ttotal: 19.2s\tremaining: 6m 49s\n",
            "224:\ttotal: 19.3s\tremaining: 6m 49s\n",
            "225:\ttotal: 19.4s\tremaining: 6m 49s\n",
            "226:\ttotal: 19.5s\tremaining: 6m 49s\n",
            "227:\ttotal: 19.6s\tremaining: 6m 49s\n",
            "228:\ttotal: 19.7s\tremaining: 6m 49s\n",
            "229:\ttotal: 19.8s\tremaining: 6m 49s\n",
            "230:\ttotal: 19.8s\tremaining: 6m 49s\n",
            "231:\ttotal: 19.9s\tremaining: 6m 49s\n",
            "232:\ttotal: 20s\tremaining: 6m 49s\n",
            "233:\ttotal: 20.1s\tremaining: 6m 49s\n",
            "234:\ttotal: 20.2s\tremaining: 6m 49s\n",
            "235:\ttotal: 20.3s\tremaining: 6m 48s\n",
            "236:\ttotal: 20.3s\tremaining: 6m 48s\n",
            "237:\ttotal: 20.4s\tremaining: 6m 48s\n",
            "238:\ttotal: 20.5s\tremaining: 6m 48s\n",
            "239:\ttotal: 20.6s\tremaining: 6m 48s\n",
            "240:\ttotal: 20.7s\tremaining: 6m 48s\n",
            "241:\ttotal: 20.8s\tremaining: 6m 48s\n",
            "242:\ttotal: 20.9s\tremaining: 6m 48s\n",
            "243:\ttotal: 20.9s\tremaining: 6m 48s\n",
            "244:\ttotal: 21s\tremaining: 6m 48s\n",
            "245:\ttotal: 21.1s\tremaining: 6m 48s\n",
            "246:\ttotal: 21.2s\tremaining: 6m 48s\n",
            "247:\ttotal: 21.3s\tremaining: 6m 47s\n",
            "248:\ttotal: 21.4s\tremaining: 6m 47s\n",
            "249:\ttotal: 21.5s\tremaining: 6m 47s\n",
            "250:\ttotal: 21.5s\tremaining: 6m 47s\n",
            "251:\ttotal: 21.6s\tremaining: 6m 47s\n",
            "252:\ttotal: 21.7s\tremaining: 6m 47s\n",
            "253:\ttotal: 21.8s\tremaining: 6m 47s\n",
            "254:\ttotal: 21.9s\tremaining: 6m 47s\n",
            "255:\ttotal: 22s\tremaining: 6m 47s\n",
            "256:\ttotal: 22.1s\tremaining: 6m 47s\n",
            "257:\ttotal: 22.1s\tremaining: 6m 46s\n",
            "258:\ttotal: 22.2s\tremaining: 6m 46s\n",
            "259:\ttotal: 22.3s\tremaining: 6m 46s\n",
            "260:\ttotal: 22.4s\tremaining: 6m 46s\n",
            "261:\ttotal: 22.5s\tremaining: 6m 46s\n",
            "262:\ttotal: 22.6s\tremaining: 6m 46s\n",
            "263:\ttotal: 22.7s\tremaining: 6m 46s\n",
            "264:\ttotal: 22.7s\tremaining: 6m 46s\n",
            "265:\ttotal: 22.8s\tremaining: 6m 46s\n",
            "266:\ttotal: 22.9s\tremaining: 6m 46s\n",
            "267:\ttotal: 23s\tremaining: 6m 46s\n",
            "268:\ttotal: 23.1s\tremaining: 6m 45s\n",
            "269:\ttotal: 23.2s\tremaining: 6m 45s\n",
            "270:\ttotal: 23.2s\tremaining: 6m 45s\n",
            "271:\ttotal: 23.3s\tremaining: 6m 45s\n",
            "272:\ttotal: 23.4s\tremaining: 6m 45s\n",
            "273:\ttotal: 23.5s\tremaining: 6m 45s\n",
            "274:\ttotal: 23.6s\tremaining: 6m 45s\n",
            "275:\ttotal: 23.7s\tremaining: 6m 45s\n",
            "276:\ttotal: 23.8s\tremaining: 6m 45s\n",
            "277:\ttotal: 23.8s\tremaining: 6m 45s\n",
            "278:\ttotal: 23.9s\tremaining: 6m 44s\n",
            "279:\ttotal: 24s\tremaining: 6m 44s\n",
            "280:\ttotal: 24.1s\tremaining: 6m 44s\n",
            "281:\ttotal: 24.2s\tremaining: 6m 44s\n",
            "282:\ttotal: 24.3s\tremaining: 6m 44s\n",
            "283:\ttotal: 24.4s\tremaining: 6m 44s\n",
            "284:\ttotal: 24.4s\tremaining: 6m 44s\n",
            "285:\ttotal: 24.5s\tremaining: 6m 44s\n",
            "286:\ttotal: 24.6s\tremaining: 6m 44s\n",
            "287:\ttotal: 24.7s\tremaining: 6m 44s\n",
            "288:\ttotal: 24.8s\tremaining: 6m 44s\n",
            "289:\ttotal: 24.9s\tremaining: 6m 44s\n",
            "290:\ttotal: 25s\tremaining: 6m 44s\n",
            "291:\ttotal: 25.1s\tremaining: 6m 43s\n",
            "292:\ttotal: 25.1s\tremaining: 6m 43s\n",
            "293:\ttotal: 25.2s\tremaining: 6m 43s\n",
            "294:\ttotal: 25.3s\tremaining: 6m 43s\n",
            "295:\ttotal: 25.4s\tremaining: 6m 43s\n",
            "296:\ttotal: 25.5s\tremaining: 6m 43s\n",
            "297:\ttotal: 25.6s\tremaining: 6m 43s\n",
            "298:\ttotal: 25.7s\tremaining: 6m 43s\n",
            "299:\ttotal: 25.8s\tremaining: 6m 43s\n",
            "300:\ttotal: 25.8s\tremaining: 6m 43s\n",
            "301:\ttotal: 25.9s\tremaining: 6m 43s\n",
            "302:\ttotal: 26s\tremaining: 6m 43s\n",
            "303:\ttotal: 26.1s\tremaining: 6m 43s\n",
            "304:\ttotal: 26.2s\tremaining: 6m 43s\n",
            "305:\ttotal: 26.3s\tremaining: 6m 42s\n",
            "306:\ttotal: 26.4s\tremaining: 6m 42s\n",
            "307:\ttotal: 26.5s\tremaining: 6m 42s\n",
            "308:\ttotal: 26.5s\tremaining: 6m 42s\n",
            "309:\ttotal: 26.6s\tremaining: 6m 42s\n",
            "310:\ttotal: 26.7s\tremaining: 6m 42s\n",
            "311:\ttotal: 26.8s\tremaining: 6m 42s\n",
            "312:\ttotal: 26.9s\tremaining: 6m 42s\n",
            "313:\ttotal: 27s\tremaining: 6m 42s\n",
            "314:\ttotal: 27s\tremaining: 6m 42s\n",
            "315:\ttotal: 27.1s\tremaining: 6m 42s\n",
            "316:\ttotal: 27.2s\tremaining: 6m 42s\n",
            "317:\ttotal: 27.3s\tremaining: 6m 41s\n",
            "318:\ttotal: 27.4s\tremaining: 6m 41s\n",
            "319:\ttotal: 27.5s\tremaining: 6m 41s\n",
            "320:\ttotal: 27.6s\tremaining: 6m 41s\n",
            "321:\ttotal: 27.7s\tremaining: 6m 41s\n",
            "322:\ttotal: 27.8s\tremaining: 6m 41s\n",
            "323:\ttotal: 27.8s\tremaining: 6m 41s\n",
            "324:\ttotal: 27.9s\tremaining: 6m 41s\n",
            "325:\ttotal: 28s\tremaining: 6m 41s\n",
            "326:\ttotal: 28.1s\tremaining: 6m 41s\n",
            "327:\ttotal: 28.2s\tremaining: 6m 41s\n",
            "328:\ttotal: 28.3s\tremaining: 6m 41s\n",
            "329:\ttotal: 28.3s\tremaining: 6m 41s\n",
            "330:\ttotal: 28.4s\tremaining: 6m 41s\n",
            "331:\ttotal: 28.5s\tremaining: 6m 40s\n",
            "332:\ttotal: 28.6s\tremaining: 6m 40s\n",
            "333:\ttotal: 28.7s\tremaining: 6m 40s\n",
            "334:\ttotal: 28.8s\tremaining: 6m 40s\n",
            "335:\ttotal: 28.9s\tremaining: 6m 40s\n",
            "336:\ttotal: 28.9s\tremaining: 6m 40s\n",
            "337:\ttotal: 29s\tremaining: 6m 40s\n",
            "338:\ttotal: 29.1s\tremaining: 6m 40s\n",
            "339:\ttotal: 29.2s\tremaining: 6m 40s\n",
            "340:\ttotal: 29.3s\tremaining: 6m 40s\n",
            "341:\ttotal: 29.4s\tremaining: 6m 40s\n",
            "342:\ttotal: 29.5s\tremaining: 6m 39s\n",
            "343:\ttotal: 29.5s\tremaining: 6m 39s\n",
            "344:\ttotal: 29.6s\tremaining: 6m 39s\n",
            "345:\ttotal: 29.7s\tremaining: 6m 39s\n",
            "346:\ttotal: 29.8s\tremaining: 6m 39s\n",
            "347:\ttotal: 29.9s\tremaining: 6m 39s\n",
            "348:\ttotal: 30s\tremaining: 6m 39s\n",
            "349:\ttotal: 30.1s\tremaining: 6m 39s\n",
            "350:\ttotal: 30.1s\tremaining: 6m 39s\n",
            "351:\ttotal: 30.2s\tremaining: 6m 39s\n",
            "352:\ttotal: 30.3s\tremaining: 6m 38s\n",
            "353:\ttotal: 30.4s\tremaining: 6m 38s\n",
            "354:\ttotal: 30.5s\tremaining: 6m 38s\n",
            "355:\ttotal: 30.6s\tremaining: 6m 38s\n",
            "356:\ttotal: 30.6s\tremaining: 6m 38s\n",
            "357:\ttotal: 30.7s\tremaining: 6m 38s\n",
            "358:\ttotal: 30.8s\tremaining: 6m 38s\n",
            "359:\ttotal: 30.9s\tremaining: 6m 38s\n",
            "360:\ttotal: 31s\tremaining: 6m 38s\n",
            "361:\ttotal: 31.1s\tremaining: 6m 38s\n",
            "362:\ttotal: 31.2s\tremaining: 6m 38s\n",
            "363:\ttotal: 31.2s\tremaining: 6m 37s\n",
            "364:\ttotal: 31.3s\tremaining: 6m 37s\n",
            "365:\ttotal: 31.4s\tremaining: 6m 37s\n",
            "366:\ttotal: 31.5s\tremaining: 6m 37s\n",
            "367:\ttotal: 31.6s\tremaining: 6m 37s\n",
            "368:\ttotal: 31.7s\tremaining: 6m 37s\n",
            "369:\ttotal: 31.8s\tremaining: 6m 37s\n",
            "370:\ttotal: 31.9s\tremaining: 6m 37s\n",
            "371:\ttotal: 31.9s\tremaining: 6m 37s\n",
            "372:\ttotal: 32s\tremaining: 6m 37s\n",
            "373:\ttotal: 32.1s\tremaining: 6m 37s\n",
            "374:\ttotal: 32.2s\tremaining: 6m 37s\n",
            "375:\ttotal: 32.3s\tremaining: 6m 36s\n",
            "376:\ttotal: 32.4s\tremaining: 6m 36s\n",
            "377:\ttotal: 32.4s\tremaining: 6m 36s\n",
            "378:\ttotal: 32.5s\tremaining: 6m 36s\n",
            "379:\ttotal: 32.6s\tremaining: 6m 36s\n",
            "380:\ttotal: 32.7s\tremaining: 6m 36s\n",
            "381:\ttotal: 32.8s\tremaining: 6m 36s\n",
            "382:\ttotal: 32.9s\tremaining: 6m 36s\n",
            "383:\ttotal: 33s\tremaining: 6m 36s\n",
            "384:\ttotal: 33.1s\tremaining: 6m 36s\n",
            "385:\ttotal: 33.2s\tremaining: 6m 36s\n",
            "386:\ttotal: 33.2s\tremaining: 6m 36s\n",
            "387:\ttotal: 33.3s\tremaining: 6m 36s\n",
            "388:\ttotal: 33.4s\tremaining: 6m 35s\n",
            "389:\ttotal: 33.5s\tremaining: 6m 35s\n",
            "390:\ttotal: 33.6s\tremaining: 6m 35s\n",
            "391:\ttotal: 33.6s\tremaining: 6m 35s\n",
            "392:\ttotal: 33.7s\tremaining: 6m 35s\n",
            "393:\ttotal: 33.8s\tremaining: 6m 35s\n",
            "394:\ttotal: 33.9s\tremaining: 6m 35s\n",
            "395:\ttotal: 34s\tremaining: 6m 35s\n",
            "396:\ttotal: 34.1s\tremaining: 6m 35s\n",
            "397:\ttotal: 34.2s\tremaining: 6m 34s\n",
            "398:\ttotal: 34.2s\tremaining: 6m 34s\n",
            "399:\ttotal: 34.3s\tremaining: 6m 34s\n",
            "400:\ttotal: 34.4s\tremaining: 6m 34s\n",
            "401:\ttotal: 34.5s\tremaining: 6m 34s\n",
            "402:\ttotal: 34.6s\tremaining: 6m 34s\n",
            "403:\ttotal: 34.7s\tremaining: 6m 34s\n",
            "404:\ttotal: 34.8s\tremaining: 6m 34s\n",
            "405:\ttotal: 34.9s\tremaining: 6m 34s\n",
            "406:\ttotal: 34.9s\tremaining: 6m 34s\n",
            "407:\ttotal: 35s\tremaining: 6m 34s\n",
            "408:\ttotal: 35.1s\tremaining: 6m 34s\n",
            "409:\ttotal: 35.2s\tremaining: 6m 34s\n",
            "410:\ttotal: 35.3s\tremaining: 6m 33s\n",
            "411:\ttotal: 35.4s\tremaining: 6m 33s\n",
            "412:\ttotal: 35.4s\tremaining: 6m 33s\n",
            "413:\ttotal: 35.5s\tremaining: 6m 33s\n",
            "414:\ttotal: 35.6s\tremaining: 6m 33s\n",
            "415:\ttotal: 35.7s\tremaining: 6m 33s\n",
            "416:\ttotal: 35.8s\tremaining: 6m 33s\n",
            "417:\ttotal: 35.9s\tremaining: 6m 33s\n",
            "418:\ttotal: 36s\tremaining: 6m 33s\n",
            "419:\ttotal: 36.1s\tremaining: 6m 33s\n",
            "420:\ttotal: 36.2s\tremaining: 6m 33s\n",
            "421:\ttotal: 36.2s\tremaining: 6m 33s\n",
            "422:\ttotal: 36.3s\tremaining: 6m 33s\n",
            "423:\ttotal: 36.4s\tremaining: 6m 32s\n",
            "424:\ttotal: 36.5s\tremaining: 6m 32s\n",
            "425:\ttotal: 36.6s\tremaining: 6m 32s\n",
            "426:\ttotal: 36.7s\tremaining: 6m 32s\n",
            "427:\ttotal: 36.7s\tremaining: 6m 32s\n",
            "428:\ttotal: 36.8s\tremaining: 6m 32s\n",
            "429:\ttotal: 36.9s\tremaining: 6m 32s\n",
            "430:\ttotal: 37s\tremaining: 6m 32s\n",
            "431:\ttotal: 37.1s\tremaining: 6m 32s\n",
            "432:\ttotal: 37.2s\tremaining: 6m 32s\n",
            "433:\ttotal: 37.3s\tremaining: 6m 32s\n",
            "434:\ttotal: 37.3s\tremaining: 6m 31s\n",
            "435:\ttotal: 37.4s\tremaining: 6m 31s\n",
            "436:\ttotal: 37.5s\tremaining: 6m 31s\n",
            "437:\ttotal: 37.6s\tremaining: 6m 31s\n",
            "438:\ttotal: 37.7s\tremaining: 6m 31s\n",
            "439:\ttotal: 37.8s\tremaining: 6m 31s\n",
            "440:\ttotal: 37.9s\tremaining: 6m 31s\n",
            "441:\ttotal: 38s\tremaining: 6m 31s\n",
            "442:\ttotal: 38.1s\tremaining: 6m 31s\n",
            "443:\ttotal: 38.1s\tremaining: 6m 31s\n",
            "444:\ttotal: 38.2s\tremaining: 6m 31s\n",
            "445:\ttotal: 38.3s\tremaining: 6m 31s\n",
            "446:\ttotal: 38.4s\tremaining: 6m 31s\n",
            "447:\ttotal: 38.5s\tremaining: 6m 31s\n",
            "448:\ttotal: 38.6s\tremaining: 6m 30s\n",
            "449:\ttotal: 38.6s\tremaining: 6m 30s\n",
            "450:\ttotal: 38.7s\tremaining: 6m 30s\n",
            "451:\ttotal: 38.8s\tremaining: 6m 30s\n",
            "452:\ttotal: 38.9s\tremaining: 6m 30s\n",
            "453:\ttotal: 39s\tremaining: 6m 30s\n",
            "454:\ttotal: 39.1s\tremaining: 6m 30s\n",
            "455:\ttotal: 39.2s\tremaining: 6m 30s\n",
            "456:\ttotal: 39.2s\tremaining: 6m 30s\n",
            "457:\ttotal: 39.3s\tremaining: 6m 30s\n",
            "458:\ttotal: 39.4s\tremaining: 6m 29s\n",
            "459:\ttotal: 39.5s\tremaining: 6m 29s\n",
            "460:\ttotal: 39.6s\tremaining: 6m 29s\n",
            "461:\ttotal: 39.7s\tremaining: 6m 29s\n",
            "462:\ttotal: 39.7s\tremaining: 6m 29s\n",
            "463:\ttotal: 39.8s\tremaining: 6m 29s\n",
            "464:\ttotal: 39.9s\tremaining: 6m 29s\n",
            "465:\ttotal: 40s\tremaining: 6m 29s\n",
            "466:\ttotal: 40.1s\tremaining: 6m 29s\n",
            "467:\ttotal: 40.2s\tremaining: 6m 29s\n",
            "468:\ttotal: 40.3s\tremaining: 6m 29s\n",
            "469:\ttotal: 40.4s\tremaining: 6m 28s\n",
            "470:\ttotal: 40.4s\tremaining: 6m 28s\n",
            "471:\ttotal: 40.5s\tremaining: 6m 28s\n",
            "472:\ttotal: 40.6s\tremaining: 6m 28s\n",
            "473:\ttotal: 40.7s\tremaining: 6m 28s\n",
            "474:\ttotal: 40.8s\tremaining: 6m 28s\n",
            "475:\ttotal: 40.9s\tremaining: 6m 28s\n",
            "476:\ttotal: 41s\tremaining: 6m 28s\n",
            "477:\ttotal: 41.1s\tremaining: 6m 28s\n",
            "478:\ttotal: 41.1s\tremaining: 6m 28s\n",
            "479:\ttotal: 41.2s\tremaining: 6m 28s\n",
            "480:\ttotal: 41.3s\tremaining: 6m 28s\n",
            "481:\ttotal: 41.4s\tremaining: 6m 27s\n",
            "482:\ttotal: 41.5s\tremaining: 6m 27s\n",
            "483:\ttotal: 41.6s\tremaining: 6m 27s\n",
            "484:\ttotal: 41.6s\tremaining: 6m 27s\n",
            "485:\ttotal: 41.7s\tremaining: 6m 27s\n",
            "486:\ttotal: 41.8s\tremaining: 6m 27s\n",
            "487:\ttotal: 41.9s\tremaining: 6m 27s\n",
            "488:\ttotal: 42s\tremaining: 6m 27s\n",
            "489:\ttotal: 42.1s\tremaining: 6m 27s\n",
            "490:\ttotal: 42.2s\tremaining: 6m 27s\n",
            "491:\ttotal: 42.2s\tremaining: 6m 27s\n",
            "492:\ttotal: 42.3s\tremaining: 6m 26s\n",
            "493:\ttotal: 42.4s\tremaining: 6m 26s\n",
            "494:\ttotal: 42.5s\tremaining: 6m 26s\n",
            "495:\ttotal: 42.6s\tremaining: 6m 26s\n",
            "496:\ttotal: 42.7s\tremaining: 6m 26s\n",
            "497:\ttotal: 42.8s\tremaining: 6m 26s\n",
            "498:\ttotal: 42.9s\tremaining: 6m 26s\n",
            "499:\ttotal: 43s\tremaining: 6m 26s\n",
            "500:\ttotal: 43s\tremaining: 6m 26s\n",
            "501:\ttotal: 43.1s\tremaining: 6m 26s\n",
            "502:\ttotal: 43.2s\tremaining: 6m 26s\n",
            "503:\ttotal: 43.3s\tremaining: 6m 26s\n",
            "504:\ttotal: 43.4s\tremaining: 6m 26s\n",
            "505:\ttotal: 43.5s\tremaining: 6m 26s\n",
            "506:\ttotal: 43.6s\tremaining: 6m 26s\n",
            "507:\ttotal: 43.6s\tremaining: 6m 25s\n",
            "508:\ttotal: 43.7s\tremaining: 6m 25s\n",
            "509:\ttotal: 43.8s\tremaining: 6m 25s\n",
            "510:\ttotal: 43.9s\tremaining: 6m 25s\n",
            "511:\ttotal: 44s\tremaining: 6m 25s\n",
            "512:\ttotal: 44.1s\tremaining: 6m 25s\n",
            "513:\ttotal: 44.2s\tremaining: 6m 25s\n",
            "514:\ttotal: 44.2s\tremaining: 6m 25s\n",
            "515:\ttotal: 44.3s\tremaining: 6m 25s\n",
            "516:\ttotal: 44.4s\tremaining: 6m 25s\n",
            "517:\ttotal: 44.5s\tremaining: 6m 24s\n",
            "518:\ttotal: 44.6s\tremaining: 6m 24s\n",
            "519:\ttotal: 44.6s\tremaining: 6m 24s\n",
            "520:\ttotal: 44.7s\tremaining: 6m 24s\n",
            "521:\ttotal: 44.8s\tremaining: 6m 24s\n",
            "522:\ttotal: 44.9s\tremaining: 6m 24s\n",
            "523:\ttotal: 45s\tremaining: 6m 24s\n",
            "524:\ttotal: 45.1s\tremaining: 6m 24s\n",
            "525:\ttotal: 45.2s\tremaining: 6m 24s\n",
            "526:\ttotal: 45.3s\tremaining: 6m 24s\n",
            "527:\ttotal: 45.4s\tremaining: 6m 24s\n",
            "528:\ttotal: 45.4s\tremaining: 6m 24s\n",
            "529:\ttotal: 45.5s\tremaining: 6m 23s\n",
            "530:\ttotal: 45.6s\tremaining: 6m 23s\n",
            "531:\ttotal: 45.7s\tremaining: 6m 23s\n",
            "532:\ttotal: 45.8s\tremaining: 6m 23s\n",
            "533:\ttotal: 45.9s\tremaining: 6m 23s\n",
            "534:\ttotal: 46s\tremaining: 6m 23s\n",
            "535:\ttotal: 46.1s\tremaining: 6m 23s\n",
            "536:\ttotal: 46.2s\tremaining: 6m 23s\n",
            "537:\ttotal: 46.2s\tremaining: 6m 23s\n",
            "538:\ttotal: 46.3s\tremaining: 6m 23s\n",
            "539:\ttotal: 46.4s\tremaining: 6m 23s\n",
            "540:\ttotal: 46.4s\tremaining: 6m 22s\n",
            "541:\ttotal: 46.5s\tremaining: 6m 22s\n",
            "542:\ttotal: 46.6s\tremaining: 6m 22s\n",
            "543:\ttotal: 46.7s\tremaining: 6m 22s\n",
            "544:\ttotal: 46.8s\tremaining: 6m 22s\n",
            "545:\ttotal: 46.9s\tremaining: 6m 22s\n",
            "546:\ttotal: 46.9s\tremaining: 6m 22s\n",
            "547:\ttotal: 47s\tremaining: 6m 22s\n",
            "548:\ttotal: 47.1s\tremaining: 6m 22s\n",
            "549:\ttotal: 47.2s\tremaining: 6m 21s\n",
            "550:\ttotal: 47.3s\tremaining: 6m 21s\n",
            "551:\ttotal: 47.4s\tremaining: 6m 21s\n",
            "552:\ttotal: 47.5s\tremaining: 6m 21s\n",
            "553:\ttotal: 47.5s\tremaining: 6m 21s\n",
            "554:\ttotal: 47.6s\tremaining: 6m 21s\n",
            "555:\ttotal: 47.7s\tremaining: 6m 21s\n",
            "556:\ttotal: 47.8s\tremaining: 6m 21s\n",
            "557:\ttotal: 47.9s\tremaining: 6m 21s\n",
            "558:\ttotal: 48s\tremaining: 6m 21s\n",
            "559:\ttotal: 48.1s\tremaining: 6m 21s\n",
            "560:\ttotal: 48.1s\tremaining: 6m 20s\n",
            "561:\ttotal: 48.2s\tremaining: 6m 20s\n",
            "562:\ttotal: 48.3s\tremaining: 6m 20s\n",
            "563:\ttotal: 48.4s\tremaining: 6m 20s\n",
            "564:\ttotal: 48.5s\tremaining: 6m 20s\n",
            "565:\ttotal: 48.6s\tremaining: 6m 20s\n",
            "566:\ttotal: 48.6s\tremaining: 6m 20s\n",
            "567:\ttotal: 48.7s\tremaining: 6m 20s\n",
            "568:\ttotal: 48.8s\tremaining: 6m 20s\n",
            "569:\ttotal: 48.9s\tremaining: 6m 20s\n",
            "570:\ttotal: 49s\tremaining: 6m 20s\n",
            "571:\ttotal: 49.1s\tremaining: 6m 19s\n",
            "572:\ttotal: 49.2s\tremaining: 6m 19s\n",
            "573:\ttotal: 49.3s\tremaining: 6m 19s\n",
            "574:\ttotal: 49.3s\tremaining: 6m 19s\n",
            "575:\ttotal: 49.4s\tremaining: 6m 19s\n",
            "576:\ttotal: 49.5s\tremaining: 6m 19s\n",
            "577:\ttotal: 49.6s\tremaining: 6m 19s\n",
            "578:\ttotal: 49.7s\tremaining: 6m 19s\n",
            "579:\ttotal: 49.8s\tremaining: 6m 19s\n",
            "580:\ttotal: 49.8s\tremaining: 6m 19s\n",
            "581:\ttotal: 49.9s\tremaining: 6m 18s\n",
            "582:\ttotal: 50s\tremaining: 6m 18s\n",
            "583:\ttotal: 50.1s\tremaining: 6m 18s\n",
            "584:\ttotal: 50.2s\tremaining: 6m 18s\n",
            "585:\ttotal: 50.3s\tremaining: 6m 18s\n",
            "586:\ttotal: 50.4s\tremaining: 6m 18s\n",
            "587:\ttotal: 50.4s\tremaining: 6m 18s\n",
            "588:\ttotal: 50.5s\tremaining: 6m 18s\n",
            "589:\ttotal: 50.6s\tremaining: 6m 18s\n",
            "590:\ttotal: 50.7s\tremaining: 6m 18s\n",
            "591:\ttotal: 50.8s\tremaining: 6m 18s\n",
            "592:\ttotal: 50.9s\tremaining: 6m 18s\n",
            "593:\ttotal: 50.9s\tremaining: 6m 17s\n",
            "594:\ttotal: 51s\tremaining: 6m 17s\n",
            "595:\ttotal: 51.1s\tremaining: 6m 17s\n",
            "596:\ttotal: 51.2s\tremaining: 6m 17s\n",
            "597:\ttotal: 51.3s\tremaining: 6m 17s\n",
            "598:\ttotal: 51.4s\tremaining: 6m 17s\n",
            "599:\ttotal: 51.5s\tremaining: 6m 17s\n",
            "600:\ttotal: 51.5s\tremaining: 6m 17s\n",
            "601:\ttotal: 51.6s\tremaining: 6m 17s\n",
            "602:\ttotal: 51.7s\tremaining: 6m 17s\n",
            "603:\ttotal: 51.8s\tremaining: 6m 17s\n",
            "604:\ttotal: 51.9s\tremaining: 6m 16s\n",
            "605:\ttotal: 52s\tremaining: 6m 16s\n",
            "606:\ttotal: 52.1s\tremaining: 6m 16s\n",
            "607:\ttotal: 52.2s\tremaining: 6m 16s\n",
            "608:\ttotal: 52.2s\tremaining: 6m 16s\n",
            "609:\ttotal: 52.3s\tremaining: 6m 16s\n",
            "610:\ttotal: 52.4s\tremaining: 6m 16s\n",
            "611:\ttotal: 52.5s\tremaining: 6m 16s\n",
            "612:\ttotal: 52.6s\tremaining: 6m 16s\n",
            "613:\ttotal: 52.7s\tremaining: 6m 16s\n",
            "614:\ttotal: 52.7s\tremaining: 6m 16s\n",
            "615:\ttotal: 52.8s\tremaining: 6m 15s\n",
            "616:\ttotal: 52.9s\tremaining: 6m 15s\n",
            "617:\ttotal: 53s\tremaining: 6m 15s\n",
            "618:\ttotal: 53.1s\tremaining: 6m 15s\n",
            "619:\ttotal: 53.2s\tremaining: 6m 15s\n",
            "620:\ttotal: 53.3s\tremaining: 6m 15s\n",
            "621:\ttotal: 53.3s\tremaining: 6m 15s\n",
            "622:\ttotal: 53.4s\tremaining: 6m 15s\n",
            "623:\ttotal: 53.5s\tremaining: 6m 15s\n",
            "624:\ttotal: 53.6s\tremaining: 6m 15s\n",
            "625:\ttotal: 53.7s\tremaining: 6m 15s\n",
            "626:\ttotal: 53.8s\tremaining: 6m 15s\n",
            "627:\ttotal: 53.8s\tremaining: 6m 14s\n",
            "628:\ttotal: 53.9s\tremaining: 6m 14s\n",
            "629:\ttotal: 54s\tremaining: 6m 14s\n",
            "630:\ttotal: 54.1s\tremaining: 6m 14s\n",
            "631:\ttotal: 54.2s\tremaining: 6m 14s\n",
            "632:\ttotal: 54.3s\tremaining: 6m 14s\n",
            "633:\ttotal: 54.4s\tremaining: 6m 14s\n",
            "634:\ttotal: 54.5s\tremaining: 6m 14s\n",
            "635:\ttotal: 54.6s\tremaining: 6m 14s\n",
            "636:\ttotal: 54.6s\tremaining: 6m 14s\n",
            "637:\ttotal: 54.7s\tremaining: 6m 14s\n",
            "638:\ttotal: 54.8s\tremaining: 6m 14s\n",
            "639:\ttotal: 54.9s\tremaining: 6m 13s\n",
            "640:\ttotal: 55s\tremaining: 6m 13s\n",
            "641:\ttotal: 55.1s\tremaining: 6m 13s\n",
            "642:\ttotal: 55.2s\tremaining: 6m 13s\n",
            "643:\ttotal: 55.2s\tremaining: 6m 13s\n",
            "644:\ttotal: 55.3s\tremaining: 6m 13s\n",
            "645:\ttotal: 55.4s\tremaining: 6m 13s\n",
            "646:\ttotal: 55.5s\tremaining: 6m 13s\n",
            "647:\ttotal: 55.6s\tremaining: 6m 13s\n",
            "648:\ttotal: 55.7s\tremaining: 6m 13s\n",
            "649:\ttotal: 55.7s\tremaining: 6m 13s\n",
            "650:\ttotal: 55.8s\tremaining: 6m 12s\n",
            "651:\ttotal: 55.9s\tremaining: 6m 12s\n",
            "652:\ttotal: 56s\tremaining: 6m 12s\n",
            "653:\ttotal: 56.1s\tremaining: 6m 12s\n",
            "654:\ttotal: 56.2s\tremaining: 6m 12s\n",
            "655:\ttotal: 56.3s\tremaining: 6m 12s\n",
            "656:\ttotal: 56.3s\tremaining: 6m 12s\n",
            "657:\ttotal: 56.5s\tremaining: 6m 12s\n",
            "658:\ttotal: 56.5s\tremaining: 6m 12s\n",
            "659:\ttotal: 56.6s\tremaining: 6m 12s\n",
            "660:\ttotal: 56.7s\tremaining: 6m 12s\n",
            "661:\ttotal: 56.8s\tremaining: 6m 12s\n",
            "662:\ttotal: 56.9s\tremaining: 6m 12s\n",
            "663:\ttotal: 57s\tremaining: 6m 12s\n",
            "664:\ttotal: 57.1s\tremaining: 6m 12s\n",
            "665:\ttotal: 57.2s\tremaining: 6m 11s\n",
            "666:\ttotal: 57.2s\tremaining: 6m 11s\n",
            "667:\ttotal: 57.3s\tremaining: 6m 11s\n",
            "668:\ttotal: 57.4s\tremaining: 6m 11s\n",
            "669:\ttotal: 57.5s\tremaining: 6m 11s\n",
            "670:\ttotal: 57.6s\tremaining: 6m 11s\n",
            "671:\ttotal: 57.7s\tremaining: 6m 11s\n",
            "672:\ttotal: 57.8s\tremaining: 6m 11s\n",
            "673:\ttotal: 57.8s\tremaining: 6m 11s\n",
            "674:\ttotal: 57.9s\tremaining: 6m 11s\n",
            "675:\ttotal: 58s\tremaining: 6m 11s\n",
            "676:\ttotal: 58.1s\tremaining: 6m 11s\n",
            "677:\ttotal: 58.2s\tremaining: 6m 10s\n",
            "678:\ttotal: 58.3s\tremaining: 6m 10s\n",
            "679:\ttotal: 58.4s\tremaining: 6m 10s\n",
            "680:\ttotal: 58.4s\tremaining: 6m 10s\n",
            "681:\ttotal: 58.5s\tremaining: 6m 10s\n",
            "682:\ttotal: 58.6s\tremaining: 6m 10s\n",
            "683:\ttotal: 58.7s\tremaining: 6m 10s\n",
            "684:\ttotal: 58.8s\tremaining: 6m 10s\n",
            "685:\ttotal: 58.9s\tremaining: 6m 10s\n",
            "686:\ttotal: 58.9s\tremaining: 6m 10s\n",
            "687:\ttotal: 59s\tremaining: 6m 9s\n",
            "688:\ttotal: 59.1s\tremaining: 6m 9s\n",
            "689:\ttotal: 59.2s\tremaining: 6m 9s\n",
            "690:\ttotal: 59.3s\tremaining: 6m 9s\n",
            "691:\ttotal: 59.4s\tremaining: 6m 9s\n",
            "692:\ttotal: 59.5s\tremaining: 6m 9s\n",
            "693:\ttotal: 59.5s\tremaining: 6m 9s\n",
            "694:\ttotal: 59.6s\tremaining: 6m 9s\n",
            "695:\ttotal: 59.7s\tremaining: 6m 9s\n",
            "696:\ttotal: 59.8s\tremaining: 6m 9s\n",
            "697:\ttotal: 59.9s\tremaining: 6m 9s\n",
            "698:\ttotal: 60s\tremaining: 6m 8s\n",
            "699:\ttotal: 1m\tremaining: 6m 8s\n",
            "700:\ttotal: 1m\tremaining: 6m 8s\n",
            "701:\ttotal: 1m\tremaining: 6m 8s\n",
            "702:\ttotal: 1m\tremaining: 6m 8s\n",
            "703:\ttotal: 1m\tremaining: 6m 8s\n",
            "704:\ttotal: 1m\tremaining: 6m 8s\n",
            "705:\ttotal: 1m\tremaining: 6m 8s\n",
            "706:\ttotal: 1m\tremaining: 6m 8s\n",
            "707:\ttotal: 1m\tremaining: 6m 8s\n",
            "708:\ttotal: 1m\tremaining: 6m 8s\n",
            "709:\ttotal: 1m\tremaining: 6m 7s\n",
            "710:\ttotal: 1m\tremaining: 6m 7s\n",
            "711:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "712:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "713:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "714:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "715:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "716:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "717:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "718:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "719:\ttotal: 1m 1s\tremaining: 6m 7s\n",
            "720:\ttotal: 1m 1s\tremaining: 6m 6s\n",
            "721:\ttotal: 1m 1s\tremaining: 6m 6s\n",
            "722:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "723:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "724:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "725:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "726:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "727:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "728:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "729:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "730:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "731:\ttotal: 1m 2s\tremaining: 6m 6s\n",
            "732:\ttotal: 1m 2s\tremaining: 6m 5s\n",
            "733:\ttotal: 1m 2s\tremaining: 6m 5s\n",
            "734:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "735:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "736:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "737:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "738:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "739:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "740:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "741:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "742:\ttotal: 1m 3s\tremaining: 6m 5s\n",
            "743:\ttotal: 1m 3s\tremaining: 6m 4s\n",
            "744:\ttotal: 1m 3s\tremaining: 6m 4s\n",
            "745:\ttotal: 1m 3s\tremaining: 6m 4s\n",
            "746:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "747:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "748:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "749:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "750:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "751:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "752:\ttotal: 1m 4s\tremaining: 6m 4s\n",
            "753:\ttotal: 1m 4s\tremaining: 6m 3s\n",
            "754:\ttotal: 1m 4s\tremaining: 6m 3s\n",
            "755:\ttotal: 1m 4s\tremaining: 6m 3s\n",
            "756:\ttotal: 1m 4s\tremaining: 6m 3s\n",
            "757:\ttotal: 1m 4s\tremaining: 6m 3s\n",
            "758:\ttotal: 1m 5s\tremaining: 6m 3s\n",
            "759:\ttotal: 1m 5s\tremaining: 6m 3s\n",
            "760:\ttotal: 1m 5s\tremaining: 6m 3s\n",
            "761:\ttotal: 1m 5s\tremaining: 6m 3s\n",
            "762:\ttotal: 1m 5s\tremaining: 6m 3s\n",
            "763:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "764:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "765:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "766:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "767:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "768:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "769:\ttotal: 1m 5s\tremaining: 6m 2s\n",
            "770:\ttotal: 1m 6s\tremaining: 6m 2s\n",
            "771:\ttotal: 1m 6s\tremaining: 6m 2s\n",
            "772:\ttotal: 1m 6s\tremaining: 6m 2s\n",
            "773:\ttotal: 1m 6s\tremaining: 6m 2s\n",
            "774:\ttotal: 1m 6s\tremaining: 6m 2s\n",
            "775:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "776:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "777:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "778:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "779:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "780:\ttotal: 1m 6s\tremaining: 6m 1s\n",
            "781:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "782:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "783:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "784:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "785:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "786:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "787:\ttotal: 1m 7s\tremaining: 6m 1s\n",
            "788:\ttotal: 1m 7s\tremaining: 6m\n",
            "789:\ttotal: 1m 7s\tremaining: 6m\n",
            "790:\ttotal: 1m 7s\tremaining: 6m\n",
            "791:\ttotal: 1m 7s\tremaining: 6m\n",
            "792:\ttotal: 1m 7s\tremaining: 6m\n",
            "793:\ttotal: 1m 8s\tremaining: 6m\n",
            "794:\ttotal: 1m 8s\tremaining: 6m\n",
            "795:\ttotal: 1m 8s\tremaining: 6m\n",
            "796:\ttotal: 1m 8s\tremaining: 6m\n",
            "797:\ttotal: 1m 8s\tremaining: 6m\n",
            "798:\ttotal: 1m 8s\tremaining: 6m\n",
            "799:\ttotal: 1m 8s\tremaining: 6m\n",
            "800:\ttotal: 1m 8s\tremaining: 5m 59s\n",
            "801:\ttotal: 1m 8s\tremaining: 5m 59s\n",
            "802:\ttotal: 1m 8s\tremaining: 5m 59s\n",
            "803:\ttotal: 1m 8s\tremaining: 5m 59s\n",
            "804:\ttotal: 1m 8s\tremaining: 5m 59s\n",
            "805:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "806:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "807:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "808:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "809:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "810:\ttotal: 1m 9s\tremaining: 5m 59s\n",
            "811:\ttotal: 1m 9s\tremaining: 5m 58s\n",
            "812:\ttotal: 1m 9s\tremaining: 5m 58s\n",
            "813:\ttotal: 1m 9s\tremaining: 5m 58s\n",
            "814:\ttotal: 1m 9s\tremaining: 5m 58s\n",
            "815:\ttotal: 1m 9s\tremaining: 5m 58s\n",
            "816:\ttotal: 1m 10s\tremaining: 5m 58s\n",
            "817:\ttotal: 1m 10s\tremaining: 5m 58s\n",
            "818:\ttotal: 1m 10s\tremaining: 5m 58s\n",
            "819:\ttotal: 1m 10s\tremaining: 5m 58s\n",
            "820:\ttotal: 1m 10s\tremaining: 5m 58s\n",
            "821:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "822:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "823:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "824:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "825:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "826:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "827:\ttotal: 1m 10s\tremaining: 5m 57s\n",
            "828:\ttotal: 1m 11s\tremaining: 5m 57s\n",
            "829:\ttotal: 1m 11s\tremaining: 5m 57s\n",
            "830:\ttotal: 1m 11s\tremaining: 5m 57s\n",
            "831:\ttotal: 1m 11s\tremaining: 5m 57s\n",
            "832:\ttotal: 1m 11s\tremaining: 5m 57s\n",
            "833:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "834:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "835:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "836:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "837:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "838:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "839:\ttotal: 1m 11s\tremaining: 5m 56s\n",
            "840:\ttotal: 1m 12s\tremaining: 5m 56s\n",
            "841:\ttotal: 1m 12s\tremaining: 5m 56s\n",
            "842:\ttotal: 1m 12s\tremaining: 5m 56s\n",
            "843:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "844:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "845:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "846:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "847:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "848:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "849:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "850:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "851:\ttotal: 1m 12s\tremaining: 5m 55s\n",
            "852:\ttotal: 1m 13s\tremaining: 5m 55s\n",
            "853:\ttotal: 1m 13s\tremaining: 5m 55s\n",
            "854:\ttotal: 1m 13s\tremaining: 5m 55s\n",
            "855:\ttotal: 1m 13s\tremaining: 5m 55s\n",
            "856:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "857:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "858:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "859:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "860:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "861:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "862:\ttotal: 1m 13s\tremaining: 5m 54s\n",
            "863:\ttotal: 1m 14s\tremaining: 5m 54s\n",
            "864:\ttotal: 1m 14s\tremaining: 5m 54s\n",
            "865:\ttotal: 1m 14s\tremaining: 5m 54s\n",
            "866:\ttotal: 1m 14s\tremaining: 5m 54s\n",
            "867:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "868:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "869:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "870:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "871:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "872:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "873:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "874:\ttotal: 1m 14s\tremaining: 5m 53s\n",
            "875:\ttotal: 1m 15s\tremaining: 5m 53s\n",
            "876:\ttotal: 1m 15s\tremaining: 5m 53s\n",
            "877:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "878:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "879:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "880:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "881:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "882:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "883:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "884:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "885:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "886:\ttotal: 1m 15s\tremaining: 5m 52s\n",
            "887:\ttotal: 1m 16s\tremaining: 5m 52s\n",
            "888:\ttotal: 1m 16s\tremaining: 5m 52s\n",
            "889:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "890:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "891:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "892:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "893:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "894:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "895:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "896:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "897:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "898:\ttotal: 1m 16s\tremaining: 5m 51s\n",
            "899:\ttotal: 1m 17s\tremaining: 5m 51s\n",
            "900:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "901:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "902:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "903:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "904:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "905:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "906:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "907:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "908:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "909:\ttotal: 1m 17s\tremaining: 5m 50s\n",
            "910:\ttotal: 1m 18s\tremaining: 5m 50s\n",
            "911:\ttotal: 1m 18s\tremaining: 5m 50s\n",
            "912:\ttotal: 1m 18s\tremaining: 5m 50s\n",
            "913:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "914:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "915:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "916:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "917:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "918:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "919:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "920:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "921:\ttotal: 1m 18s\tremaining: 5m 49s\n",
            "922:\ttotal: 1m 19s\tremaining: 5m 49s\n",
            "923:\ttotal: 1m 19s\tremaining: 5m 49s\n",
            "924:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "925:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "926:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "927:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "928:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "929:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "930:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "931:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "932:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "933:\ttotal: 1m 19s\tremaining: 5m 48s\n",
            "934:\ttotal: 1m 20s\tremaining: 5m 48s\n",
            "935:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "936:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "937:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "938:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "939:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "940:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "941:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "942:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "943:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "944:\ttotal: 1m 20s\tremaining: 5m 47s\n",
            "945:\ttotal: 1m 21s\tremaining: 5m 47s\n",
            "946:\ttotal: 1m 21s\tremaining: 5m 47s\n",
            "947:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "948:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "949:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "950:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "951:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "952:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "953:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "954:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "955:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "956:\ttotal: 1m 21s\tremaining: 5m 46s\n",
            "957:\ttotal: 1m 22s\tremaining: 5m 46s\n",
            "958:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "959:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "960:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "961:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "962:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "963:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "964:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "965:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "966:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "967:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "968:\ttotal: 1m 22s\tremaining: 5m 45s\n",
            "969:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "970:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "971:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "972:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "973:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "974:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "975:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "976:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "977:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "978:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "979:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "980:\ttotal: 1m 23s\tremaining: 5m 44s\n",
            "981:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "982:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "983:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "984:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "985:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "986:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "987:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "988:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "989:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "990:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "991:\ttotal: 1m 24s\tremaining: 5m 43s\n",
            "992:\ttotal: 1m 24s\tremaining: 5m 42s\n",
            "993:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "994:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "995:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "996:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "997:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "998:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "999:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "1000:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "1001:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "1002:\ttotal: 1m 25s\tremaining: 5m 42s\n",
            "1003:\ttotal: 1m 25s\tremaining: 5m 41s\n",
            "1004:\ttotal: 1m 25s\tremaining: 5m 41s\n",
            "1005:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1006:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1007:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1008:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1009:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1010:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1011:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1012:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1013:\ttotal: 1m 26s\tremaining: 5m 41s\n",
            "1014:\ttotal: 1m 26s\tremaining: 5m 40s\n",
            "1015:\ttotal: 1m 26s\tremaining: 5m 40s\n",
            "1016:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1017:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1018:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1019:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1020:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1021:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1022:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1023:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1024:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1025:\ttotal: 1m 27s\tremaining: 5m 40s\n",
            "1026:\ttotal: 1m 27s\tremaining: 5m 39s\n",
            "1027:\ttotal: 1m 27s\tremaining: 5m 39s\n",
            "1028:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1029:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1030:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1031:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1032:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1033:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1034:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1035:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1036:\ttotal: 1m 28s\tremaining: 5m 39s\n",
            "1037:\ttotal: 1m 28s\tremaining: 5m 38s\n",
            "1038:\ttotal: 1m 28s\tremaining: 5m 38s\n",
            "1039:\ttotal: 1m 28s\tremaining: 5m 38s\n",
            "1040:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1041:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1042:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1043:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1044:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1045:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1046:\ttotal: 1m 29s\tremaining: 5m 38s\n",
            "1047:\ttotal: 1m 29s\tremaining: 5m 37s\n",
            "1048:\ttotal: 1m 29s\tremaining: 5m 37s\n",
            "1049:\ttotal: 1m 29s\tremaining: 5m 37s\n",
            "1050:\ttotal: 1m 29s\tremaining: 5m 37s\n",
            "1051:\ttotal: 1m 29s\tremaining: 5m 37s\n",
            "1052:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1053:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1054:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1055:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1056:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1057:\ttotal: 1m 30s\tremaining: 5m 37s\n",
            "1058:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1059:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1060:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1061:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1062:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1063:\ttotal: 1m 30s\tremaining: 5m 36s\n",
            "1064:\ttotal: 1m 31s\tremaining: 5m 36s\n",
            "1065:\ttotal: 1m 31s\tremaining: 5m 36s\n",
            "1066:\ttotal: 1m 31s\tremaining: 5m 36s\n",
            "1067:\ttotal: 1m 31s\tremaining: 5m 36s\n",
            "1068:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1069:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1070:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1071:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1072:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1073:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1074:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1075:\ttotal: 1m 31s\tremaining: 5m 35s\n",
            "1076:\ttotal: 1m 32s\tremaining: 5m 35s\n",
            "1077:\ttotal: 1m 32s\tremaining: 5m 35s\n",
            "1078:\ttotal: 1m 32s\tremaining: 5m 35s\n",
            "1079:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1080:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1081:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1082:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1083:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1084:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1085:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1086:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1087:\ttotal: 1m 32s\tremaining: 5m 34s\n",
            "1088:\ttotal: 1m 33s\tremaining: 5m 34s\n",
            "1089:\ttotal: 1m 33s\tremaining: 5m 34s\n",
            "1090:\ttotal: 1m 33s\tremaining: 5m 34s\n",
            "1091:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1092:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1093:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1094:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1095:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1096:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1097:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1098:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1099:\ttotal: 1m 33s\tremaining: 5m 33s\n",
            "1100:\ttotal: 1m 34s\tremaining: 5m 33s\n",
            "1101:\ttotal: 1m 34s\tremaining: 5m 33s\n",
            "1102:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1103:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1104:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1105:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1106:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1107:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1108:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1109:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1110:\ttotal: 1m 34s\tremaining: 5m 32s\n",
            "1111:\ttotal: 1m 35s\tremaining: 5m 32s\n",
            "1112:\ttotal: 1m 35s\tremaining: 5m 32s\n",
            "1113:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1114:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1115:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1116:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1117:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1118:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1119:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1120:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1121:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1122:\ttotal: 1m 35s\tremaining: 5m 31s\n",
            "1123:\ttotal: 1m 36s\tremaining: 5m 31s\n",
            "1124:\ttotal: 1m 36s\tremaining: 5m 31s\n",
            "1125:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1126:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1127:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1128:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1129:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1130:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1131:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1132:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1133:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1134:\ttotal: 1m 36s\tremaining: 5m 30s\n",
            "1135:\ttotal: 1m 37s\tremaining: 5m 30s\n",
            "1136:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1137:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1138:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1139:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1140:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1141:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1142:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1143:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1144:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1145:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1146:\ttotal: 1m 37s\tremaining: 5m 29s\n",
            "1147:\ttotal: 1m 38s\tremaining: 5m 29s\n",
            "1148:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1149:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1150:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1151:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1152:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1153:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1154:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1155:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1156:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1157:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1158:\ttotal: 1m 38s\tremaining: 5m 28s\n",
            "1159:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1160:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1161:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1162:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1163:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1164:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1165:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1166:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1167:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1168:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1169:\ttotal: 1m 39s\tremaining: 5m 27s\n",
            "1170:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1171:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1172:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1173:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1174:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1175:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1176:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1177:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1178:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1179:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1180:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1181:\ttotal: 1m 40s\tremaining: 5m 26s\n",
            "1182:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1183:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1184:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1185:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1186:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1187:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1188:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1189:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1190:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1191:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1192:\ttotal: 1m 41s\tremaining: 5m 25s\n",
            "1193:\ttotal: 1m 41s\tremaining: 5m 24s\n",
            "1194:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1195:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1196:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1197:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1198:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1199:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1200:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1201:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1202:\ttotal: 1m 42s\tremaining: 5m 24s\n",
            "1203:\ttotal: 1m 42s\tremaining: 5m 23s\n",
            "1204:\ttotal: 1m 42s\tremaining: 5m 23s\n",
            "1205:\ttotal: 1m 42s\tremaining: 5m 23s\n",
            "1206:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1207:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1208:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1209:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1210:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1211:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1212:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1213:\ttotal: 1m 43s\tremaining: 5m 23s\n",
            "1214:\ttotal: 1m 43s\tremaining: 5m 22s\n",
            "1215:\ttotal: 1m 43s\tremaining: 5m 22s\n",
            "1216:\ttotal: 1m 43s\tremaining: 5m 22s\n",
            "1217:\ttotal: 1m 43s\tremaining: 5m 22s\n",
            "1218:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1219:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1220:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1221:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1222:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1223:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1224:\ttotal: 1m 44s\tremaining: 5m 22s\n",
            "1225:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1226:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1227:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1228:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1229:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1230:\ttotal: 1m 44s\tremaining: 5m 21s\n",
            "1231:\ttotal: 1m 45s\tremaining: 5m 21s\n",
            "1232:\ttotal: 1m 45s\tremaining: 5m 21s\n",
            "1233:\ttotal: 1m 45s\tremaining: 5m 21s\n",
            "1234:\ttotal: 1m 45s\tremaining: 5m 21s\n",
            "1235:\ttotal: 1m 45s\tremaining: 5m 21s\n",
            "1236:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1237:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1238:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1239:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1240:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1241:\ttotal: 1m 45s\tremaining: 5m 20s\n",
            "1242:\ttotal: 1m 46s\tremaining: 5m 20s\n",
            "1243:\ttotal: 1m 46s\tremaining: 5m 20s\n",
            "1244:\ttotal: 1m 46s\tremaining: 5m 20s\n",
            "1245:\ttotal: 1m 46s\tremaining: 5m 20s\n",
            "1246:\ttotal: 1m 46s\tremaining: 5m 20s\n",
            "1247:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1248:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1249:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1250:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1251:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1252:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1253:\ttotal: 1m 46s\tremaining: 5m 19s\n",
            "1254:\ttotal: 1m 47s\tremaining: 5m 19s\n",
            "1255:\ttotal: 1m 47s\tremaining: 5m 19s\n",
            "1256:\ttotal: 1m 47s\tremaining: 5m 19s\n",
            "1257:\ttotal: 1m 47s\tremaining: 5m 19s\n",
            "1258:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1259:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1260:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1261:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1262:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1263:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1264:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1265:\ttotal: 1m 47s\tremaining: 5m 18s\n",
            "1266:\ttotal: 1m 48s\tremaining: 5m 18s\n",
            "1267:\ttotal: 1m 48s\tremaining: 5m 18s\n",
            "1268:\ttotal: 1m 48s\tremaining: 5m 18s\n",
            "1269:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1270:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1271:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1272:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1273:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1274:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1275:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1276:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1277:\ttotal: 1m 48s\tremaining: 5m 17s\n",
            "1278:\ttotal: 1m 49s\tremaining: 5m 17s\n",
            "1279:\ttotal: 1m 49s\tremaining: 5m 17s\n",
            "1280:\ttotal: 1m 49s\tremaining: 5m 17s\n",
            "1281:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1282:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1283:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1284:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1285:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1286:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1287:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1288:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1289:\ttotal: 1m 49s\tremaining: 5m 16s\n",
            "1290:\ttotal: 1m 50s\tremaining: 5m 16s\n",
            "1291:\ttotal: 1m 50s\tremaining: 5m 16s\n",
            "1292:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1293:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1294:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1295:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1296:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1297:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1298:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1299:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1300:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1301:\ttotal: 1m 50s\tremaining: 5m 15s\n",
            "1302:\ttotal: 1m 51s\tremaining: 5m 15s\n",
            "1303:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1304:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1305:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1306:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1307:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1308:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1309:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1310:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1311:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1312:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1313:\ttotal: 1m 51s\tremaining: 5m 14s\n",
            "1314:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1315:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1316:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1317:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1318:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1319:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1320:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1321:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1322:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1323:\ttotal: 1m 52s\tremaining: 5m 13s\n",
            "1324:\ttotal: 1m 52s\tremaining: 5m 12s\n",
            "1325:\ttotal: 1m 52s\tremaining: 5m 12s\n",
            "1326:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1327:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1328:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1329:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1330:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1331:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1332:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1333:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1334:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1335:\ttotal: 1m 53s\tremaining: 5m 12s\n",
            "1336:\ttotal: 1m 53s\tremaining: 5m 11s\n",
            "1337:\ttotal: 1m 53s\tremaining: 5m 11s\n",
            "1338:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1339:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1340:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1341:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1342:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1343:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1344:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1345:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1346:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1347:\ttotal: 1m 54s\tremaining: 5m 11s\n",
            "1348:\ttotal: 1m 54s\tremaining: 5m 10s\n",
            "1349:\ttotal: 1m 54s\tremaining: 5m 10s\n",
            "1350:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1351:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1352:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1353:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1354:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1355:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1356:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1357:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1358:\ttotal: 1m 55s\tremaining: 5m 10s\n",
            "1359:\ttotal: 1m 55s\tremaining: 5m 9s\n",
            "1360:\ttotal: 1m 55s\tremaining: 5m 9s\n",
            "1361:\ttotal: 1m 55s\tremaining: 5m 9s\n",
            "1362:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1363:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1364:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1365:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1366:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1367:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1368:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1369:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1370:\ttotal: 1m 56s\tremaining: 5m 9s\n",
            "1371:\ttotal: 1m 56s\tremaining: 5m 8s\n",
            "1372:\ttotal: 1m 56s\tremaining: 5m 8s\n",
            "1373:\ttotal: 1m 56s\tremaining: 5m 8s\n",
            "1374:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1375:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1376:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1377:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1378:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1379:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1380:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1381:\ttotal: 1m 57s\tremaining: 5m 8s\n",
            "1382:\ttotal: 1m 57s\tremaining: 5m 7s\n",
            "1383:\ttotal: 1m 57s\tremaining: 5m 7s\n",
            "1384:\ttotal: 1m 57s\tremaining: 5m 7s\n",
            "1385:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1386:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1387:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1388:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1389:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1390:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1391:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1392:\ttotal: 1m 58s\tremaining: 5m 7s\n",
            "1393:\ttotal: 1m 58s\tremaining: 5m 6s\n",
            "1394:\ttotal: 1m 58s\tremaining: 5m 6s\n",
            "1395:\ttotal: 1m 58s\tremaining: 5m 6s\n",
            "1396:\ttotal: 1m 58s\tremaining: 5m 6s\n",
            "1397:\ttotal: 1m 58s\tremaining: 5m 6s\n",
            "1398:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1399:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1400:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1401:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1402:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1403:\ttotal: 1m 59s\tremaining: 5m 6s\n",
            "1404:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1405:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1406:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1407:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1408:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1409:\ttotal: 1m 59s\tremaining: 5m 5s\n",
            "1410:\ttotal: 2m\tremaining: 5m 5s\n",
            "1411:\ttotal: 2m\tremaining: 5m 5s\n",
            "1412:\ttotal: 2m\tremaining: 5m 5s\n",
            "1413:\ttotal: 2m\tremaining: 5m 5s\n",
            "1414:\ttotal: 2m\tremaining: 5m 5s\n",
            "1415:\ttotal: 2m\tremaining: 5m 4s\n",
            "1416:\ttotal: 2m\tremaining: 5m 4s\n",
            "1417:\ttotal: 2m\tremaining: 5m 4s\n",
            "1418:\ttotal: 2m\tremaining: 5m 4s\n",
            "1419:\ttotal: 2m\tremaining: 5m 4s\n",
            "1420:\ttotal: 2m\tremaining: 5m 4s\n",
            "1421:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1422:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1423:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1424:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1425:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1426:\ttotal: 2m 1s\tremaining: 5m 4s\n",
            "1427:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1428:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1429:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1430:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1431:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1432:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1433:\ttotal: 2m 1s\tremaining: 5m 3s\n",
            "1434:\ttotal: 2m 2s\tremaining: 5m 3s\n",
            "1435:\ttotal: 2m 2s\tremaining: 5m 3s\n",
            "1436:\ttotal: 2m 2s\tremaining: 5m 3s\n",
            "1437:\ttotal: 2m 2s\tremaining: 5m 3s\n",
            "1438:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1439:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1440:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1441:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1442:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1443:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1444:\ttotal: 2m 2s\tremaining: 5m 2s\n",
            "1445:\ttotal: 2m 3s\tremaining: 5m 2s\n",
            "1446:\ttotal: 2m 3s\tremaining: 5m 2s\n",
            "1447:\ttotal: 2m 3s\tremaining: 5m 2s\n",
            "1448:\ttotal: 2m 3s\tremaining: 5m 2s\n",
            "1449:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1450:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1451:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1452:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1453:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1454:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1455:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1456:\ttotal: 2m 3s\tremaining: 5m 1s\n",
            "1457:\ttotal: 2m 4s\tremaining: 5m 1s\n",
            "1458:\ttotal: 2m 4s\tremaining: 5m 1s\n",
            "1459:\ttotal: 2m 4s\tremaining: 5m 1s\n",
            "1460:\ttotal: 2m 4s\tremaining: 5m 1s\n",
            "1461:\ttotal: 2m 4s\tremaining: 5m\n",
            "1462:\ttotal: 2m 4s\tremaining: 5m\n",
            "1463:\ttotal: 2m 4s\tremaining: 5m\n",
            "1464:\ttotal: 2m 4s\tremaining: 5m\n",
            "1465:\ttotal: 2m 4s\tremaining: 5m\n",
            "1466:\ttotal: 2m 4s\tremaining: 5m\n",
            "1467:\ttotal: 2m 4s\tremaining: 5m\n",
            "1468:\ttotal: 2m 4s\tremaining: 5m\n",
            "1469:\ttotal: 2m 5s\tremaining: 5m\n",
            "1470:\ttotal: 2m 5s\tremaining: 5m\n",
            "1471:\ttotal: 2m 5s\tremaining: 5m\n",
            "1472:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1473:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1474:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1475:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1476:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1477:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1478:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1479:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1480:\ttotal: 2m 5s\tremaining: 4m 59s\n",
            "1481:\ttotal: 2m 6s\tremaining: 4m 59s\n",
            "1482:\ttotal: 2m 6s\tremaining: 4m 59s\n",
            "1483:\ttotal: 2m 6s\tremaining: 4m 59s\n",
            "1484:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1485:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1486:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1487:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1488:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1489:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1490:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1491:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1492:\ttotal: 2m 6s\tremaining: 4m 58s\n",
            "1493:\ttotal: 2m 7s\tremaining: 4m 58s\n",
            "1494:\ttotal: 2m 7s\tremaining: 4m 58s\n",
            "1495:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1496:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1497:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1498:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1499:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1500:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1501:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1502:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1503:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1504:\ttotal: 2m 7s\tremaining: 4m 57s\n",
            "1505:\ttotal: 2m 8s\tremaining: 4m 57s\n",
            "1506:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1507:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1508:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1509:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1510:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1511:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1512:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1513:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1514:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1515:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1516:\ttotal: 2m 8s\tremaining: 4m 56s\n",
            "1517:\ttotal: 2m 9s\tremaining: 4m 56s\n",
            "1518:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1519:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1520:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1521:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1522:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1523:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1524:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1525:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1526:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1527:\ttotal: 2m 9s\tremaining: 4m 55s\n",
            "1528:\ttotal: 2m 10s\tremaining: 4m 55s\n",
            "1529:\ttotal: 2m 10s\tremaining: 4m 55s\n",
            "1530:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1531:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1532:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1533:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1534:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1535:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1536:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1537:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1538:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1539:\ttotal: 2m 10s\tremaining: 4m 54s\n",
            "1540:\ttotal: 2m 11s\tremaining: 4m 54s\n",
            "1541:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1542:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1543:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1544:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1545:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1546:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1547:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1548:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1549:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1550:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1551:\ttotal: 2m 11s\tremaining: 4m 53s\n",
            "1552:\ttotal: 2m 12s\tremaining: 4m 53s\n",
            "1553:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1554:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1555:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1556:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1557:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1558:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1559:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1560:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1561:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1562:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1563:\ttotal: 2m 12s\tremaining: 4m 52s\n",
            "1564:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1565:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1566:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1567:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1568:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1569:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1570:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1571:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1572:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1573:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1574:\ttotal: 2m 13s\tremaining: 4m 51s\n",
            "1575:\ttotal: 2m 13s\tremaining: 4m 50s\n",
            "1576:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1577:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1578:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1579:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1580:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1581:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1582:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1583:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1584:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1585:\ttotal: 2m 14s\tremaining: 4m 50s\n",
            "1586:\ttotal: 2m 14s\tremaining: 4m 49s\n",
            "1587:\ttotal: 2m 14s\tremaining: 4m 49s\n",
            "1588:\ttotal: 2m 14s\tremaining: 4m 49s\n",
            "1589:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1590:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1591:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1592:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1593:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1594:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1595:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1596:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1597:\ttotal: 2m 15s\tremaining: 4m 49s\n",
            "1598:\ttotal: 2m 15s\tremaining: 4m 48s\n",
            "1599:\ttotal: 2m 15s\tremaining: 4m 48s\n",
            "1600:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1601:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1602:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1603:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1604:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1605:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1606:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1607:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1608:\ttotal: 2m 16s\tremaining: 4m 48s\n",
            "1609:\ttotal: 2m 16s\tremaining: 4m 47s\n",
            "1610:\ttotal: 2m 16s\tremaining: 4m 47s\n",
            "1611:\ttotal: 2m 16s\tremaining: 4m 47s\n",
            "1612:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1613:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1614:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1615:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1616:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1617:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1618:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1619:\ttotal: 2m 17s\tremaining: 4m 47s\n",
            "1620:\ttotal: 2m 17s\tremaining: 4m 46s\n",
            "1621:\ttotal: 2m 17s\tremaining: 4m 46s\n",
            "1622:\ttotal: 2m 17s\tremaining: 4m 46s\n",
            "1623:\ttotal: 2m 17s\tremaining: 4m 46s\n",
            "1624:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1625:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1626:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1627:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1628:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1629:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1630:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1631:\ttotal: 2m 18s\tremaining: 4m 46s\n",
            "1632:\ttotal: 2m 18s\tremaining: 4m 45s\n",
            "1633:\ttotal: 2m 18s\tremaining: 4m 45s\n",
            "1634:\ttotal: 2m 18s\tremaining: 4m 45s\n",
            "1635:\ttotal: 2m 18s\tremaining: 4m 45s\n",
            "1636:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1637:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1638:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1639:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1640:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1641:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1642:\ttotal: 2m 19s\tremaining: 4m 45s\n",
            "1643:\ttotal: 2m 19s\tremaining: 4m 44s\n",
            "1644:\ttotal: 2m 19s\tremaining: 4m 44s\n",
            "1645:\ttotal: 2m 19s\tremaining: 4m 44s\n",
            "1646:\ttotal: 2m 19s\tremaining: 4m 44s\n",
            "1647:\ttotal: 2m 19s\tremaining: 4m 44s\n",
            "1648:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1649:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1650:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1651:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1652:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1653:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1654:\ttotal: 2m 20s\tremaining: 4m 44s\n",
            "1655:\ttotal: 2m 20s\tremaining: 4m 43s\n",
            "1656:\ttotal: 2m 20s\tremaining: 4m 43s\n",
            "1657:\ttotal: 2m 20s\tremaining: 4m 43s\n",
            "1658:\ttotal: 2m 20s\tremaining: 4m 43s\n",
            "1659:\ttotal: 2m 20s\tremaining: 4m 43s\n",
            "1660:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1661:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1662:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1663:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1664:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1665:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1666:\ttotal: 2m 21s\tremaining: 4m 43s\n",
            "1667:\ttotal: 2m 21s\tremaining: 4m 42s\n",
            "1668:\ttotal: 2m 21s\tremaining: 4m 42s\n",
            "1669:\ttotal: 2m 21s\tremaining: 4m 42s\n",
            "1670:\ttotal: 2m 21s\tremaining: 4m 42s\n",
            "1671:\ttotal: 2m 21s\tremaining: 4m 42s\n",
            "1672:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1673:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1674:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1675:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1676:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1677:\ttotal: 2m 22s\tremaining: 4m 42s\n",
            "1678:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1679:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1680:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1681:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1682:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1683:\ttotal: 2m 22s\tremaining: 4m 41s\n",
            "1684:\ttotal: 2m 23s\tremaining: 4m 41s\n",
            "1685:\ttotal: 2m 23s\tremaining: 4m 41s\n",
            "1686:\ttotal: 2m 23s\tremaining: 4m 41s\n",
            "1687:\ttotal: 2m 23s\tremaining: 4m 41s\n",
            "1688:\ttotal: 2m 23s\tremaining: 4m 41s\n",
            "1689:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1690:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1691:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1692:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1693:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1694:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1695:\ttotal: 2m 23s\tremaining: 4m 40s\n",
            "1696:\ttotal: 2m 24s\tremaining: 4m 40s\n",
            "1697:\ttotal: 2m 24s\tremaining: 4m 40s\n",
            "1698:\ttotal: 2m 24s\tremaining: 4m 40s\n",
            "1699:\ttotal: 2m 24s\tremaining: 4m 40s\n",
            "1700:\ttotal: 2m 24s\tremaining: 4m 40s\n",
            "1701:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1702:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1703:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1704:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1705:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1706:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1707:\ttotal: 2m 24s\tremaining: 4m 39s\n",
            "1708:\ttotal: 2m 25s\tremaining: 4m 39s\n",
            "1709:\ttotal: 2m 25s\tremaining: 4m 39s\n",
            "1710:\ttotal: 2m 25s\tremaining: 4m 39s\n",
            "1711:\ttotal: 2m 25s\tremaining: 4m 39s\n",
            "1712:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1713:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1714:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1715:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1716:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1717:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1718:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1719:\ttotal: 2m 25s\tremaining: 4m 38s\n",
            "1720:\ttotal: 2m 26s\tremaining: 4m 38s\n",
            "1721:\ttotal: 2m 26s\tremaining: 4m 38s\n",
            "1722:\ttotal: 2m 26s\tremaining: 4m 38s\n",
            "1723:\ttotal: 2m 26s\tremaining: 4m 38s\n",
            "1724:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1725:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1726:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1727:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1728:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1729:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1730:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1731:\ttotal: 2m 26s\tremaining: 4m 37s\n",
            "1732:\ttotal: 2m 27s\tremaining: 4m 37s\n",
            "1733:\ttotal: 2m 27s\tremaining: 4m 37s\n",
            "1734:\ttotal: 2m 27s\tremaining: 4m 37s\n",
            "1735:\ttotal: 2m 27s\tremaining: 4m 37s\n",
            "1736:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1737:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1738:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1739:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1740:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1741:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1742:\ttotal: 2m 27s\tremaining: 4m 36s\n",
            "1743:\ttotal: 2m 28s\tremaining: 4m 36s\n",
            "1744:\ttotal: 2m 28s\tremaining: 4m 36s\n",
            "1745:\ttotal: 2m 28s\tremaining: 4m 36s\n",
            "1746:\ttotal: 2m 28s\tremaining: 4m 36s\n",
            "1747:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1748:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1749:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1750:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1751:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1752:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1753:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1754:\ttotal: 2m 28s\tremaining: 4m 35s\n",
            "1755:\ttotal: 2m 29s\tremaining: 4m 35s\n",
            "1756:\ttotal: 2m 29s\tremaining: 4m 35s\n",
            "1757:\ttotal: 2m 29s\tremaining: 4m 35s\n",
            "1758:\ttotal: 2m 29s\tremaining: 4m 35s\n",
            "1759:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1760:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1761:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1762:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1763:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1764:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1765:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1766:\ttotal: 2m 29s\tremaining: 4m 34s\n",
            "1767:\ttotal: 2m 30s\tremaining: 4m 34s\n",
            "1768:\ttotal: 2m 30s\tremaining: 4m 34s\n",
            "1769:\ttotal: 2m 30s\tremaining: 4m 34s\n",
            "1770:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1771:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1772:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1773:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1774:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1775:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1776:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1777:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1778:\ttotal: 2m 30s\tremaining: 4m 33s\n",
            "1779:\ttotal: 2m 31s\tremaining: 4m 33s\n",
            "1780:\ttotal: 2m 31s\tremaining: 4m 33s\n",
            "1781:\ttotal: 2m 31s\tremaining: 4m 33s\n",
            "1782:\ttotal: 2m 31s\tremaining: 4m 33s\n",
            "1783:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1784:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1785:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1786:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1787:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1788:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1789:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1790:\ttotal: 2m 31s\tremaining: 4m 32s\n",
            "1791:\ttotal: 2m 32s\tremaining: 4m 32s\n",
            "1792:\ttotal: 2m 32s\tremaining: 4m 32s\n",
            "1793:\ttotal: 2m 32s\tremaining: 4m 32s\n",
            "1794:\ttotal: 2m 32s\tremaining: 4m 32s\n",
            "1795:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1796:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1797:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1798:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1799:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1800:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1801:\ttotal: 2m 32s\tremaining: 4m 31s\n",
            "1802:\ttotal: 2m 33s\tremaining: 4m 31s\n",
            "1803:\ttotal: 2m 33s\tremaining: 4m 31s\n",
            "1804:\ttotal: 2m 33s\tremaining: 4m 31s\n",
            "1805:\ttotal: 2m 33s\tremaining: 4m 31s\n",
            "1806:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1807:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1808:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1809:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1810:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1811:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1812:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1813:\ttotal: 2m 33s\tremaining: 4m 30s\n",
            "1814:\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "1815:\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "1816:\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "1817:\ttotal: 2m 34s\tremaining: 4m 30s\n",
            "1818:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1819:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1820:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1821:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1822:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1823:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1824:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1825:\ttotal: 2m 34s\tremaining: 4m 29s\n",
            "1826:\ttotal: 2m 35s\tremaining: 4m 29s\n",
            "1827:\ttotal: 2m 35s\tremaining: 4m 29s\n",
            "1828:\ttotal: 2m 35s\tremaining: 4m 29s\n",
            "1829:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1830:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1831:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1832:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1833:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1834:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1835:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1836:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1837:\ttotal: 2m 35s\tremaining: 4m 28s\n",
            "1838:\ttotal: 2m 36s\tremaining: 4m 28s\n",
            "1839:\ttotal: 2m 36s\tremaining: 4m 28s\n",
            "1840:\ttotal: 2m 36s\tremaining: 4m 28s\n",
            "1841:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1842:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1843:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1844:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1845:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1846:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1847:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1848:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1849:\ttotal: 2m 36s\tremaining: 4m 27s\n",
            "1850:\ttotal: 2m 37s\tremaining: 4m 27s\n",
            "1851:\ttotal: 2m 37s\tremaining: 4m 27s\n",
            "1852:\ttotal: 2m 37s\tremaining: 4m 27s\n",
            "1853:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1854:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1855:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1856:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1857:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1858:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1859:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1860:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1861:\ttotal: 2m 37s\tremaining: 4m 26s\n",
            "1862:\ttotal: 2m 38s\tremaining: 4m 26s\n",
            "1863:\ttotal: 2m 38s\tremaining: 4m 26s\n",
            "1864:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1865:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1866:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1867:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1868:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1869:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1870:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1871:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1872:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1873:\ttotal: 2m 38s\tremaining: 4m 25s\n",
            "1874:\ttotal: 2m 39s\tremaining: 4m 25s\n",
            "1875:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1876:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1877:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1878:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1879:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1880:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1881:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1882:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1883:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1884:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1885:\ttotal: 2m 39s\tremaining: 4m 24s\n",
            "1886:\ttotal: 2m 40s\tremaining: 4m 24s\n",
            "1887:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1888:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1889:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1890:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1891:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1892:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1893:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1894:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1895:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1896:\ttotal: 2m 40s\tremaining: 4m 23s\n",
            "1897:\ttotal: 2m 41s\tremaining: 4m 23s\n",
            "1898:\ttotal: 2m 41s\tremaining: 4m 23s\n",
            "1899:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1900:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1901:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1902:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1903:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1904:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1905:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1906:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1907:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1908:\ttotal: 2m 41s\tremaining: 4m 22s\n",
            "1909:\ttotal: 2m 42s\tremaining: 4m 22s\n",
            "1910:\ttotal: 2m 42s\tremaining: 4m 22s\n",
            "1911:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1912:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1913:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1914:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1915:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1916:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1917:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1918:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1919:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1920:\ttotal: 2m 42s\tremaining: 4m 21s\n",
            "1921:\ttotal: 2m 43s\tremaining: 4m 21s\n",
            "1922:\ttotal: 2m 43s\tremaining: 4m 21s\n",
            "1923:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1924:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1925:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1926:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1927:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1928:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1929:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1930:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1931:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1932:\ttotal: 2m 43s\tremaining: 4m 20s\n",
            "1933:\ttotal: 2m 44s\tremaining: 4m 20s\n",
            "1934:\ttotal: 2m 44s\tremaining: 4m 20s\n",
            "1935:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1936:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1937:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1938:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1939:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1940:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1941:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1942:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1943:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1944:\ttotal: 2m 44s\tremaining: 4m 19s\n",
            "1945:\ttotal: 2m 45s\tremaining: 4m 19s\n",
            "1946:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1947:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1948:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1949:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1950:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1951:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1952:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1953:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1954:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1955:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1956:\ttotal: 2m 45s\tremaining: 4m 18s\n",
            "1957:\ttotal: 2m 46s\tremaining: 4m 18s\n",
            "1958:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1959:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1960:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1961:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1962:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1963:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1964:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1965:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1966:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1967:\ttotal: 2m 46s\tremaining: 4m 17s\n",
            "1968:\ttotal: 2m 47s\tremaining: 4m 17s\n",
            "1969:\ttotal: 2m 47s\tremaining: 4m 17s\n",
            "1970:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1971:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1972:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1973:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1974:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1975:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1976:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1977:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1978:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1979:\ttotal: 2m 47s\tremaining: 4m 16s\n",
            "1980:\ttotal: 2m 48s\tremaining: 4m 16s\n",
            "1981:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1982:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1983:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1984:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1985:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1986:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1987:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1988:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1989:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1990:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1991:\ttotal: 2m 48s\tremaining: 4m 15s\n",
            "1992:\ttotal: 2m 49s\tremaining: 4m 15s\n",
            "1993:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1994:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1995:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1996:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1997:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1998:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "1999:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "2000:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "2001:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "2002:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "2003:\ttotal: 2m 49s\tremaining: 4m 14s\n",
            "2004:\ttotal: 2m 50s\tremaining: 4m 14s\n",
            "2005:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2006:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2007:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2008:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2009:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2010:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2011:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2012:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2013:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2014:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2015:\ttotal: 2m 50s\tremaining: 4m 13s\n",
            "2016:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2017:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2018:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2019:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2020:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2021:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2022:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2023:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2024:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2025:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2026:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2027:\ttotal: 2m 51s\tremaining: 4m 12s\n",
            "2028:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2029:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2030:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2031:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2032:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2033:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2034:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2035:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2036:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2037:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2038:\ttotal: 2m 52s\tremaining: 4m 11s\n",
            "2039:\ttotal: 2m 53s\tremaining: 4m 11s\n",
            "2040:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2041:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2042:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2043:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2044:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2045:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2046:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2047:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2048:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2049:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2050:\ttotal: 2m 53s\tremaining: 4m 10s\n",
            "2051:\ttotal: 2m 54s\tremaining: 4m 10s\n",
            "2052:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2053:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2054:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2055:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2056:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2057:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2058:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2059:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2060:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2061:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2062:\ttotal: 2m 54s\tremaining: 4m 9s\n",
            "2063:\ttotal: 2m 55s\tremaining: 4m 9s\n",
            "2064:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2065:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2066:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2067:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2068:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2069:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2070:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2071:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2072:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2073:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2074:\ttotal: 2m 55s\tremaining: 4m 8s\n",
            "2075:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2076:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2077:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2078:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2079:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2080:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2081:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2082:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2083:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2084:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2085:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2086:\ttotal: 2m 56s\tremaining: 4m 7s\n",
            "2087:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2088:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2089:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2090:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2091:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2092:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2093:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2094:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2095:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2096:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2097:\ttotal: 2m 57s\tremaining: 4m 6s\n",
            "2098:\ttotal: 2m 57s\tremaining: 4m 5s\n",
            "2099:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2100:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2101:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2102:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2103:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2104:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2105:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2106:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2107:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2108:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2109:\ttotal: 2m 58s\tremaining: 4m 5s\n",
            "2110:\ttotal: 2m 58s\tremaining: 4m 4s\n",
            "2111:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2112:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2113:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2114:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2115:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2116:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2117:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2118:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2119:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2120:\ttotal: 2m 59s\tremaining: 4m 4s\n",
            "2121:\ttotal: 2m 59s\tremaining: 4m 3s\n",
            "2122:\ttotal: 2m 59s\tremaining: 4m 3s\n",
            "2123:\ttotal: 3m\tremaining: 4m 3s\n",
            "2124:\ttotal: 3m\tremaining: 4m 3s\n",
            "2125:\ttotal: 3m\tremaining: 4m 3s\n",
            "2126:\ttotal: 3m\tremaining: 4m 3s\n",
            "2127:\ttotal: 3m\tremaining: 4m 3s\n",
            "2128:\ttotal: 3m\tremaining: 4m 3s\n",
            "2129:\ttotal: 3m\tremaining: 4m 3s\n",
            "2130:\ttotal: 3m\tremaining: 4m 3s\n",
            "2131:\ttotal: 3m\tremaining: 4m 3s\n",
            "2132:\ttotal: 3m\tremaining: 4m 3s\n",
            "2133:\ttotal: 3m\tremaining: 4m 2s\n",
            "2134:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2135:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2136:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2137:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2138:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2139:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2140:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2141:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2142:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2143:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2144:\ttotal: 3m 1s\tremaining: 4m 2s\n",
            "2145:\ttotal: 3m 1s\tremaining: 4m 1s\n",
            "2146:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2147:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2148:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2149:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2150:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2151:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2152:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2153:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2154:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2155:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2156:\ttotal: 3m 2s\tremaining: 4m 1s\n",
            "2157:\ttotal: 3m 2s\tremaining: 4m\n",
            "2158:\ttotal: 3m 3s\tremaining: 4m\n",
            "2159:\ttotal: 3m 3s\tremaining: 4m\n",
            "2160:\ttotal: 3m 3s\tremaining: 4m\n",
            "2161:\ttotal: 3m 3s\tremaining: 4m\n",
            "2162:\ttotal: 3m 3s\tremaining: 4m\n",
            "2163:\ttotal: 3m 3s\tremaining: 4m\n",
            "2164:\ttotal: 3m 3s\tremaining: 4m\n",
            "2165:\ttotal: 3m 3s\tremaining: 4m\n",
            "2166:\ttotal: 3m 3s\tremaining: 4m\n",
            "2167:\ttotal: 3m 3s\tremaining: 4m\n",
            "2168:\ttotal: 3m 3s\tremaining: 3m 59s\n",
            "2169:\ttotal: 3m 3s\tremaining: 3m 59s\n",
            "2170:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2171:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2172:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2173:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2174:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2175:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2176:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2177:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2178:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2179:\ttotal: 3m 4s\tremaining: 3m 59s\n",
            "2180:\ttotal: 3m 4s\tremaining: 3m 58s\n",
            "2181:\ttotal: 3m 4s\tremaining: 3m 58s\n",
            "2182:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2183:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2184:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2185:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2186:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2187:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2188:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2189:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2190:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2191:\ttotal: 3m 5s\tremaining: 3m 58s\n",
            "2192:\ttotal: 3m 5s\tremaining: 3m 57s\n",
            "2193:\ttotal: 3m 5s\tremaining: 3m 57s\n",
            "2194:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2195:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2196:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2197:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2198:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2199:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2200:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2201:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2202:\ttotal: 3m 6s\tremaining: 3m 57s\n",
            "2203:\ttotal: 3m 6s\tremaining: 3m 56s\n",
            "2204:\ttotal: 3m 6s\tremaining: 3m 56s\n",
            "2205:\ttotal: 3m 6s\tremaining: 3m 56s\n",
            "2206:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2207:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2208:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2209:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2210:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2211:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2212:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2213:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2214:\ttotal: 3m 7s\tremaining: 3m 56s\n",
            "2215:\ttotal: 3m 7s\tremaining: 3m 55s\n",
            "2216:\ttotal: 3m 7s\tremaining: 3m 55s\n",
            "2217:\ttotal: 3m 7s\tremaining: 3m 55s\n",
            "2218:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2219:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2220:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2221:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2222:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2223:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2224:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2225:\ttotal: 3m 8s\tremaining: 3m 55s\n",
            "2226:\ttotal: 3m 8s\tremaining: 3m 54s\n",
            "2227:\ttotal: 3m 8s\tremaining: 3m 54s\n",
            "2228:\ttotal: 3m 8s\tremaining: 3m 54s\n",
            "2229:\ttotal: 3m 8s\tremaining: 3m 54s\n",
            "2230:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2231:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2232:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2233:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2234:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2235:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2236:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2237:\ttotal: 3m 9s\tremaining: 3m 54s\n",
            "2238:\ttotal: 3m 9s\tremaining: 3m 53s\n",
            "2239:\ttotal: 3m 9s\tremaining: 3m 53s\n",
            "2240:\ttotal: 3m 9s\tremaining: 3m 53s\n",
            "2241:\ttotal: 3m 9s\tremaining: 3m 53s\n",
            "2242:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2243:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2244:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2245:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2246:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2247:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2248:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2249:\ttotal: 3m 10s\tremaining: 3m 53s\n",
            "2250:\ttotal: 3m 10s\tremaining: 3m 52s\n",
            "2251:\ttotal: 3m 10s\tremaining: 3m 52s\n",
            "2252:\ttotal: 3m 10s\tremaining: 3m 52s\n",
            "2253:\ttotal: 3m 10s\tremaining: 3m 52s\n",
            "2254:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2255:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2256:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2257:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2258:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2259:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2260:\ttotal: 3m 11s\tremaining: 3m 52s\n",
            "2261:\ttotal: 3m 11s\tremaining: 3m 51s\n",
            "2262:\ttotal: 3m 11s\tremaining: 3m 51s\n",
            "2263:\ttotal: 3m 11s\tremaining: 3m 51s\n",
            "2264:\ttotal: 3m 11s\tremaining: 3m 51s\n",
            "2265:\ttotal: 3m 11s\tremaining: 3m 51s\n",
            "2266:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2267:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2268:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2269:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2270:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2271:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2272:\ttotal: 3m 12s\tremaining: 3m 51s\n",
            "2273:\ttotal: 3m 12s\tremaining: 3m 50s\n",
            "2274:\ttotal: 3m 12s\tremaining: 3m 50s\n",
            "2275:\ttotal: 3m 12s\tremaining: 3m 50s\n",
            "2276:\ttotal: 3m 12s\tremaining: 3m 50s\n",
            "2277:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2278:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2279:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2280:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2281:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2282:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2283:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2284:\ttotal: 3m 13s\tremaining: 3m 50s\n",
            "2285:\ttotal: 3m 13s\tremaining: 3m 49s\n",
            "2286:\ttotal: 3m 13s\tremaining: 3m 49s\n",
            "2287:\ttotal: 3m 13s\tremaining: 3m 49s\n",
            "2288:\ttotal: 3m 13s\tremaining: 3m 49s\n",
            "2289:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2290:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2291:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2292:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2293:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2294:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2295:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2296:\ttotal: 3m 14s\tremaining: 3m 49s\n",
            "2297:\ttotal: 3m 14s\tremaining: 3m 48s\n",
            "2298:\ttotal: 3m 14s\tremaining: 3m 48s\n",
            "2299:\ttotal: 3m 14s\tremaining: 3m 48s\n",
            "2300:\ttotal: 3m 14s\tremaining: 3m 48s\n",
            "2301:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2302:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2303:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2304:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2305:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2306:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2307:\ttotal: 3m 15s\tremaining: 3m 48s\n",
            "2308:\ttotal: 3m 15s\tremaining: 3m 47s\n",
            "2309:\ttotal: 3m 15s\tremaining: 3m 47s\n",
            "2310:\ttotal: 3m 15s\tremaining: 3m 47s\n",
            "2311:\ttotal: 3m 15s\tremaining: 3m 47s\n",
            "2312:\ttotal: 3m 15s\tremaining: 3m 47s\n",
            "2313:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2314:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2315:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2316:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2317:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2318:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2319:\ttotal: 3m 16s\tremaining: 3m 47s\n",
            "2320:\ttotal: 3m 16s\tremaining: 3m 46s\n",
            "2321:\ttotal: 3m 16s\tremaining: 3m 46s\n",
            "2322:\ttotal: 3m 16s\tremaining: 3m 46s\n",
            "2323:\ttotal: 3m 16s\tremaining: 3m 46s\n",
            "2324:\ttotal: 3m 16s\tremaining: 3m 46s\n",
            "2325:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2326:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2327:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2328:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2329:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2330:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2331:\ttotal: 3m 17s\tremaining: 3m 46s\n",
            "2332:\ttotal: 3m 17s\tremaining: 3m 45s\n",
            "2333:\ttotal: 3m 17s\tremaining: 3m 45s\n",
            "2334:\ttotal: 3m 17s\tremaining: 3m 45s\n",
            "2335:\ttotal: 3m 17s\tremaining: 3m 45s\n",
            "2336:\ttotal: 3m 17s\tremaining: 3m 45s\n",
            "2337:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2338:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2339:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2340:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2341:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2342:\ttotal: 3m 18s\tremaining: 3m 45s\n",
            "2343:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2344:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2345:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2346:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2347:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2348:\ttotal: 3m 18s\tremaining: 3m 44s\n",
            "2349:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2350:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2351:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2352:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2353:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2354:\ttotal: 3m 19s\tremaining: 3m 44s\n",
            "2355:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2356:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2357:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2358:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2359:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2360:\ttotal: 3m 19s\tremaining: 3m 43s\n",
            "2361:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2362:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2363:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2364:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2365:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2366:\ttotal: 3m 20s\tremaining: 3m 43s\n",
            "2367:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2368:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2369:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2370:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2371:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2372:\ttotal: 3m 20s\tremaining: 3m 42s\n",
            "2373:\ttotal: 3m 21s\tremaining: 3m 42s\n",
            "2374:\ttotal: 3m 21s\tremaining: 3m 42s\n",
            "2375:\ttotal: 3m 21s\tremaining: 3m 42s\n",
            "2376:\ttotal: 3m 21s\tremaining: 3m 42s\n",
            "2377:\ttotal: 3m 21s\tremaining: 3m 42s\n",
            "2378:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2379:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2380:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2381:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2382:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2383:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2384:\ttotal: 3m 21s\tremaining: 3m 41s\n",
            "2385:\ttotal: 3m 22s\tremaining: 3m 41s\n",
            "2386:\ttotal: 3m 22s\tremaining: 3m 41s\n",
            "2387:\ttotal: 3m 22s\tremaining: 3m 41s\n",
            "2388:\ttotal: 3m 22s\tremaining: 3m 41s\n",
            "2389:\ttotal: 3m 22s\tremaining: 3m 41s\n",
            "2390:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2391:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2392:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2393:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2394:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2395:\ttotal: 3m 22s\tremaining: 3m 40s\n",
            "2396:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2397:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2398:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2399:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2400:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2401:\ttotal: 3m 23s\tremaining: 3m 40s\n",
            "2402:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2403:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2404:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2405:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2406:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2407:\ttotal: 3m 23s\tremaining: 3m 39s\n",
            "2408:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2409:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2410:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2411:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2412:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2413:\ttotal: 3m 24s\tremaining: 3m 39s\n",
            "2414:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2415:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2416:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2417:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2418:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2419:\ttotal: 3m 24s\tremaining: 3m 38s\n",
            "2420:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2421:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2422:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2423:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2424:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2425:\ttotal: 3m 25s\tremaining: 3m 38s\n",
            "2426:\ttotal: 3m 25s\tremaining: 3m 37s\n",
            "2427:\ttotal: 3m 25s\tremaining: 3m 37s\n",
            "2428:\ttotal: 3m 25s\tremaining: 3m 37s\n",
            "2429:\ttotal: 3m 25s\tremaining: 3m 37s\n",
            "2430:\ttotal: 3m 25s\tremaining: 3m 37s\n",
            "2431:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2432:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2433:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2434:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2435:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2436:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2437:\ttotal: 3m 26s\tremaining: 3m 37s\n",
            "2438:\ttotal: 3m 26s\tremaining: 3m 36s\n",
            "2439:\ttotal: 3m 26s\tremaining: 3m 36s\n",
            "2440:\ttotal: 3m 26s\tremaining: 3m 36s\n",
            "2441:\ttotal: 3m 26s\tremaining: 3m 36s\n",
            "2442:\ttotal: 3m 26s\tremaining: 3m 36s\n",
            "2443:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2444:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2445:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2446:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2447:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2448:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2449:\ttotal: 3m 27s\tremaining: 3m 36s\n",
            "2450:\ttotal: 3m 27s\tremaining: 3m 35s\n",
            "2451:\ttotal: 3m 27s\tremaining: 3m 35s\n",
            "2452:\ttotal: 3m 27s\tremaining: 3m 35s\n",
            "2453:\ttotal: 3m 27s\tremaining: 3m 35s\n",
            "2454:\ttotal: 3m 27s\tremaining: 3m 35s\n",
            "2455:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2456:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2457:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2458:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2459:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2460:\ttotal: 3m 28s\tremaining: 3m 35s\n",
            "2461:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2462:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2463:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2464:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2465:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2466:\ttotal: 3m 28s\tremaining: 3m 34s\n",
            "2467:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2468:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2469:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2470:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2471:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2472:\ttotal: 3m 29s\tremaining: 3m 34s\n",
            "2473:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2474:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2475:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2476:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2477:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2478:\ttotal: 3m 29s\tremaining: 3m 33s\n",
            "2479:\ttotal: 3m 30s\tremaining: 3m 33s\n",
            "2480:\ttotal: 3m 30s\tremaining: 3m 33s\n",
            "2481:\ttotal: 3m 30s\tremaining: 3m 33s\n",
            "2482:\ttotal: 3m 30s\tremaining: 3m 33s\n",
            "2483:\ttotal: 3m 30s\tremaining: 3m 33s\n",
            "2484:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2485:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2486:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2487:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2488:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2489:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2490:\ttotal: 3m 30s\tremaining: 3m 32s\n",
            "2491:\ttotal: 3m 31s\tremaining: 3m 32s\n",
            "2492:\ttotal: 3m 31s\tremaining: 3m 32s\n",
            "2493:\ttotal: 3m 31s\tremaining: 3m 32s\n",
            "2494:\ttotal: 3m 31s\tremaining: 3m 32s\n",
            "2495:\ttotal: 3m 31s\tremaining: 3m 32s\n",
            "2496:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2497:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2498:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2499:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2500:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2501:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2502:\ttotal: 3m 31s\tremaining: 3m 31s\n",
            "2503:\ttotal: 3m 32s\tremaining: 3m 31s\n",
            "2504:\ttotal: 3m 32s\tremaining: 3m 31s\n",
            "2505:\ttotal: 3m 32s\tremaining: 3m 31s\n",
            "2506:\ttotal: 3m 32s\tremaining: 3m 31s\n",
            "2507:\ttotal: 3m 32s\tremaining: 3m 31s\n",
            "2508:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2509:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2510:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2511:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2512:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2513:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2514:\ttotal: 3m 32s\tremaining: 3m 30s\n",
            "2515:\ttotal: 3m 33s\tremaining: 3m 30s\n",
            "2516:\ttotal: 3m 33s\tremaining: 3m 30s\n",
            "2517:\ttotal: 3m 33s\tremaining: 3m 30s\n",
            "2518:\ttotal: 3m 33s\tremaining: 3m 30s\n",
            "2519:\ttotal: 3m 33s\tremaining: 3m 30s\n",
            "2520:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2521:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2522:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2523:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2524:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2525:\ttotal: 3m 33s\tremaining: 3m 29s\n",
            "2526:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2527:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2528:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2529:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2530:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2531:\ttotal: 3m 34s\tremaining: 3m 29s\n",
            "2532:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2533:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2534:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2535:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2536:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2537:\ttotal: 3m 34s\tremaining: 3m 28s\n",
            "2538:\ttotal: 3m 35s\tremaining: 3m 28s\n",
            "2539:\ttotal: 3m 35s\tremaining: 3m 28s\n",
            "2540:\ttotal: 3m 35s\tremaining: 3m 28s\n",
            "2541:\ttotal: 3m 35s\tremaining: 3m 28s\n",
            "2542:\ttotal: 3m 35s\tremaining: 3m 28s\n",
            "2543:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2544:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2545:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2546:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2547:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2548:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2549:\ttotal: 3m 35s\tremaining: 3m 27s\n",
            "2550:\ttotal: 3m 36s\tremaining: 3m 27s\n",
            "2551:\ttotal: 3m 36s\tremaining: 3m 27s\n",
            "2552:\ttotal: 3m 36s\tremaining: 3m 27s\n",
            "2553:\ttotal: 3m 36s\tremaining: 3m 27s\n",
            "2554:\ttotal: 3m 36s\tremaining: 3m 27s\n",
            "2555:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2556:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2557:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2558:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2559:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2560:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2561:\ttotal: 3m 36s\tremaining: 3m 26s\n",
            "2562:\ttotal: 3m 37s\tremaining: 3m 26s\n",
            "2563:\ttotal: 3m 37s\tremaining: 3m 26s\n",
            "2564:\ttotal: 3m 37s\tremaining: 3m 26s\n",
            "2565:\ttotal: 3m 37s\tremaining: 3m 26s\n",
            "2566:\ttotal: 3m 37s\tremaining: 3m 26s\n",
            "2567:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2568:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2569:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2570:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2571:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2572:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2573:\ttotal: 3m 37s\tremaining: 3m 25s\n",
            "2574:\ttotal: 3m 38s\tremaining: 3m 25s\n",
            "2575:\ttotal: 3m 38s\tremaining: 3m 25s\n",
            "2576:\ttotal: 3m 38s\tremaining: 3m 25s\n",
            "2577:\ttotal: 3m 38s\tremaining: 3m 25s\n",
            "2578:\ttotal: 3m 38s\tremaining: 3m 25s\n",
            "2579:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2580:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2581:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2582:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2583:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2584:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2585:\ttotal: 3m 38s\tremaining: 3m 24s\n",
            "2586:\ttotal: 3m 39s\tremaining: 3m 24s\n",
            "2587:\ttotal: 3m 39s\tremaining: 3m 24s\n",
            "2588:\ttotal: 3m 39s\tremaining: 3m 24s\n",
            "2589:\ttotal: 3m 39s\tremaining: 3m 24s\n",
            "2590:\ttotal: 3m 39s\tremaining: 3m 24s\n",
            "2591:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2592:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2593:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2594:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2595:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2596:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2597:\ttotal: 3m 39s\tremaining: 3m 23s\n",
            "2598:\ttotal: 3m 40s\tremaining: 3m 23s\n",
            "2599:\ttotal: 3m 40s\tremaining: 3m 23s\n",
            "2600:\ttotal: 3m 40s\tremaining: 3m 23s\n",
            "2601:\ttotal: 3m 40s\tremaining: 3m 23s\n",
            "2602:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2603:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2604:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2605:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2606:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2607:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2608:\ttotal: 3m 40s\tremaining: 3m 22s\n",
            "2609:\ttotal: 3m 41s\tremaining: 3m 22s\n",
            "2610:\ttotal: 3m 41s\tremaining: 3m 22s\n",
            "2611:\ttotal: 3m 41s\tremaining: 3m 22s\n",
            "2612:\ttotal: 3m 41s\tremaining: 3m 22s\n",
            "2613:\ttotal: 3m 41s\tremaining: 3m 22s\n",
            "2614:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2615:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2616:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2617:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2618:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2619:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2620:\ttotal: 3m 41s\tremaining: 3m 21s\n",
            "2621:\ttotal: 3m 42s\tremaining: 3m 21s\n",
            "2622:\ttotal: 3m 42s\tremaining: 3m 21s\n",
            "2623:\ttotal: 3m 42s\tremaining: 3m 21s\n",
            "2624:\ttotal: 3m 42s\tremaining: 3m 21s\n",
            "2625:\ttotal: 3m 42s\tremaining: 3m 21s\n",
            "2626:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2627:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2628:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2629:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2630:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2631:\ttotal: 3m 42s\tremaining: 3m 20s\n",
            "2632:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2633:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2634:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2635:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2636:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2637:\ttotal: 3m 43s\tremaining: 3m 20s\n",
            "2638:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2639:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2640:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2641:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2642:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2643:\ttotal: 3m 43s\tremaining: 3m 19s\n",
            "2644:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2645:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2646:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2647:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2648:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2649:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2650:\ttotal: 3m 44s\tremaining: 3m 19s\n",
            "2651:\ttotal: 3m 44s\tremaining: 3m 18s\n",
            "2652:\ttotal: 3m 44s\tremaining: 3m 18s\n",
            "2653:\ttotal: 3m 44s\tremaining: 3m 18s\n",
            "2654:\ttotal: 3m 44s\tremaining: 3m 18s\n",
            "2655:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2656:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2657:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2658:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2659:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2660:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2661:\ttotal: 3m 45s\tremaining: 3m 18s\n",
            "2662:\ttotal: 3m 45s\tremaining: 3m 17s\n",
            "2663:\ttotal: 3m 45s\tremaining: 3m 17s\n",
            "2664:\ttotal: 3m 45s\tremaining: 3m 17s\n",
            "2665:\ttotal: 3m 45s\tremaining: 3m 17s\n",
            "2666:\ttotal: 3m 45s\tremaining: 3m 17s\n",
            "2667:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2668:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2669:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2670:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2671:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2672:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2673:\ttotal: 3m 46s\tremaining: 3m 17s\n",
            "2674:\ttotal: 3m 46s\tremaining: 3m 16s\n",
            "2675:\ttotal: 3m 46s\tremaining: 3m 16s\n",
            "2676:\ttotal: 3m 46s\tremaining: 3m 16s\n",
            "2677:\ttotal: 3m 46s\tremaining: 3m 16s\n",
            "2678:\ttotal: 3m 46s\tremaining: 3m 16s\n",
            "2679:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2680:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2681:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2682:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2683:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2684:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2685:\ttotal: 3m 47s\tremaining: 3m 16s\n",
            "2686:\ttotal: 3m 47s\tremaining: 3m 15s\n",
            "2687:\ttotal: 3m 47s\tremaining: 3m 15s\n",
            "2688:\ttotal: 3m 47s\tremaining: 3m 15s\n",
            "2689:\ttotal: 3m 47s\tremaining: 3m 15s\n",
            "2690:\ttotal: 3m 47s\tremaining: 3m 15s\n",
            "2691:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2692:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2693:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2694:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2695:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2696:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2697:\ttotal: 3m 48s\tremaining: 3m 15s\n",
            "2698:\ttotal: 3m 48s\tremaining: 3m 14s\n",
            "2699:\ttotal: 3m 48s\tremaining: 3m 14s\n",
            "2700:\ttotal: 3m 48s\tremaining: 3m 14s\n",
            "2701:\ttotal: 3m 48s\tremaining: 3m 14s\n",
            "2702:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2703:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2704:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2705:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2706:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2707:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2708:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2709:\ttotal: 3m 49s\tremaining: 3m 14s\n",
            "2710:\ttotal: 3m 49s\tremaining: 3m 13s\n",
            "2711:\ttotal: 3m 49s\tremaining: 3m 13s\n",
            "2712:\ttotal: 3m 49s\tremaining: 3m 13s\n",
            "2713:\ttotal: 3m 49s\tremaining: 3m 13s\n",
            "2714:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2715:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2716:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2717:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2718:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2719:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2720:\ttotal: 3m 50s\tremaining: 3m 13s\n",
            "2721:\ttotal: 3m 50s\tremaining: 3m 12s\n",
            "2722:\ttotal: 3m 50s\tremaining: 3m 12s\n",
            "2723:\ttotal: 3m 50s\tremaining: 3m 12s\n",
            "2724:\ttotal: 3m 50s\tremaining: 3m 12s\n",
            "2725:\ttotal: 3m 50s\tremaining: 3m 12s\n",
            "2726:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2727:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2728:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2729:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2730:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2731:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2732:\ttotal: 3m 51s\tremaining: 3m 12s\n",
            "2733:\ttotal: 3m 51s\tremaining: 3m 11s\n",
            "2734:\ttotal: 3m 51s\tremaining: 3m 11s\n",
            "2735:\ttotal: 3m 51s\tremaining: 3m 11s\n",
            "2736:\ttotal: 3m 51s\tremaining: 3m 11s\n",
            "2737:\ttotal: 3m 51s\tremaining: 3m 11s\n",
            "2738:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2739:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2740:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2741:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2742:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2743:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2744:\ttotal: 3m 52s\tremaining: 3m 11s\n",
            "2745:\ttotal: 3m 52s\tremaining: 3m 10s\n",
            "2746:\ttotal: 3m 52s\tremaining: 3m 10s\n",
            "2747:\ttotal: 3m 52s\tremaining: 3m 10s\n",
            "2748:\ttotal: 3m 52s\tremaining: 3m 10s\n",
            "2749:\ttotal: 3m 52s\tremaining: 3m 10s\n",
            "2750:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2751:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2752:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2753:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2754:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2755:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2756:\ttotal: 3m 53s\tremaining: 3m 10s\n",
            "2757:\ttotal: 3m 53s\tremaining: 3m 9s\n",
            "2758:\ttotal: 3m 53s\tremaining: 3m 9s\n",
            "2759:\ttotal: 3m 53s\tremaining: 3m 9s\n",
            "2760:\ttotal: 3m 53s\tremaining: 3m 9s\n",
            "2761:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2762:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2763:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2764:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2765:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2766:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2767:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2768:\ttotal: 3m 54s\tremaining: 3m 9s\n",
            "2769:\ttotal: 3m 54s\tremaining: 3m 8s\n",
            "2770:\ttotal: 3m 54s\tremaining: 3m 8s\n",
            "2771:\ttotal: 3m 54s\tremaining: 3m 8s\n",
            "2772:\ttotal: 3m 54s\tremaining: 3m 8s\n",
            "2773:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2774:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2775:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2776:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2777:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2778:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2779:\ttotal: 3m 55s\tremaining: 3m 8s\n",
            "2780:\ttotal: 3m 55s\tremaining: 3m 7s\n",
            "2781:\ttotal: 3m 55s\tremaining: 3m 7s\n",
            "2782:\ttotal: 3m 55s\tremaining: 3m 7s\n",
            "2783:\ttotal: 3m 55s\tremaining: 3m 7s\n",
            "2784:\ttotal: 3m 55s\tremaining: 3m 7s\n",
            "2785:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2786:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2787:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2788:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2789:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2790:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2791:\ttotal: 3m 56s\tremaining: 3m 7s\n",
            "2792:\ttotal: 3m 56s\tremaining: 3m 6s\n",
            "2793:\ttotal: 3m 56s\tremaining: 3m 6s\n",
            "2794:\ttotal: 3m 56s\tremaining: 3m 6s\n",
            "2795:\ttotal: 3m 56s\tremaining: 3m 6s\n",
            "2796:\ttotal: 3m 56s\tremaining: 3m 6s\n",
            "2797:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2798:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2799:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2800:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2801:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2802:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2803:\ttotal: 3m 57s\tremaining: 3m 6s\n",
            "2804:\ttotal: 3m 57s\tremaining: 3m 5s\n",
            "2805:\ttotal: 3m 57s\tremaining: 3m 5s\n",
            "2806:\ttotal: 3m 57s\tremaining: 3m 5s\n",
            "2807:\ttotal: 3m 57s\tremaining: 3m 5s\n",
            "2808:\ttotal: 3m 57s\tremaining: 3m 5s\n",
            "2809:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2810:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2811:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2812:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2813:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2814:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2815:\ttotal: 3m 58s\tremaining: 3m 5s\n",
            "2816:\ttotal: 3m 58s\tremaining: 3m 4s\n",
            "2817:\ttotal: 3m 58s\tremaining: 3m 4s\n",
            "2818:\ttotal: 3m 58s\tremaining: 3m 4s\n",
            "2819:\ttotal: 3m 58s\tremaining: 3m 4s\n",
            "2820:\ttotal: 3m 58s\tremaining: 3m 4s\n",
            "2821:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2822:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2823:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2824:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2825:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2826:\ttotal: 3m 59s\tremaining: 3m 4s\n",
            "2827:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2828:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2829:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2830:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2831:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2832:\ttotal: 3m 59s\tremaining: 3m 3s\n",
            "2833:\ttotal: 4m\tremaining: 3m 3s\n",
            "2834:\ttotal: 4m\tremaining: 3m 3s\n",
            "2835:\ttotal: 4m\tremaining: 3m 3s\n",
            "2836:\ttotal: 4m\tremaining: 3m 3s\n",
            "2837:\ttotal: 4m\tremaining: 3m 3s\n",
            "2838:\ttotal: 4m\tremaining: 3m 3s\n",
            "2839:\ttotal: 4m\tremaining: 3m 2s\n",
            "2840:\ttotal: 4m\tremaining: 3m 2s\n",
            "2841:\ttotal: 4m\tremaining: 3m 2s\n",
            "2842:\ttotal: 4m\tremaining: 3m 2s\n",
            "2843:\ttotal: 4m\tremaining: 3m 2s\n",
            "2844:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2845:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2846:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2847:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2848:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2849:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2850:\ttotal: 4m 1s\tremaining: 3m 2s\n",
            "2851:\ttotal: 4m 1s\tremaining: 3m 1s\n",
            "2852:\ttotal: 4m 1s\tremaining: 3m 1s\n",
            "2853:\ttotal: 4m 1s\tremaining: 3m 1s\n",
            "2854:\ttotal: 4m 1s\tremaining: 3m 1s\n",
            "2855:\ttotal: 4m 1s\tremaining: 3m 1s\n",
            "2856:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2857:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2858:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2859:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2860:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2861:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2862:\ttotal: 4m 2s\tremaining: 3m 1s\n",
            "2863:\ttotal: 4m 2s\tremaining: 3m\n",
            "2864:\ttotal: 4m 2s\tremaining: 3m\n",
            "2865:\ttotal: 4m 2s\tremaining: 3m\n",
            "2866:\ttotal: 4m 2s\tremaining: 3m\n",
            "2867:\ttotal: 4m 2s\tremaining: 3m\n",
            "2868:\ttotal: 4m 3s\tremaining: 3m\n",
            "2869:\ttotal: 4m 3s\tremaining: 3m\n",
            "2870:\ttotal: 4m 3s\tremaining: 3m\n",
            "2871:\ttotal: 4m 3s\tremaining: 3m\n",
            "2872:\ttotal: 4m 3s\tremaining: 3m\n",
            "2873:\ttotal: 4m 3s\tremaining: 3m\n",
            "2874:\ttotal: 4m 3s\tremaining: 3m\n",
            "2875:\ttotal: 4m 3s\tremaining: 2m 59s\n",
            "2876:\ttotal: 4m 3s\tremaining: 2m 59s\n",
            "2877:\ttotal: 4m 3s\tremaining: 2m 59s\n",
            "2878:\ttotal: 4m 3s\tremaining: 2m 59s\n",
            "2879:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2880:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2881:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2882:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2883:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2884:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2885:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2886:\ttotal: 4m 4s\tremaining: 2m 59s\n",
            "2887:\ttotal: 4m 4s\tremaining: 2m 58s\n",
            "2888:\ttotal: 4m 4s\tremaining: 2m 58s\n",
            "2889:\ttotal: 4m 4s\tremaining: 2m 58s\n",
            "2890:\ttotal: 4m 4s\tremaining: 2m 58s\n",
            "2891:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2892:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2893:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2894:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2895:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2896:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2897:\ttotal: 4m 5s\tremaining: 2m 58s\n",
            "2898:\ttotal: 4m 5s\tremaining: 2m 57s\n",
            "2899:\ttotal: 4m 5s\tremaining: 2m 57s\n",
            "2900:\ttotal: 4m 5s\tremaining: 2m 57s\n",
            "2901:\ttotal: 4m 5s\tremaining: 2m 57s\n",
            "2902:\ttotal: 4m 5s\tremaining: 2m 57s\n",
            "2903:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2904:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2905:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2906:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2907:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2908:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2909:\ttotal: 4m 6s\tremaining: 2m 57s\n",
            "2910:\ttotal: 4m 6s\tremaining: 2m 56s\n",
            "2911:\ttotal: 4m 6s\tremaining: 2m 56s\n",
            "2912:\ttotal: 4m 6s\tremaining: 2m 56s\n",
            "2913:\ttotal: 4m 6s\tremaining: 2m 56s\n",
            "2914:\ttotal: 4m 6s\tremaining: 2m 56s\n",
            "2915:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2916:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2917:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2918:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2919:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2920:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2921:\ttotal: 4m 7s\tremaining: 2m 56s\n",
            "2922:\ttotal: 4m 7s\tremaining: 2m 55s\n",
            "2923:\ttotal: 4m 7s\tremaining: 2m 55s\n",
            "2924:\ttotal: 4m 7s\tremaining: 2m 55s\n",
            "2925:\ttotal: 4m 7s\tremaining: 2m 55s\n",
            "2926:\ttotal: 4m 7s\tremaining: 2m 55s\n",
            "2927:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2928:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2929:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2930:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2931:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2932:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2933:\ttotal: 4m 8s\tremaining: 2m 55s\n",
            "2934:\ttotal: 4m 8s\tremaining: 2m 54s\n",
            "2935:\ttotal: 4m 8s\tremaining: 2m 54s\n",
            "2936:\ttotal: 4m 8s\tremaining: 2m 54s\n",
            "2937:\ttotal: 4m 8s\tremaining: 2m 54s\n",
            "2938:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2939:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2940:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2941:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2942:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2943:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2944:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2945:\ttotal: 4m 9s\tremaining: 2m 54s\n",
            "2946:\ttotal: 4m 9s\tremaining: 2m 53s\n",
            "2947:\ttotal: 4m 9s\tremaining: 2m 53s\n",
            "2948:\ttotal: 4m 9s\tremaining: 2m 53s\n",
            "2949:\ttotal: 4m 9s\tremaining: 2m 53s\n",
            "2950:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2951:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2952:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2953:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2954:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2955:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2956:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2957:\ttotal: 4m 10s\tremaining: 2m 53s\n",
            "2958:\ttotal: 4m 10s\tremaining: 2m 52s\n",
            "2959:\ttotal: 4m 10s\tremaining: 2m 52s\n",
            "2960:\ttotal: 4m 10s\tremaining: 2m 52s\n",
            "2961:\ttotal: 4m 10s\tremaining: 2m 52s\n",
            "2962:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2963:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2964:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2965:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2966:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2967:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2968:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2969:\ttotal: 4m 11s\tremaining: 2m 52s\n",
            "2970:\ttotal: 4m 11s\tremaining: 2m 51s\n",
            "2971:\ttotal: 4m 11s\tremaining: 2m 51s\n",
            "2972:\ttotal: 4m 11s\tremaining: 2m 51s\n",
            "2973:\ttotal: 4m 11s\tremaining: 2m 51s\n",
            "2974:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2975:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2976:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2977:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2978:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2979:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2980:\ttotal: 4m 12s\tremaining: 2m 51s\n",
            "2981:\ttotal: 4m 12s\tremaining: 2m 50s\n",
            "2982:\ttotal: 4m 12s\tremaining: 2m 50s\n",
            "2983:\ttotal: 4m 12s\tremaining: 2m 50s\n",
            "2984:\ttotal: 4m 12s\tremaining: 2m 50s\n",
            "2985:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2986:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2987:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2988:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2989:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2990:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2991:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2992:\ttotal: 4m 13s\tremaining: 2m 50s\n",
            "2993:\ttotal: 4m 13s\tremaining: 2m 49s\n",
            "2994:\ttotal: 4m 13s\tremaining: 2m 49s\n",
            "2995:\ttotal: 4m 13s\tremaining: 2m 49s\n",
            "2996:\ttotal: 4m 13s\tremaining: 2m 49s\n",
            "2997:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "2998:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "2999:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3000:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3001:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3002:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3003:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3004:\ttotal: 4m 14s\tremaining: 2m 49s\n",
            "3005:\ttotal: 4m 14s\tremaining: 2m 48s\n",
            "3006:\ttotal: 4m 14s\tremaining: 2m 48s\n",
            "3007:\ttotal: 4m 14s\tremaining: 2m 48s\n",
            "3008:\ttotal: 4m 14s\tremaining: 2m 48s\n",
            "3009:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3010:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3011:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3012:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3013:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3014:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3015:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3016:\ttotal: 4m 15s\tremaining: 2m 48s\n",
            "3017:\ttotal: 4m 15s\tremaining: 2m 47s\n",
            "3018:\ttotal: 4m 15s\tremaining: 2m 47s\n",
            "3019:\ttotal: 4m 15s\tremaining: 2m 47s\n",
            "3020:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3021:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3022:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3023:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3024:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3025:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3026:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3027:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3028:\ttotal: 4m 16s\tremaining: 2m 47s\n",
            "3029:\ttotal: 4m 16s\tremaining: 2m 46s\n",
            "3030:\ttotal: 4m 16s\tremaining: 2m 46s\n",
            "3031:\ttotal: 4m 16s\tremaining: 2m 46s\n",
            "3032:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3033:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3034:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3035:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3036:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3037:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3038:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3039:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3040:\ttotal: 4m 17s\tremaining: 2m 46s\n",
            "3041:\ttotal: 4m 17s\tremaining: 2m 45s\n",
            "3042:\ttotal: 4m 17s\tremaining: 2m 45s\n",
            "3043:\ttotal: 4m 17s\tremaining: 2m 45s\n",
            "3044:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3045:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3046:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3047:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3048:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3049:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3050:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3051:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3052:\ttotal: 4m 18s\tremaining: 2m 45s\n",
            "3053:\ttotal: 4m 18s\tremaining: 2m 44s\n",
            "3054:\ttotal: 4m 18s\tremaining: 2m 44s\n",
            "3055:\ttotal: 4m 18s\tremaining: 2m 44s\n",
            "3056:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3057:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3058:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3059:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3060:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3061:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3062:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3063:\ttotal: 4m 19s\tremaining: 2m 44s\n",
            "3064:\ttotal: 4m 19s\tremaining: 2m 43s\n",
            "3065:\ttotal: 4m 19s\tremaining: 2m 43s\n",
            "3066:\ttotal: 4m 19s\tremaining: 2m 43s\n",
            "3067:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3068:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3069:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3070:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3071:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3072:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3073:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3074:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3075:\ttotal: 4m 20s\tremaining: 2m 43s\n",
            "3076:\ttotal: 4m 20s\tremaining: 2m 42s\n",
            "3077:\ttotal: 4m 20s\tremaining: 2m 42s\n",
            "3078:\ttotal: 4m 20s\tremaining: 2m 42s\n",
            "3079:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3080:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3081:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3082:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3083:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3084:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3085:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3086:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3087:\ttotal: 4m 21s\tremaining: 2m 42s\n",
            "3088:\ttotal: 4m 21s\tremaining: 2m 41s\n",
            "3089:\ttotal: 4m 21s\tremaining: 2m 41s\n",
            "3090:\ttotal: 4m 21s\tremaining: 2m 41s\n",
            "3091:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3092:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3093:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3094:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3095:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3096:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3097:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3098:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3099:\ttotal: 4m 22s\tremaining: 2m 41s\n",
            "3100:\ttotal: 4m 22s\tremaining: 2m 40s\n",
            "3101:\ttotal: 4m 22s\tremaining: 2m 40s\n",
            "3102:\ttotal: 4m 22s\tremaining: 2m 40s\n",
            "3103:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3104:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3105:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3106:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3107:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3108:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3109:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3110:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3111:\ttotal: 4m 23s\tremaining: 2m 40s\n",
            "3112:\ttotal: 4m 23s\tremaining: 2m 39s\n",
            "3113:\ttotal: 4m 23s\tremaining: 2m 39s\n",
            "3114:\ttotal: 4m 23s\tremaining: 2m 39s\n",
            "3115:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3116:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3117:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3118:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3119:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3120:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3121:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3122:\ttotal: 4m 24s\tremaining: 2m 39s\n",
            "3123:\ttotal: 4m 24s\tremaining: 2m 38s\n",
            "3124:\ttotal: 4m 24s\tremaining: 2m 38s\n",
            "3125:\ttotal: 4m 24s\tremaining: 2m 38s\n",
            "3126:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3127:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3128:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3129:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3130:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3131:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3132:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3133:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3134:\ttotal: 4m 25s\tremaining: 2m 38s\n",
            "3135:\ttotal: 4m 25s\tremaining: 2m 37s\n",
            "3136:\ttotal: 4m 25s\tremaining: 2m 37s\n",
            "3137:\ttotal: 4m 25s\tremaining: 2m 37s\n",
            "3138:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3139:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3140:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3141:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3142:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3143:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3144:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3145:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3146:\ttotal: 4m 26s\tremaining: 2m 37s\n",
            "3147:\ttotal: 4m 26s\tremaining: 2m 36s\n",
            "3148:\ttotal: 4m 26s\tremaining: 2m 36s\n",
            "3149:\ttotal: 4m 26s\tremaining: 2m 36s\n",
            "3150:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3151:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3152:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3153:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3154:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3155:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3156:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3157:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3158:\ttotal: 4m 27s\tremaining: 2m 36s\n",
            "3159:\ttotal: 4m 27s\tremaining: 2m 35s\n",
            "3160:\ttotal: 4m 27s\tremaining: 2m 35s\n",
            "3161:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3162:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3163:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3164:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3165:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3166:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3167:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3168:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3169:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3170:\ttotal: 4m 28s\tremaining: 2m 35s\n",
            "3171:\ttotal: 4m 28s\tremaining: 2m 34s\n",
            "3172:\ttotal: 4m 28s\tremaining: 2m 34s\n",
            "3173:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3174:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3175:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3176:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3177:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3178:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3179:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3180:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3181:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3182:\ttotal: 4m 29s\tremaining: 2m 34s\n",
            "3183:\ttotal: 4m 29s\tremaining: 2m 33s\n",
            "3184:\ttotal: 4m 29s\tremaining: 2m 33s\n",
            "3185:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3186:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3187:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3188:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3189:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3190:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3191:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3192:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3193:\ttotal: 4m 30s\tremaining: 2m 33s\n",
            "3194:\ttotal: 4m 30s\tremaining: 2m 32s\n",
            "3195:\ttotal: 4m 30s\tremaining: 2m 32s\n",
            "3196:\ttotal: 4m 30s\tremaining: 2m 32s\n",
            "3197:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3198:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3199:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3200:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3201:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3202:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3203:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3204:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3205:\ttotal: 4m 31s\tremaining: 2m 32s\n",
            "3206:\ttotal: 4m 31s\tremaining: 2m 31s\n",
            "3207:\ttotal: 4m 31s\tremaining: 2m 31s\n",
            "3208:\ttotal: 4m 31s\tremaining: 2m 31s\n",
            "3209:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3210:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3211:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3212:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3213:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3214:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3215:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3216:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3217:\ttotal: 4m 32s\tremaining: 2m 31s\n",
            "3218:\ttotal: 4m 32s\tremaining: 2m 30s\n",
            "3219:\ttotal: 4m 32s\tremaining: 2m 30s\n",
            "3220:\ttotal: 4m 32s\tremaining: 2m 30s\n",
            "3221:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3222:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3223:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3224:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3225:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3226:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3227:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3228:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3229:\ttotal: 4m 33s\tremaining: 2m 30s\n",
            "3230:\ttotal: 4m 33s\tremaining: 2m 29s\n",
            "3231:\ttotal: 4m 33s\tremaining: 2m 29s\n",
            "3232:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3233:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3234:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3235:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3236:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3237:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3238:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3239:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3240:\ttotal: 4m 34s\tremaining: 2m 29s\n",
            "3241:\ttotal: 4m 34s\tremaining: 2m 28s\n",
            "3242:\ttotal: 4m 34s\tremaining: 2m 28s\n",
            "3243:\ttotal: 4m 34s\tremaining: 2m 28s\n",
            "3244:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3245:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3246:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3247:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3248:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3249:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3250:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3251:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3252:\ttotal: 4m 35s\tremaining: 2m 28s\n",
            "3253:\ttotal: 4m 35s\tremaining: 2m 27s\n",
            "3254:\ttotal: 4m 35s\tremaining: 2m 27s\n",
            "3255:\ttotal: 4m 35s\tremaining: 2m 27s\n",
            "3256:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3257:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3258:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3259:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3260:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3261:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3262:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3263:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3264:\ttotal: 4m 36s\tremaining: 2m 27s\n",
            "3265:\ttotal: 4m 36s\tremaining: 2m 26s\n",
            "3266:\ttotal: 4m 36s\tremaining: 2m 26s\n",
            "3267:\ttotal: 4m 36s\tremaining: 2m 26s\n",
            "3268:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3269:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3270:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3271:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3272:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3273:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3274:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3275:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3276:\ttotal: 4m 37s\tremaining: 2m 26s\n",
            "3277:\ttotal: 4m 37s\tremaining: 2m 25s\n",
            "3278:\ttotal: 4m 37s\tremaining: 2m 25s\n",
            "3279:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3280:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3281:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3282:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3283:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3284:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3285:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3286:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3287:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3288:\ttotal: 4m 38s\tremaining: 2m 25s\n",
            "3289:\ttotal: 4m 38s\tremaining: 2m 24s\n",
            "3290:\ttotal: 4m 38s\tremaining: 2m 24s\n",
            "3291:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3292:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3293:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3294:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3295:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3296:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3297:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3298:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3299:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3300:\ttotal: 4m 39s\tremaining: 2m 24s\n",
            "3301:\ttotal: 4m 39s\tremaining: 2m 23s\n",
            "3302:\ttotal: 4m 39s\tremaining: 2m 23s\n",
            "3303:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3304:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3305:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3306:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3307:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3308:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3309:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3310:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3311:\ttotal: 4m 40s\tremaining: 2m 23s\n",
            "3312:\ttotal: 4m 40s\tremaining: 2m 22s\n",
            "3313:\ttotal: 4m 40s\tremaining: 2m 22s\n",
            "3314:\ttotal: 4m 40s\tremaining: 2m 22s\n",
            "3315:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3316:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3317:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3318:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3319:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3320:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3321:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3322:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3323:\ttotal: 4m 41s\tremaining: 2m 22s\n",
            "3324:\ttotal: 4m 41s\tremaining: 2m 21s\n",
            "3325:\ttotal: 4m 41s\tremaining: 2m 21s\n",
            "3326:\ttotal: 4m 41s\tremaining: 2m 21s\n",
            "3327:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3328:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3329:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3330:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3331:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3332:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3333:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3334:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3335:\ttotal: 4m 42s\tremaining: 2m 21s\n",
            "3336:\ttotal: 4m 42s\tremaining: 2m 20s\n",
            "3337:\ttotal: 4m 42s\tremaining: 2m 20s\n",
            "3338:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3339:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3340:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3341:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3342:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3343:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3344:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3345:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3346:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3347:\ttotal: 4m 43s\tremaining: 2m 20s\n",
            "3348:\ttotal: 4m 43s\tremaining: 2m 19s\n",
            "3349:\ttotal: 4m 43s\tremaining: 2m 19s\n",
            "3350:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3351:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3352:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3353:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3354:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3355:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3356:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3357:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3358:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3359:\ttotal: 4m 44s\tremaining: 2m 19s\n",
            "3360:\ttotal: 4m 44s\tremaining: 2m 18s\n",
            "3361:\ttotal: 4m 44s\tremaining: 2m 18s\n",
            "3362:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3363:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3364:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3365:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3366:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3367:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3368:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3369:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3370:\ttotal: 4m 45s\tremaining: 2m 18s\n",
            "3371:\ttotal: 4m 45s\tremaining: 2m 17s\n",
            "3372:\ttotal: 4m 45s\tremaining: 2m 17s\n",
            "3373:\ttotal: 4m 45s\tremaining: 2m 17s\n",
            "3374:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3375:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3376:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3377:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3378:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3379:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3380:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3381:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3382:\ttotal: 4m 46s\tremaining: 2m 17s\n",
            "3383:\ttotal: 4m 46s\tremaining: 2m 16s\n",
            "3384:\ttotal: 4m 46s\tremaining: 2m 16s\n",
            "3385:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3386:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3387:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3388:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3389:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3390:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3391:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3392:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3393:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3394:\ttotal: 4m 47s\tremaining: 2m 16s\n",
            "3395:\ttotal: 4m 47s\tremaining: 2m 15s\n",
            "3396:\ttotal: 4m 47s\tremaining: 2m 15s\n",
            "3397:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3398:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3399:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3400:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3401:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3402:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3403:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3404:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3405:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3406:\ttotal: 4m 48s\tremaining: 2m 15s\n",
            "3407:\ttotal: 4m 48s\tremaining: 2m 14s\n",
            "3408:\ttotal: 4m 48s\tremaining: 2m 14s\n",
            "3409:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3410:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3411:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3412:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3413:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3414:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3415:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3416:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3417:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3418:\ttotal: 4m 49s\tremaining: 2m 14s\n",
            "3419:\ttotal: 4m 49s\tremaining: 2m 13s\n",
            "3420:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3421:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3422:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3423:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3424:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3425:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3426:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3427:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3428:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3429:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3430:\ttotal: 4m 50s\tremaining: 2m 13s\n",
            "3431:\ttotal: 4m 50s\tremaining: 2m 12s\n",
            "3432:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3433:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3434:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3435:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3436:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3437:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3438:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3439:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3440:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3441:\ttotal: 4m 51s\tremaining: 2m 12s\n",
            "3442:\ttotal: 4m 51s\tremaining: 2m 11s\n",
            "3443:\ttotal: 4m 51s\tremaining: 2m 11s\n",
            "3444:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3445:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3446:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3447:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3448:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3449:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3450:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3451:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3452:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3453:\ttotal: 4m 52s\tremaining: 2m 11s\n",
            "3454:\ttotal: 4m 52s\tremaining: 2m 10s\n",
            "3455:\ttotal: 4m 52s\tremaining: 2m 10s\n",
            "3456:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3457:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3458:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3459:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3460:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3461:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3462:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3463:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3464:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3465:\ttotal: 4m 53s\tremaining: 2m 10s\n",
            "3466:\ttotal: 4m 53s\tremaining: 2m 9s\n",
            "3467:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3468:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3469:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3470:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3471:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3472:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3473:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3474:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3475:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3476:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3477:\ttotal: 4m 54s\tremaining: 2m 9s\n",
            "3478:\ttotal: 4m 54s\tremaining: 2m 8s\n",
            "3479:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3480:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3481:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3482:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3483:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3484:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3485:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3486:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3487:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3488:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3489:\ttotal: 4m 55s\tremaining: 2m 8s\n",
            "3490:\ttotal: 4m 55s\tremaining: 2m 7s\n",
            "3491:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3492:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3493:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3494:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3495:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3496:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3497:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3498:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3499:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3500:\ttotal: 4m 56s\tremaining: 2m 7s\n",
            "3501:\ttotal: 4m 56s\tremaining: 2m 6s\n",
            "3502:\ttotal: 4m 56s\tremaining: 2m 6s\n",
            "3503:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3504:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3505:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3506:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3507:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3508:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3509:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3510:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3511:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3512:\ttotal: 4m 57s\tremaining: 2m 6s\n",
            "3513:\ttotal: 4m 57s\tremaining: 2m 5s\n",
            "3514:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3515:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3516:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3517:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3518:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3519:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3520:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3521:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3522:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3523:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3524:\ttotal: 4m 58s\tremaining: 2m 5s\n",
            "3525:\ttotal: 4m 58s\tremaining: 2m 4s\n",
            "3526:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3527:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3528:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3529:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3530:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3531:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3532:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3533:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3534:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3535:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3536:\ttotal: 4m 59s\tremaining: 2m 4s\n",
            "3537:\ttotal: 4m 59s\tremaining: 2m 3s\n",
            "3538:\ttotal: 5m\tremaining: 2m 3s\n",
            "3539:\ttotal: 5m\tremaining: 2m 3s\n",
            "3540:\ttotal: 5m\tremaining: 2m 3s\n",
            "3541:\ttotal: 5m\tremaining: 2m 3s\n",
            "3542:\ttotal: 5m\tremaining: 2m 3s\n",
            "3543:\ttotal: 5m\tremaining: 2m 3s\n",
            "3544:\ttotal: 5m\tremaining: 2m 3s\n",
            "3545:\ttotal: 5m\tremaining: 2m 3s\n",
            "3546:\ttotal: 5m\tremaining: 2m 3s\n",
            "3547:\ttotal: 5m\tremaining: 2m 3s\n",
            "3548:\ttotal: 5m\tremaining: 2m 3s\n",
            "3549:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3550:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3551:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3552:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3553:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3554:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3555:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3556:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3557:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3558:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3559:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3560:\ttotal: 5m 1s\tremaining: 2m 2s\n",
            "3561:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3562:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3563:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3564:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3565:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3566:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3567:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3568:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3569:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3570:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3571:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3572:\ttotal: 5m 2s\tremaining: 2m 1s\n",
            "3573:\ttotal: 5m 3s\tremaining: 2m\n",
            "3574:\ttotal: 5m 3s\tremaining: 2m\n",
            "3575:\ttotal: 5m 3s\tremaining: 2m\n",
            "3576:\ttotal: 5m 3s\tremaining: 2m\n",
            "3577:\ttotal: 5m 3s\tremaining: 2m\n",
            "3578:\ttotal: 5m 3s\tremaining: 2m\n",
            "3579:\ttotal: 5m 3s\tremaining: 2m\n",
            "3580:\ttotal: 5m 3s\tremaining: 2m\n",
            "3581:\ttotal: 5m 3s\tremaining: 2m\n",
            "3582:\ttotal: 5m 3s\tremaining: 2m\n",
            "3583:\ttotal: 5m 3s\tremaining: 2m\n",
            "3584:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3585:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3586:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3587:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3588:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3589:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3590:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3591:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3592:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3593:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3594:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3595:\ttotal: 5m 4s\tremaining: 1m 59s\n",
            "3596:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3597:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3598:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3599:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3600:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3601:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3602:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3603:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3604:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3605:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3606:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3607:\ttotal: 5m 5s\tremaining: 1m 58s\n",
            "3608:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3609:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3610:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3611:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3612:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3613:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3614:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3615:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3616:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3617:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3618:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3619:\ttotal: 5m 6s\tremaining: 1m 57s\n",
            "3620:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3621:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3622:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3623:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3624:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3625:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3626:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3627:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3628:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3629:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3630:\ttotal: 5m 7s\tremaining: 1m 56s\n",
            "3631:\ttotal: 5m 8s\tremaining: 1m 56s\n",
            "3632:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3633:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3634:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3635:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3636:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3637:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3638:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3639:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3640:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3641:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3642:\ttotal: 5m 8s\tremaining: 1m 55s\n",
            "3643:\ttotal: 5m 9s\tremaining: 1m 55s\n",
            "3644:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3645:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3646:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3647:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3648:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3649:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3650:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3651:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3652:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3653:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3654:\ttotal: 5m 9s\tremaining: 1m 54s\n",
            "3655:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3656:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3657:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3658:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3659:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3660:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3661:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3662:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3663:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3664:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3665:\ttotal: 5m 10s\tremaining: 1m 53s\n",
            "3666:\ttotal: 5m 11s\tremaining: 1m 53s\n",
            "3667:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3668:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3669:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3670:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3671:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3672:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3673:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3674:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3675:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3676:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3677:\ttotal: 5m 11s\tremaining: 1m 52s\n",
            "3678:\ttotal: 5m 12s\tremaining: 1m 52s\n",
            "3679:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3680:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3681:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3682:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3683:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3684:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3685:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3686:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3687:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3688:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3689:\ttotal: 5m 12s\tremaining: 1m 51s\n",
            "3690:\ttotal: 5m 13s\tremaining: 1m 51s\n",
            "3691:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3692:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3693:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3694:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3695:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3696:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3697:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3698:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3699:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3700:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3701:\ttotal: 5m 13s\tremaining: 1m 50s\n",
            "3702:\ttotal: 5m 14s\tremaining: 1m 50s\n",
            "3703:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3704:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3705:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3706:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3707:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3708:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3709:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3710:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3711:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3712:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3713:\ttotal: 5m 14s\tremaining: 1m 49s\n",
            "3714:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3715:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3716:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3717:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3718:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3719:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3720:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3721:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3722:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3723:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3724:\ttotal: 5m 15s\tremaining: 1m 48s\n",
            "3725:\ttotal: 5m 16s\tremaining: 1m 48s\n",
            "3726:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3727:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3728:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3729:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3730:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3731:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3732:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3733:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3734:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3735:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3736:\ttotal: 5m 16s\tremaining: 1m 47s\n",
            "3737:\ttotal: 5m 17s\tremaining: 1m 47s\n",
            "3738:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3739:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3740:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3741:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3742:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3743:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3744:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3745:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3746:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3747:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3748:\ttotal: 5m 17s\tremaining: 1m 46s\n",
            "3749:\ttotal: 5m 18s\tremaining: 1m 46s\n",
            "3750:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3751:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3752:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3753:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3754:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3755:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3756:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3757:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3758:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3759:\ttotal: 5m 18s\tremaining: 1m 45s\n",
            "3760:\ttotal: 5m 19s\tremaining: 1m 45s\n",
            "3761:\ttotal: 5m 19s\tremaining: 1m 45s\n",
            "3762:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3763:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3764:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3765:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3766:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3767:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3768:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3769:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3770:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3771:\ttotal: 5m 19s\tremaining: 1m 44s\n",
            "3772:\ttotal: 5m 20s\tremaining: 1m 44s\n",
            "3773:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3774:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3775:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3776:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3777:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3778:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3779:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3780:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3781:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3782:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3783:\ttotal: 5m 20s\tremaining: 1m 43s\n",
            "3784:\ttotal: 5m 21s\tremaining: 1m 43s\n",
            "3785:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3786:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3787:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3788:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3789:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3790:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3791:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3792:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3793:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3794:\ttotal: 5m 21s\tremaining: 1m 42s\n",
            "3795:\ttotal: 5m 22s\tremaining: 1m 42s\n",
            "3796:\ttotal: 5m 22s\tremaining: 1m 42s\n",
            "3797:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3798:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3799:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3800:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3801:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3802:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3803:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3804:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3805:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3806:\ttotal: 5m 22s\tremaining: 1m 41s\n",
            "3807:\ttotal: 5m 23s\tremaining: 1m 41s\n",
            "3808:\ttotal: 5m 23s\tremaining: 1m 41s\n",
            "3809:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3810:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3811:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3812:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3813:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3814:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3815:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3816:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3817:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3818:\ttotal: 5m 23s\tremaining: 1m 40s\n",
            "3819:\ttotal: 5m 24s\tremaining: 1m 40s\n",
            "3820:\ttotal: 5m 24s\tremaining: 1m 40s\n",
            "3821:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3822:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3823:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3824:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3825:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3826:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3827:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3828:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3829:\ttotal: 5m 24s\tremaining: 1m 39s\n",
            "3830:\ttotal: 5m 25s\tremaining: 1m 39s\n",
            "3831:\ttotal: 5m 25s\tremaining: 1m 39s\n",
            "3832:\ttotal: 5m 25s\tremaining: 1m 39s\n",
            "3833:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3834:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3835:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3836:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3837:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3838:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3839:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3840:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3841:\ttotal: 5m 25s\tremaining: 1m 38s\n",
            "3842:\ttotal: 5m 26s\tremaining: 1m 38s\n",
            "3843:\ttotal: 5m 26s\tremaining: 1m 38s\n",
            "3844:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3845:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3846:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3847:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3848:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3849:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3850:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3851:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3852:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3853:\ttotal: 5m 26s\tremaining: 1m 37s\n",
            "3854:\ttotal: 5m 27s\tremaining: 1m 37s\n",
            "3855:\ttotal: 5m 27s\tremaining: 1m 37s\n",
            "3856:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3857:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3858:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3859:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3860:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3861:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3862:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3863:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3864:\ttotal: 5m 27s\tremaining: 1m 36s\n",
            "3865:\ttotal: 5m 28s\tremaining: 1m 36s\n",
            "3866:\ttotal: 5m 28s\tremaining: 1m 36s\n",
            "3867:\ttotal: 5m 28s\tremaining: 1m 36s\n",
            "3868:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3869:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3870:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3871:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3872:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3873:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3874:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3875:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3876:\ttotal: 5m 28s\tremaining: 1m 35s\n",
            "3877:\ttotal: 5m 29s\tremaining: 1m 35s\n",
            "3878:\ttotal: 5m 29s\tremaining: 1m 35s\n",
            "3879:\ttotal: 5m 29s\tremaining: 1m 35s\n",
            "3880:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3881:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3882:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3883:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3884:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3885:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3886:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3887:\ttotal: 5m 29s\tremaining: 1m 34s\n",
            "3888:\ttotal: 5m 30s\tremaining: 1m 34s\n",
            "3889:\ttotal: 5m 30s\tremaining: 1m 34s\n",
            "3890:\ttotal: 5m 30s\tremaining: 1m 34s\n",
            "3891:\ttotal: 5m 30s\tremaining: 1m 34s\n",
            "3892:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3893:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3894:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3895:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3896:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3897:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3898:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3899:\ttotal: 5m 30s\tremaining: 1m 33s\n",
            "3900:\ttotal: 5m 31s\tremaining: 1m 33s\n",
            "3901:\ttotal: 5m 31s\tremaining: 1m 33s\n",
            "3902:\ttotal: 5m 31s\tremaining: 1m 33s\n",
            "3903:\ttotal: 5m 31s\tremaining: 1m 33s\n",
            "3904:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3905:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3906:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3907:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3908:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3909:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3910:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3911:\ttotal: 5m 31s\tremaining: 1m 32s\n",
            "3912:\ttotal: 5m 32s\tremaining: 1m 32s\n",
            "3913:\ttotal: 5m 32s\tremaining: 1m 32s\n",
            "3914:\ttotal: 5m 32s\tremaining: 1m 32s\n",
            "3915:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3916:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3917:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3918:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3919:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3920:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3921:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3922:\ttotal: 5m 32s\tremaining: 1m 31s\n",
            "3923:\ttotal: 5m 33s\tremaining: 1m 31s\n",
            "3924:\ttotal: 5m 33s\tremaining: 1m 31s\n",
            "3925:\ttotal: 5m 33s\tremaining: 1m 31s\n",
            "3926:\ttotal: 5m 33s\tremaining: 1m 31s\n",
            "3927:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3928:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3929:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3930:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3931:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3932:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3933:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3934:\ttotal: 5m 33s\tremaining: 1m 30s\n",
            "3935:\ttotal: 5m 34s\tremaining: 1m 30s\n",
            "3936:\ttotal: 5m 34s\tremaining: 1m 30s\n",
            "3937:\ttotal: 5m 34s\tremaining: 1m 30s\n",
            "3938:\ttotal: 5m 34s\tremaining: 1m 30s\n",
            "3939:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3940:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3941:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3942:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3943:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3944:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3945:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3946:\ttotal: 5m 34s\tremaining: 1m 29s\n",
            "3947:\ttotal: 5m 35s\tremaining: 1m 29s\n",
            "3948:\ttotal: 5m 35s\tremaining: 1m 29s\n",
            "3949:\ttotal: 5m 35s\tremaining: 1m 29s\n",
            "3950:\ttotal: 5m 35s\tremaining: 1m 29s\n",
            "3951:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3952:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3953:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3954:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3955:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3956:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3957:\ttotal: 5m 35s\tremaining: 1m 28s\n",
            "3958:\ttotal: 5m 36s\tremaining: 1m 28s\n",
            "3959:\ttotal: 5m 36s\tremaining: 1m 28s\n",
            "3960:\ttotal: 5m 36s\tremaining: 1m 28s\n",
            "3961:\ttotal: 5m 36s\tremaining: 1m 28s\n",
            "3962:\ttotal: 5m 36s\tremaining: 1m 28s\n",
            "3963:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3964:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3965:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3966:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3967:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3968:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3969:\ttotal: 5m 36s\tremaining: 1m 27s\n",
            "3970:\ttotal: 5m 37s\tremaining: 1m 27s\n",
            "3971:\ttotal: 5m 37s\tremaining: 1m 27s\n",
            "3972:\ttotal: 5m 37s\tremaining: 1m 27s\n",
            "3973:\ttotal: 5m 37s\tremaining: 1m 27s\n",
            "3974:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3975:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3976:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3977:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3978:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3979:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3980:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3981:\ttotal: 5m 37s\tremaining: 1m 26s\n",
            "3982:\ttotal: 5m 38s\tremaining: 1m 26s\n",
            "3983:\ttotal: 5m 38s\tremaining: 1m 26s\n",
            "3984:\ttotal: 5m 38s\tremaining: 1m 26s\n",
            "3985:\ttotal: 5m 38s\tremaining: 1m 26s\n",
            "3986:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3987:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3988:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3989:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3990:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3991:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3992:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3993:\ttotal: 5m 38s\tremaining: 1m 25s\n",
            "3994:\ttotal: 5m 39s\tremaining: 1m 25s\n",
            "3995:\ttotal: 5m 39s\tremaining: 1m 25s\n",
            "3996:\ttotal: 5m 39s\tremaining: 1m 25s\n",
            "3997:\ttotal: 5m 39s\tremaining: 1m 25s\n",
            "3998:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "3999:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4000:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4001:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4002:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4003:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4004:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4005:\ttotal: 5m 39s\tremaining: 1m 24s\n",
            "4006:\ttotal: 5m 40s\tremaining: 1m 24s\n",
            "4007:\ttotal: 5m 40s\tremaining: 1m 24s\n",
            "4008:\ttotal: 5m 40s\tremaining: 1m 24s\n",
            "4009:\ttotal: 5m 40s\tremaining: 1m 24s\n",
            "4010:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4011:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4012:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4013:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4014:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4015:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4016:\ttotal: 5m 40s\tremaining: 1m 23s\n",
            "4017:\ttotal: 5m 41s\tremaining: 1m 23s\n",
            "4018:\ttotal: 5m 41s\tremaining: 1m 23s\n",
            "4019:\ttotal: 5m 41s\tremaining: 1m 23s\n",
            "4020:\ttotal: 5m 41s\tremaining: 1m 23s\n",
            "4021:\ttotal: 5m 41s\tremaining: 1m 23s\n",
            "4022:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4023:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4024:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4025:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4026:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4027:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4028:\ttotal: 5m 41s\tremaining: 1m 22s\n",
            "4029:\ttotal: 5m 42s\tremaining: 1m 22s\n",
            "4030:\ttotal: 5m 42s\tremaining: 1m 22s\n",
            "4031:\ttotal: 5m 42s\tremaining: 1m 22s\n",
            "4032:\ttotal: 5m 42s\tremaining: 1m 22s\n",
            "4033:\ttotal: 5m 42s\tremaining: 1m 22s\n",
            "4034:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4035:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4036:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4037:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4038:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4039:\ttotal: 5m 42s\tremaining: 1m 21s\n",
            "4040:\ttotal: 5m 43s\tremaining: 1m 21s\n",
            "4041:\ttotal: 5m 43s\tremaining: 1m 21s\n",
            "4042:\ttotal: 5m 43s\tremaining: 1m 21s\n",
            "4043:\ttotal: 5m 43s\tremaining: 1m 21s\n",
            "4044:\ttotal: 5m 43s\tremaining: 1m 21s\n",
            "4045:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4046:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4047:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4048:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4049:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4050:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4051:\ttotal: 5m 43s\tremaining: 1m 20s\n",
            "4052:\ttotal: 5m 44s\tremaining: 1m 20s\n",
            "4053:\ttotal: 5m 44s\tremaining: 1m 20s\n",
            "4054:\ttotal: 5m 44s\tremaining: 1m 20s\n",
            "4055:\ttotal: 5m 44s\tremaining: 1m 20s\n",
            "4056:\ttotal: 5m 44s\tremaining: 1m 20s\n",
            "4057:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4058:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4059:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4060:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4061:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4062:\ttotal: 5m 44s\tremaining: 1m 19s\n",
            "4063:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4064:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4065:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4066:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4067:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4068:\ttotal: 5m 45s\tremaining: 1m 19s\n",
            "4069:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4070:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4071:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4072:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4073:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4074:\ttotal: 5m 45s\tremaining: 1m 18s\n",
            "4075:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4076:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4077:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4078:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4079:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4080:\ttotal: 5m 46s\tremaining: 1m 18s\n",
            "4081:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4082:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4083:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4084:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4085:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4086:\ttotal: 5m 46s\tremaining: 1m 17s\n",
            "4087:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4088:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4089:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4090:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4091:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4092:\ttotal: 5m 47s\tremaining: 1m 17s\n",
            "4093:\ttotal: 5m 47s\tremaining: 1m 16s\n",
            "4094:\ttotal: 5m 47s\tremaining: 1m 16s\n",
            "4095:\ttotal: 5m 47s\tremaining: 1m 16s\n",
            "4096:\ttotal: 5m 47s\tremaining: 1m 16s\n",
            "4097:\ttotal: 5m 47s\tremaining: 1m 16s\n",
            "4098:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4099:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4100:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4101:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4102:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4103:\ttotal: 5m 48s\tremaining: 1m 16s\n",
            "4104:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4105:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4106:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4107:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4108:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4109:\ttotal: 5m 48s\tremaining: 1m 15s\n",
            "4110:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4111:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4112:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4113:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4114:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4115:\ttotal: 5m 49s\tremaining: 1m 15s\n",
            "4116:\ttotal: 5m 49s\tremaining: 1m 14s\n",
            "4117:\ttotal: 5m 49s\tremaining: 1m 14s\n",
            "4118:\ttotal: 5m 49s\tremaining: 1m 14s\n",
            "4119:\ttotal: 5m 49s\tremaining: 1m 14s\n",
            "4120:\ttotal: 5m 49s\tremaining: 1m 14s\n",
            "4121:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4122:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4123:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4124:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4125:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4126:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4127:\ttotal: 5m 50s\tremaining: 1m 14s\n",
            "4128:\ttotal: 5m 50s\tremaining: 1m 13s\n",
            "4129:\ttotal: 5m 50s\tremaining: 1m 13s\n",
            "4130:\ttotal: 5m 50s\tremaining: 1m 13s\n",
            "4131:\ttotal: 5m 50s\tremaining: 1m 13s\n",
            "4132:\ttotal: 5m 50s\tremaining: 1m 13s\n",
            "4133:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4134:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4135:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4136:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4137:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4138:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4139:\ttotal: 5m 51s\tremaining: 1m 13s\n",
            "4140:\ttotal: 5m 51s\tremaining: 1m 12s\n",
            "4141:\ttotal: 5m 51s\tremaining: 1m 12s\n",
            "4142:\ttotal: 5m 51s\tremaining: 1m 12s\n",
            "4143:\ttotal: 5m 51s\tremaining: 1m 12s\n",
            "4144:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4145:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4146:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4147:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4148:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4149:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4150:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4151:\ttotal: 5m 52s\tremaining: 1m 12s\n",
            "4152:\ttotal: 5m 52s\tremaining: 1m 11s\n",
            "4153:\ttotal: 5m 52s\tremaining: 1m 11s\n",
            "4154:\ttotal: 5m 52s\tremaining: 1m 11s\n",
            "4155:\ttotal: 5m 52s\tremaining: 1m 11s\n",
            "4156:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4157:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4158:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4159:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4160:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4161:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4162:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4163:\ttotal: 5m 53s\tremaining: 1m 11s\n",
            "4164:\ttotal: 5m 53s\tremaining: 1m 10s\n",
            "4165:\ttotal: 5m 53s\tremaining: 1m 10s\n",
            "4166:\ttotal: 5m 53s\tremaining: 1m 10s\n",
            "4167:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4168:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4169:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4170:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4171:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4172:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4173:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4174:\ttotal: 5m 54s\tremaining: 1m 10s\n",
            "4175:\ttotal: 5m 54s\tremaining: 1m 9s\n",
            "4176:\ttotal: 5m 54s\tremaining: 1m 9s\n",
            "4177:\ttotal: 5m 54s\tremaining: 1m 9s\n",
            "4178:\ttotal: 5m 54s\tremaining: 1m 9s\n",
            "4179:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4180:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4181:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4182:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4183:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4184:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4185:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4186:\ttotal: 5m 55s\tremaining: 1m 9s\n",
            "4187:\ttotal: 5m 55s\tremaining: 1m 8s\n",
            "4188:\ttotal: 5m 55s\tremaining: 1m 8s\n",
            "4189:\ttotal: 5m 55s\tremaining: 1m 8s\n",
            "4190:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4191:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4192:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4193:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4194:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4195:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4196:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4197:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4198:\ttotal: 5m 56s\tremaining: 1m 8s\n",
            "4199:\ttotal: 5m 56s\tremaining: 1m 7s\n",
            "4200:\ttotal: 5m 56s\tremaining: 1m 7s\n",
            "4201:\ttotal: 5m 56s\tremaining: 1m 7s\n",
            "4202:\ttotal: 5m 56s\tremaining: 1m 7s\n",
            "4203:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4204:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4205:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4206:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4207:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4208:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4209:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4210:\ttotal: 5m 57s\tremaining: 1m 7s\n",
            "4211:\ttotal: 5m 57s\tremaining: 1m 6s\n",
            "4212:\ttotal: 5m 57s\tremaining: 1m 6s\n",
            "4213:\ttotal: 5m 57s\tremaining: 1m 6s\n",
            "4214:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4215:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4216:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4217:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4218:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4219:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4220:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4221:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4222:\ttotal: 5m 58s\tremaining: 1m 6s\n",
            "4223:\ttotal: 5m 58s\tremaining: 1m 5s\n",
            "4224:\ttotal: 5m 58s\tremaining: 1m 5s\n",
            "4225:\ttotal: 5m 58s\tremaining: 1m 5s\n",
            "4226:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4227:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4228:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4229:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4230:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4231:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4232:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4233:\ttotal: 5m 59s\tremaining: 1m 5s\n",
            "4234:\ttotal: 5m 59s\tremaining: 1m 4s\n",
            "4235:\ttotal: 5m 59s\tremaining: 1m 4s\n",
            "4236:\ttotal: 5m 59s\tremaining: 1m 4s\n",
            "4237:\ttotal: 6m\tremaining: 1m 4s\n",
            "4238:\ttotal: 6m\tremaining: 1m 4s\n",
            "4239:\ttotal: 6m\tremaining: 1m 4s\n",
            "4240:\ttotal: 6m\tremaining: 1m 4s\n",
            "4241:\ttotal: 6m\tremaining: 1m 4s\n",
            "4242:\ttotal: 6m\tremaining: 1m 4s\n",
            "4243:\ttotal: 6m\tremaining: 1m 4s\n",
            "4244:\ttotal: 6m\tremaining: 1m 4s\n",
            "4245:\ttotal: 6m\tremaining: 1m 4s\n",
            "4246:\ttotal: 6m\tremaining: 1m 3s\n",
            "4247:\ttotal: 6m\tremaining: 1m 3s\n",
            "4248:\ttotal: 6m\tremaining: 1m 3s\n",
            "4249:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4250:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4251:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4252:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4253:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4254:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4255:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4256:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4257:\ttotal: 6m 1s\tremaining: 1m 3s\n",
            "4258:\ttotal: 6m 1s\tremaining: 1m 2s\n",
            "4259:\ttotal: 6m 1s\tremaining: 1m 2s\n",
            "4260:\ttotal: 6m 1s\tremaining: 1m 2s\n",
            "4261:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4262:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4263:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4264:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4265:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4266:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4267:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4268:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4269:\ttotal: 6m 2s\tremaining: 1m 2s\n",
            "4270:\ttotal: 6m 2s\tremaining: 1m 1s\n",
            "4271:\ttotal: 6m 2s\tremaining: 1m 1s\n",
            "4272:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4273:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4274:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4275:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4276:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4277:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4278:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4279:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4280:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4281:\ttotal: 6m 3s\tremaining: 1m 1s\n",
            "4282:\ttotal: 6m 3s\tremaining: 1m\n",
            "4283:\ttotal: 6m 3s\tremaining: 1m\n",
            "4284:\ttotal: 6m 4s\tremaining: 1m\n",
            "4285:\ttotal: 6m 4s\tremaining: 1m\n",
            "4286:\ttotal: 6m 4s\tremaining: 1m\n",
            "4287:\ttotal: 6m 4s\tremaining: 1m\n",
            "4288:\ttotal: 6m 4s\tremaining: 1m\n",
            "4289:\ttotal: 6m 4s\tremaining: 1m\n",
            "4290:\ttotal: 6m 4s\tremaining: 1m\n",
            "4291:\ttotal: 6m 4s\tremaining: 1m\n",
            "4292:\ttotal: 6m 4s\tremaining: 1m\n",
            "4293:\ttotal: 6m 4s\tremaining: 60s\n",
            "4294:\ttotal: 6m 4s\tremaining: 59.9s\n",
            "4295:\ttotal: 6m 5s\tremaining: 59.8s\n",
            "4296:\ttotal: 6m 5s\tremaining: 59.7s\n",
            "4297:\ttotal: 6m 5s\tremaining: 59.6s\n",
            "4298:\ttotal: 6m 5s\tremaining: 59.6s\n",
            "4299:\ttotal: 6m 5s\tremaining: 59.5s\n",
            "4300:\ttotal: 6m 5s\tremaining: 59.4s\n",
            "4301:\ttotal: 6m 5s\tremaining: 59.3s\n",
            "4302:\ttotal: 6m 5s\tremaining: 59.2s\n",
            "4303:\ttotal: 6m 5s\tremaining: 59.1s\n",
            "4304:\ttotal: 6m 5s\tremaining: 59s\n",
            "4305:\ttotal: 6m 5s\tremaining: 59s\n",
            "4306:\ttotal: 6m 5s\tremaining: 58.9s\n",
            "4307:\ttotal: 6m 6s\tremaining: 58.8s\n",
            "4308:\ttotal: 6m 6s\tremaining: 58.7s\n",
            "4309:\ttotal: 6m 6s\tremaining: 58.6s\n",
            "4310:\ttotal: 6m 6s\tremaining: 58.5s\n",
            "4311:\ttotal: 6m 6s\tremaining: 58.5s\n",
            "4312:\ttotal: 6m 6s\tremaining: 58.4s\n",
            "4313:\ttotal: 6m 6s\tremaining: 58.3s\n",
            "4314:\ttotal: 6m 6s\tremaining: 58.2s\n",
            "4315:\ttotal: 6m 6s\tremaining: 58.1s\n",
            "4316:\ttotal: 6m 6s\tremaining: 58s\n",
            "4317:\ttotal: 6m 6s\tremaining: 57.9s\n",
            "4318:\ttotal: 6m 6s\tremaining: 57.9s\n",
            "4319:\ttotal: 6m 7s\tremaining: 57.8s\n",
            "4320:\ttotal: 6m 7s\tremaining: 57.7s\n",
            "4321:\ttotal: 6m 7s\tremaining: 57.6s\n",
            "4322:\ttotal: 6m 7s\tremaining: 57.5s\n",
            "4323:\ttotal: 6m 7s\tremaining: 57.4s\n",
            "4324:\ttotal: 6m 7s\tremaining: 57.4s\n",
            "4325:\ttotal: 6m 7s\tremaining: 57.3s\n",
            "4326:\ttotal: 6m 7s\tremaining: 57.2s\n",
            "4327:\ttotal: 6m 7s\tremaining: 57.1s\n",
            "4328:\ttotal: 6m 7s\tremaining: 57s\n",
            "4329:\ttotal: 6m 7s\tremaining: 56.9s\n",
            "4330:\ttotal: 6m 7s\tremaining: 56.8s\n",
            "4331:\ttotal: 6m 8s\tremaining: 56.8s\n",
            "4332:\ttotal: 6m 8s\tremaining: 56.7s\n",
            "4333:\ttotal: 6m 8s\tremaining: 56.6s\n",
            "4334:\ttotal: 6m 8s\tremaining: 56.5s\n",
            "4335:\ttotal: 6m 8s\tremaining: 56.4s\n",
            "4336:\ttotal: 6m 8s\tremaining: 56.3s\n",
            "4337:\ttotal: 6m 8s\tremaining: 56.2s\n",
            "4338:\ttotal: 6m 8s\tremaining: 56.2s\n",
            "4339:\ttotal: 6m 8s\tremaining: 56.1s\n",
            "4340:\ttotal: 6m 8s\tremaining: 56s\n",
            "4341:\ttotal: 6m 8s\tremaining: 55.9s\n",
            "4342:\ttotal: 6m 9s\tremaining: 55.8s\n",
            "4343:\ttotal: 6m 9s\tremaining: 55.7s\n",
            "4344:\ttotal: 6m 9s\tremaining: 55.7s\n",
            "4345:\ttotal: 6m 9s\tremaining: 55.6s\n",
            "4346:\ttotal: 6m 9s\tremaining: 55.5s\n",
            "4347:\ttotal: 6m 9s\tremaining: 55.4s\n",
            "4348:\ttotal: 6m 9s\tremaining: 55.3s\n",
            "4349:\ttotal: 6m 9s\tremaining: 55.2s\n",
            "4350:\ttotal: 6m 9s\tremaining: 55.1s\n",
            "4351:\ttotal: 6m 9s\tremaining: 55.1s\n",
            "4352:\ttotal: 6m 9s\tremaining: 55s\n",
            "4353:\ttotal: 6m 9s\tremaining: 54.9s\n",
            "4354:\ttotal: 6m 10s\tremaining: 54.8s\n",
            "4355:\ttotal: 6m 10s\tremaining: 54.7s\n",
            "4356:\ttotal: 6m 10s\tremaining: 54.6s\n",
            "4357:\ttotal: 6m 10s\tremaining: 54.5s\n",
            "4358:\ttotal: 6m 10s\tremaining: 54.5s\n",
            "4359:\ttotal: 6m 10s\tremaining: 54.4s\n",
            "4360:\ttotal: 6m 10s\tremaining: 54.3s\n",
            "4361:\ttotal: 6m 10s\tremaining: 54.2s\n",
            "4362:\ttotal: 6m 10s\tremaining: 54.1s\n",
            "4363:\ttotal: 6m 10s\tremaining: 54s\n",
            "4364:\ttotal: 6m 10s\tremaining: 54s\n",
            "4365:\ttotal: 6m 10s\tremaining: 53.9s\n",
            "4366:\ttotal: 6m 11s\tremaining: 53.8s\n",
            "4367:\ttotal: 6m 11s\tremaining: 53.7s\n",
            "4368:\ttotal: 6m 11s\tremaining: 53.6s\n",
            "4369:\ttotal: 6m 11s\tremaining: 53.5s\n",
            "4370:\ttotal: 6m 11s\tremaining: 53.4s\n",
            "4371:\ttotal: 6m 11s\tremaining: 53.4s\n",
            "4372:\ttotal: 6m 11s\tremaining: 53.3s\n",
            "4373:\ttotal: 6m 11s\tremaining: 53.2s\n",
            "4374:\ttotal: 6m 11s\tremaining: 53.1s\n",
            "4375:\ttotal: 6m 11s\tremaining: 53s\n",
            "4376:\ttotal: 6m 11s\tremaining: 52.9s\n",
            "4377:\ttotal: 6m 12s\tremaining: 52.9s\n",
            "4378:\ttotal: 6m 12s\tremaining: 52.8s\n",
            "4379:\ttotal: 6m 12s\tremaining: 52.7s\n",
            "4380:\ttotal: 6m 12s\tremaining: 52.6s\n",
            "4381:\ttotal: 6m 12s\tremaining: 52.5s\n",
            "4382:\ttotal: 6m 12s\tremaining: 52.4s\n",
            "4383:\ttotal: 6m 12s\tremaining: 52.3s\n",
            "4384:\ttotal: 6m 12s\tremaining: 52.3s\n",
            "4385:\ttotal: 6m 12s\tremaining: 52.2s\n",
            "4386:\ttotal: 6m 12s\tremaining: 52.1s\n",
            "4387:\ttotal: 6m 12s\tremaining: 52s\n",
            "4388:\ttotal: 6m 12s\tremaining: 51.9s\n",
            "4389:\ttotal: 6m 13s\tremaining: 51.8s\n",
            "4390:\ttotal: 6m 13s\tremaining: 51.8s\n",
            "4391:\ttotal: 6m 13s\tremaining: 51.7s\n",
            "4392:\ttotal: 6m 13s\tremaining: 51.6s\n",
            "4393:\ttotal: 6m 13s\tremaining: 51.5s\n",
            "4394:\ttotal: 6m 13s\tremaining: 51.4s\n",
            "4395:\ttotal: 6m 13s\tremaining: 51.3s\n",
            "4396:\ttotal: 6m 13s\tremaining: 51.2s\n",
            "4397:\ttotal: 6m 13s\tremaining: 51.2s\n",
            "4398:\ttotal: 6m 13s\tremaining: 51.1s\n",
            "4399:\ttotal: 6m 13s\tremaining: 51s\n",
            "4400:\ttotal: 6m 13s\tremaining: 50.9s\n",
            "4401:\ttotal: 6m 14s\tremaining: 50.8s\n",
            "4402:\ttotal: 6m 14s\tremaining: 50.7s\n",
            "4403:\ttotal: 6m 14s\tremaining: 50.6s\n",
            "4404:\ttotal: 6m 14s\tremaining: 50.6s\n",
            "4405:\ttotal: 6m 14s\tremaining: 50.5s\n",
            "4406:\ttotal: 6m 14s\tremaining: 50.4s\n",
            "4407:\ttotal: 6m 14s\tremaining: 50.3s\n",
            "4408:\ttotal: 6m 14s\tremaining: 50.2s\n",
            "4409:\ttotal: 6m 14s\tremaining: 50.1s\n",
            "4410:\ttotal: 6m 14s\tremaining: 50.1s\n",
            "4411:\ttotal: 6m 14s\tremaining: 50s\n",
            "4412:\ttotal: 6m 15s\tremaining: 49.9s\n",
            "4413:\ttotal: 6m 15s\tremaining: 49.8s\n",
            "4414:\ttotal: 6m 15s\tremaining: 49.7s\n",
            "4415:\ttotal: 6m 15s\tremaining: 49.6s\n",
            "4416:\ttotal: 6m 15s\tremaining: 49.5s\n",
            "4417:\ttotal: 6m 15s\tremaining: 49.5s\n",
            "4418:\ttotal: 6m 15s\tremaining: 49.4s\n",
            "4419:\ttotal: 6m 15s\tremaining: 49.3s\n",
            "4420:\ttotal: 6m 15s\tremaining: 49.2s\n",
            "4421:\ttotal: 6m 15s\tremaining: 49.1s\n",
            "4422:\ttotal: 6m 15s\tremaining: 49s\n",
            "4423:\ttotal: 6m 15s\tremaining: 48.9s\n",
            "4424:\ttotal: 6m 16s\tremaining: 48.9s\n",
            "4425:\ttotal: 6m 16s\tremaining: 48.8s\n",
            "4426:\ttotal: 6m 16s\tremaining: 48.7s\n",
            "4427:\ttotal: 6m 16s\tremaining: 48.6s\n",
            "4428:\ttotal: 6m 16s\tremaining: 48.5s\n",
            "4429:\ttotal: 6m 16s\tremaining: 48.4s\n",
            "4430:\ttotal: 6m 16s\tremaining: 48.4s\n",
            "4431:\ttotal: 6m 16s\tremaining: 48.3s\n",
            "4432:\ttotal: 6m 16s\tremaining: 48.2s\n",
            "4433:\ttotal: 6m 16s\tremaining: 48.1s\n",
            "4434:\ttotal: 6m 16s\tremaining: 48s\n",
            "4435:\ttotal: 6m 16s\tremaining: 47.9s\n",
            "4436:\ttotal: 6m 17s\tremaining: 47.8s\n",
            "4437:\ttotal: 6m 17s\tremaining: 47.8s\n",
            "4438:\ttotal: 6m 17s\tremaining: 47.7s\n",
            "4439:\ttotal: 6m 17s\tremaining: 47.6s\n",
            "4440:\ttotal: 6m 17s\tremaining: 47.5s\n",
            "4441:\ttotal: 6m 17s\tremaining: 47.4s\n",
            "4442:\ttotal: 6m 17s\tremaining: 47.3s\n",
            "4443:\ttotal: 6m 17s\tremaining: 47.2s\n",
            "4444:\ttotal: 6m 17s\tremaining: 47.2s\n",
            "4445:\ttotal: 6m 17s\tremaining: 47.1s\n",
            "4446:\ttotal: 6m 17s\tremaining: 47s\n",
            "4447:\ttotal: 6m 17s\tremaining: 46.9s\n",
            "4448:\ttotal: 6m 18s\tremaining: 46.8s\n",
            "4449:\ttotal: 6m 18s\tremaining: 46.7s\n",
            "4450:\ttotal: 6m 18s\tremaining: 46.7s\n",
            "4451:\ttotal: 6m 18s\tremaining: 46.6s\n",
            "4452:\ttotal: 6m 18s\tremaining: 46.5s\n",
            "4453:\ttotal: 6m 18s\tremaining: 46.4s\n",
            "4454:\ttotal: 6m 18s\tremaining: 46.3s\n",
            "4455:\ttotal: 6m 18s\tremaining: 46.2s\n",
            "4456:\ttotal: 6m 18s\tremaining: 46.1s\n",
            "4457:\ttotal: 6m 18s\tremaining: 46.1s\n",
            "4458:\ttotal: 6m 18s\tremaining: 46s\n",
            "4459:\ttotal: 6m 19s\tremaining: 45.9s\n",
            "4460:\ttotal: 6m 19s\tremaining: 45.8s\n",
            "4461:\ttotal: 6m 19s\tremaining: 45.7s\n",
            "4462:\ttotal: 6m 19s\tremaining: 45.6s\n",
            "4463:\ttotal: 6m 19s\tremaining: 45.5s\n",
            "4464:\ttotal: 6m 19s\tremaining: 45.5s\n",
            "4465:\ttotal: 6m 19s\tremaining: 45.4s\n",
            "4466:\ttotal: 6m 19s\tremaining: 45.3s\n",
            "4467:\ttotal: 6m 19s\tremaining: 45.2s\n",
            "4468:\ttotal: 6m 19s\tremaining: 45.1s\n",
            "4469:\ttotal: 6m 19s\tremaining: 45s\n",
            "4470:\ttotal: 6m 19s\tremaining: 45s\n",
            "4471:\ttotal: 6m 20s\tremaining: 44.9s\n",
            "4472:\ttotal: 6m 20s\tremaining: 44.8s\n",
            "4473:\ttotal: 6m 20s\tremaining: 44.7s\n",
            "4474:\ttotal: 6m 20s\tremaining: 44.6s\n",
            "4475:\ttotal: 6m 20s\tremaining: 44.5s\n",
            "4476:\ttotal: 6m 20s\tremaining: 44.4s\n",
            "4477:\ttotal: 6m 20s\tremaining: 44.4s\n",
            "4478:\ttotal: 6m 20s\tremaining: 44.3s\n",
            "4479:\ttotal: 6m 20s\tremaining: 44.2s\n",
            "4480:\ttotal: 6m 20s\tremaining: 44.1s\n",
            "4481:\ttotal: 6m 20s\tremaining: 44s\n",
            "4482:\ttotal: 6m 21s\tremaining: 43.9s\n",
            "4483:\ttotal: 6m 21s\tremaining: 43.9s\n",
            "4484:\ttotal: 6m 21s\tremaining: 43.8s\n",
            "4485:\ttotal: 6m 21s\tremaining: 43.7s\n",
            "4486:\ttotal: 6m 21s\tremaining: 43.6s\n",
            "4487:\ttotal: 6m 21s\tremaining: 43.5s\n",
            "4488:\ttotal: 6m 21s\tremaining: 43.4s\n",
            "4489:\ttotal: 6m 21s\tremaining: 43.3s\n",
            "4490:\ttotal: 6m 21s\tremaining: 43.3s\n",
            "4491:\ttotal: 6m 21s\tremaining: 43.2s\n",
            "4492:\ttotal: 6m 21s\tremaining: 43.1s\n",
            "4493:\ttotal: 6m 21s\tremaining: 43s\n",
            "4494:\ttotal: 6m 22s\tremaining: 42.9s\n",
            "4495:\ttotal: 6m 22s\tremaining: 42.8s\n",
            "4496:\ttotal: 6m 22s\tremaining: 42.7s\n",
            "4497:\ttotal: 6m 22s\tremaining: 42.7s\n",
            "4498:\ttotal: 6m 22s\tremaining: 42.6s\n",
            "4499:\ttotal: 6m 22s\tremaining: 42.5s\n",
            "4500:\ttotal: 6m 22s\tremaining: 42.4s\n",
            "4501:\ttotal: 6m 22s\tremaining: 42.3s\n",
            "4502:\ttotal: 6m 22s\tremaining: 42.2s\n",
            "4503:\ttotal: 6m 22s\tremaining: 42.2s\n",
            "4504:\ttotal: 6m 22s\tremaining: 42.1s\n",
            "4505:\ttotal: 6m 22s\tremaining: 42s\n",
            "4506:\ttotal: 6m 23s\tremaining: 41.9s\n",
            "4507:\ttotal: 6m 23s\tremaining: 41.8s\n",
            "4508:\ttotal: 6m 23s\tremaining: 41.7s\n",
            "4509:\ttotal: 6m 23s\tremaining: 41.6s\n",
            "4510:\ttotal: 6m 23s\tremaining: 41.6s\n",
            "4511:\ttotal: 6m 23s\tremaining: 41.5s\n",
            "4512:\ttotal: 6m 23s\tremaining: 41.4s\n",
            "4513:\ttotal: 6m 23s\tremaining: 41.3s\n",
            "4514:\ttotal: 6m 23s\tremaining: 41.2s\n",
            "4515:\ttotal: 6m 23s\tremaining: 41.1s\n",
            "4516:\ttotal: 6m 23s\tremaining: 41s\n",
            "4517:\ttotal: 6m 23s\tremaining: 41s\n",
            "4518:\ttotal: 6m 24s\tremaining: 40.9s\n",
            "4519:\ttotal: 6m 24s\tremaining: 40.8s\n",
            "4520:\ttotal: 6m 24s\tremaining: 40.7s\n",
            "4521:\ttotal: 6m 24s\tremaining: 40.6s\n",
            "4522:\ttotal: 6m 24s\tremaining: 40.5s\n",
            "4523:\ttotal: 6m 24s\tremaining: 40.5s\n",
            "4524:\ttotal: 6m 24s\tremaining: 40.4s\n",
            "4525:\ttotal: 6m 24s\tremaining: 40.3s\n",
            "4526:\ttotal: 6m 24s\tremaining: 40.2s\n",
            "4527:\ttotal: 6m 24s\tremaining: 40.1s\n",
            "4528:\ttotal: 6m 24s\tremaining: 40s\n",
            "4529:\ttotal: 6m 24s\tremaining: 39.9s\n",
            "4530:\ttotal: 6m 25s\tremaining: 39.9s\n",
            "4531:\ttotal: 6m 25s\tremaining: 39.8s\n",
            "4532:\ttotal: 6m 25s\tremaining: 39.7s\n",
            "4533:\ttotal: 6m 25s\tremaining: 39.6s\n",
            "4534:\ttotal: 6m 25s\tremaining: 39.5s\n",
            "4535:\ttotal: 6m 25s\tremaining: 39.4s\n",
            "4536:\ttotal: 6m 25s\tremaining: 39.3s\n",
            "4537:\ttotal: 6m 25s\tremaining: 39.3s\n",
            "4538:\ttotal: 6m 25s\tremaining: 39.2s\n",
            "4539:\ttotal: 6m 25s\tremaining: 39.1s\n",
            "4540:\ttotal: 6m 25s\tremaining: 39s\n",
            "4541:\ttotal: 6m 26s\tremaining: 38.9s\n",
            "4542:\ttotal: 6m 26s\tremaining: 38.8s\n",
            "4543:\ttotal: 6m 26s\tremaining: 38.8s\n",
            "4544:\ttotal: 6m 26s\tremaining: 38.7s\n",
            "4545:\ttotal: 6m 26s\tremaining: 38.6s\n",
            "4546:\ttotal: 6m 26s\tremaining: 38.5s\n",
            "4547:\ttotal: 6m 26s\tremaining: 38.4s\n",
            "4548:\ttotal: 6m 26s\tremaining: 38.3s\n",
            "4549:\ttotal: 6m 26s\tremaining: 38.2s\n",
            "4550:\ttotal: 6m 26s\tremaining: 38.2s\n",
            "4551:\ttotal: 6m 26s\tremaining: 38.1s\n",
            "4552:\ttotal: 6m 26s\tremaining: 38s\n",
            "4553:\ttotal: 6m 27s\tremaining: 37.9s\n",
            "4554:\ttotal: 6m 27s\tremaining: 37.8s\n",
            "4555:\ttotal: 6m 27s\tremaining: 37.7s\n",
            "4556:\ttotal: 6m 27s\tremaining: 37.6s\n",
            "4557:\ttotal: 6m 27s\tremaining: 37.6s\n",
            "4558:\ttotal: 6m 27s\tremaining: 37.5s\n",
            "4559:\ttotal: 6m 27s\tremaining: 37.4s\n",
            "4560:\ttotal: 6m 27s\tremaining: 37.3s\n",
            "4561:\ttotal: 6m 27s\tremaining: 37.2s\n",
            "4562:\ttotal: 6m 27s\tremaining: 37.1s\n",
            "4563:\ttotal: 6m 27s\tremaining: 37.1s\n",
            "4564:\ttotal: 6m 27s\tremaining: 37s\n",
            "4565:\ttotal: 6m 28s\tremaining: 36.9s\n",
            "4566:\ttotal: 6m 28s\tremaining: 36.8s\n",
            "4567:\ttotal: 6m 28s\tremaining: 36.7s\n",
            "4568:\ttotal: 6m 28s\tremaining: 36.6s\n",
            "4569:\ttotal: 6m 28s\tremaining: 36.5s\n",
            "4570:\ttotal: 6m 28s\tremaining: 36.5s\n",
            "4571:\ttotal: 6m 28s\tremaining: 36.4s\n",
            "4572:\ttotal: 6m 28s\tremaining: 36.3s\n",
            "4573:\ttotal: 6m 28s\tremaining: 36.2s\n",
            "4574:\ttotal: 6m 28s\tremaining: 36.1s\n",
            "4575:\ttotal: 6m 28s\tremaining: 36s\n",
            "4576:\ttotal: 6m 28s\tremaining: 35.9s\n",
            "4577:\ttotal: 6m 29s\tremaining: 35.9s\n",
            "4578:\ttotal: 6m 29s\tremaining: 35.8s\n",
            "4579:\ttotal: 6m 29s\tremaining: 35.7s\n",
            "4580:\ttotal: 6m 29s\tremaining: 35.6s\n",
            "4581:\ttotal: 6m 29s\tremaining: 35.5s\n",
            "4582:\ttotal: 6m 29s\tremaining: 35.4s\n",
            "4583:\ttotal: 6m 29s\tremaining: 35.4s\n",
            "4584:\ttotal: 6m 29s\tremaining: 35.3s\n",
            "4585:\ttotal: 6m 29s\tremaining: 35.2s\n",
            "4586:\ttotal: 6m 29s\tremaining: 35.1s\n",
            "4587:\ttotal: 6m 29s\tremaining: 35s\n",
            "4588:\ttotal: 6m 30s\tremaining: 34.9s\n",
            "4589:\ttotal: 6m 30s\tremaining: 34.8s\n",
            "4590:\ttotal: 6m 30s\tremaining: 34.8s\n",
            "4591:\ttotal: 6m 30s\tremaining: 34.7s\n",
            "4592:\ttotal: 6m 30s\tremaining: 34.6s\n",
            "4593:\ttotal: 6m 30s\tremaining: 34.5s\n",
            "4594:\ttotal: 6m 30s\tremaining: 34.4s\n",
            "4595:\ttotal: 6m 30s\tremaining: 34.3s\n",
            "4596:\ttotal: 6m 30s\tremaining: 34.3s\n",
            "4597:\ttotal: 6m 30s\tremaining: 34.2s\n",
            "4598:\ttotal: 6m 30s\tremaining: 34.1s\n",
            "4599:\ttotal: 6m 30s\tremaining: 34s\n",
            "4600:\ttotal: 6m 31s\tremaining: 33.9s\n",
            "4601:\ttotal: 6m 31s\tremaining: 33.8s\n",
            "4602:\ttotal: 6m 31s\tremaining: 33.7s\n",
            "4603:\ttotal: 6m 31s\tremaining: 33.7s\n",
            "4604:\ttotal: 6m 31s\tremaining: 33.6s\n",
            "4605:\ttotal: 6m 31s\tremaining: 33.5s\n",
            "4606:\ttotal: 6m 31s\tremaining: 33.4s\n",
            "4607:\ttotal: 6m 31s\tremaining: 33.3s\n",
            "4608:\ttotal: 6m 31s\tremaining: 33.2s\n",
            "4609:\ttotal: 6m 31s\tremaining: 33.1s\n",
            "4610:\ttotal: 6m 31s\tremaining: 33.1s\n",
            "4611:\ttotal: 6m 32s\tremaining: 33s\n",
            "4612:\ttotal: 6m 32s\tremaining: 32.9s\n",
            "4613:\ttotal: 6m 32s\tremaining: 32.8s\n",
            "4614:\ttotal: 6m 32s\tremaining: 32.7s\n",
            "4615:\ttotal: 6m 32s\tremaining: 32.6s\n",
            "4616:\ttotal: 6m 32s\tremaining: 32.6s\n",
            "4617:\ttotal: 6m 32s\tremaining: 32.5s\n",
            "4618:\ttotal: 6m 32s\tremaining: 32.4s\n",
            "4619:\ttotal: 6m 32s\tremaining: 32.3s\n",
            "4620:\ttotal: 6m 32s\tremaining: 32.2s\n",
            "4621:\ttotal: 6m 32s\tremaining: 32.1s\n",
            "4622:\ttotal: 6m 32s\tremaining: 32s\n",
            "4623:\ttotal: 6m 33s\tremaining: 32s\n",
            "4624:\ttotal: 6m 33s\tremaining: 31.9s\n",
            "4625:\ttotal: 6m 33s\tremaining: 31.8s\n",
            "4626:\ttotal: 6m 33s\tremaining: 31.7s\n",
            "4627:\ttotal: 6m 33s\tremaining: 31.6s\n",
            "4628:\ttotal: 6m 33s\tremaining: 31.5s\n",
            "4629:\ttotal: 6m 33s\tremaining: 31.4s\n",
            "4630:\ttotal: 6m 33s\tremaining: 31.4s\n",
            "4631:\ttotal: 6m 33s\tremaining: 31.3s\n",
            "4632:\ttotal: 6m 33s\tremaining: 31.2s\n",
            "4633:\ttotal: 6m 33s\tremaining: 31.1s\n",
            "4634:\ttotal: 6m 33s\tremaining: 31s\n",
            "4635:\ttotal: 6m 34s\tremaining: 30.9s\n",
            "4636:\ttotal: 6m 34s\tremaining: 30.9s\n",
            "4637:\ttotal: 6m 34s\tremaining: 30.8s\n",
            "4638:\ttotal: 6m 34s\tremaining: 30.7s\n",
            "4639:\ttotal: 6m 34s\tremaining: 30.6s\n",
            "4640:\ttotal: 6m 34s\tremaining: 30.5s\n",
            "4641:\ttotal: 6m 34s\tremaining: 30.4s\n",
            "4642:\ttotal: 6m 34s\tremaining: 30.3s\n",
            "4643:\ttotal: 6m 34s\tremaining: 30.3s\n",
            "4644:\ttotal: 6m 34s\tremaining: 30.2s\n",
            "4645:\ttotal: 6m 34s\tremaining: 30.1s\n",
            "4646:\ttotal: 6m 35s\tremaining: 30s\n",
            "4647:\ttotal: 6m 35s\tremaining: 29.9s\n",
            "4648:\ttotal: 6m 35s\tremaining: 29.8s\n",
            "4649:\ttotal: 6m 35s\tremaining: 29.8s\n",
            "4650:\ttotal: 6m 35s\tremaining: 29.7s\n",
            "4651:\ttotal: 6m 35s\tremaining: 29.6s\n",
            "4652:\ttotal: 6m 35s\tremaining: 29.5s\n",
            "4653:\ttotal: 6m 35s\tremaining: 29.4s\n",
            "4654:\ttotal: 6m 35s\tremaining: 29.3s\n",
            "4655:\ttotal: 6m 35s\tremaining: 29.2s\n",
            "4656:\ttotal: 6m 35s\tremaining: 29.2s\n",
            "4657:\ttotal: 6m 35s\tremaining: 29.1s\n",
            "4658:\ttotal: 6m 36s\tremaining: 29s\n",
            "4659:\ttotal: 6m 36s\tremaining: 28.9s\n",
            "4660:\ttotal: 6m 36s\tremaining: 28.8s\n",
            "4661:\ttotal: 6m 36s\tremaining: 28.7s\n",
            "4662:\ttotal: 6m 36s\tremaining: 28.6s\n",
            "4663:\ttotal: 6m 36s\tremaining: 28.6s\n",
            "4664:\ttotal: 6m 36s\tremaining: 28.5s\n",
            "4665:\ttotal: 6m 36s\tremaining: 28.4s\n",
            "4666:\ttotal: 6m 36s\tremaining: 28.3s\n",
            "4667:\ttotal: 6m 36s\tremaining: 28.2s\n",
            "4668:\ttotal: 6m 36s\tremaining: 28.1s\n",
            "4669:\ttotal: 6m 36s\tremaining: 28.1s\n",
            "4670:\ttotal: 6m 37s\tremaining: 28s\n",
            "4671:\ttotal: 6m 37s\tremaining: 27.9s\n",
            "4672:\ttotal: 6m 37s\tremaining: 27.8s\n",
            "4673:\ttotal: 6m 37s\tremaining: 27.7s\n",
            "4674:\ttotal: 6m 37s\tremaining: 27.6s\n",
            "4675:\ttotal: 6m 37s\tremaining: 27.5s\n",
            "4676:\ttotal: 6m 37s\tremaining: 27.5s\n",
            "4677:\ttotal: 6m 37s\tremaining: 27.4s\n",
            "4678:\ttotal: 6m 37s\tremaining: 27.3s\n",
            "4679:\ttotal: 6m 37s\tremaining: 27.2s\n",
            "4680:\ttotal: 6m 37s\tremaining: 27.1s\n",
            "4681:\ttotal: 6m 38s\tremaining: 27s\n",
            "4682:\ttotal: 6m 38s\tremaining: 26.9s\n",
            "4683:\ttotal: 6m 38s\tremaining: 26.9s\n",
            "4684:\ttotal: 6m 38s\tremaining: 26.8s\n",
            "4685:\ttotal: 6m 38s\tremaining: 26.7s\n",
            "4686:\ttotal: 6m 38s\tremaining: 26.6s\n",
            "4687:\ttotal: 6m 38s\tremaining: 26.5s\n",
            "4688:\ttotal: 6m 38s\tremaining: 26.4s\n",
            "4689:\ttotal: 6m 38s\tremaining: 26.4s\n",
            "4690:\ttotal: 6m 38s\tremaining: 26.3s\n",
            "4691:\ttotal: 6m 38s\tremaining: 26.2s\n",
            "4692:\ttotal: 6m 38s\tremaining: 26.1s\n",
            "4693:\ttotal: 6m 39s\tremaining: 26s\n",
            "4694:\ttotal: 6m 39s\tremaining: 25.9s\n",
            "4695:\ttotal: 6m 39s\tremaining: 25.8s\n",
            "4696:\ttotal: 6m 39s\tremaining: 25.8s\n",
            "4697:\ttotal: 6m 39s\tremaining: 25.7s\n",
            "4698:\ttotal: 6m 39s\tremaining: 25.6s\n",
            "4699:\ttotal: 6m 39s\tremaining: 25.5s\n",
            "4700:\ttotal: 6m 39s\tremaining: 25.4s\n",
            "4701:\ttotal: 6m 39s\tremaining: 25.3s\n",
            "4702:\ttotal: 6m 39s\tremaining: 25.3s\n",
            "4703:\ttotal: 6m 39s\tremaining: 25.2s\n",
            "4704:\ttotal: 6m 40s\tremaining: 25.1s\n",
            "4705:\ttotal: 6m 40s\tremaining: 25s\n",
            "4706:\ttotal: 6m 40s\tremaining: 24.9s\n",
            "4707:\ttotal: 6m 40s\tremaining: 24.8s\n",
            "4708:\ttotal: 6m 40s\tremaining: 24.7s\n",
            "4709:\ttotal: 6m 40s\tremaining: 24.7s\n",
            "4710:\ttotal: 6m 40s\tremaining: 24.6s\n",
            "4711:\ttotal: 6m 40s\tremaining: 24.5s\n",
            "4712:\ttotal: 6m 40s\tremaining: 24.4s\n",
            "4713:\ttotal: 6m 40s\tremaining: 24.3s\n",
            "4714:\ttotal: 6m 40s\tremaining: 24.2s\n",
            "4715:\ttotal: 6m 40s\tremaining: 24.1s\n",
            "4716:\ttotal: 6m 41s\tremaining: 24.1s\n",
            "4717:\ttotal: 6m 41s\tremaining: 24s\n",
            "4718:\ttotal: 6m 41s\tremaining: 23.9s\n",
            "4719:\ttotal: 6m 41s\tremaining: 23.8s\n",
            "4720:\ttotal: 6m 41s\tremaining: 23.7s\n",
            "4721:\ttotal: 6m 41s\tremaining: 23.6s\n",
            "4722:\ttotal: 6m 41s\tremaining: 23.6s\n",
            "4723:\ttotal: 6m 41s\tremaining: 23.5s\n",
            "4724:\ttotal: 6m 41s\tremaining: 23.4s\n",
            "4725:\ttotal: 6m 41s\tremaining: 23.3s\n",
            "4726:\ttotal: 6m 41s\tremaining: 23.2s\n",
            "4727:\ttotal: 6m 41s\tremaining: 23.1s\n",
            "4728:\ttotal: 6m 42s\tremaining: 23s\n",
            "4729:\ttotal: 6m 42s\tremaining: 23s\n",
            "4730:\ttotal: 6m 42s\tremaining: 22.9s\n",
            "4731:\ttotal: 6m 42s\tremaining: 22.8s\n",
            "4732:\ttotal: 6m 42s\tremaining: 22.7s\n",
            "4733:\ttotal: 6m 42s\tremaining: 22.6s\n",
            "4734:\ttotal: 6m 42s\tremaining: 22.5s\n",
            "4735:\ttotal: 6m 42s\tremaining: 22.4s\n",
            "4736:\ttotal: 6m 42s\tremaining: 22.4s\n",
            "4737:\ttotal: 6m 42s\tremaining: 22.3s\n",
            "4738:\ttotal: 6m 42s\tremaining: 22.2s\n",
            "4739:\ttotal: 6m 43s\tremaining: 22.1s\n",
            "4740:\ttotal: 6m 43s\tremaining: 22s\n",
            "4741:\ttotal: 6m 43s\tremaining: 21.9s\n",
            "4742:\ttotal: 6m 43s\tremaining: 21.9s\n",
            "4743:\ttotal: 6m 43s\tremaining: 21.8s\n",
            "4744:\ttotal: 6m 43s\tremaining: 21.7s\n",
            "4745:\ttotal: 6m 43s\tremaining: 21.6s\n",
            "4746:\ttotal: 6m 43s\tremaining: 21.5s\n",
            "4747:\ttotal: 6m 43s\tremaining: 21.4s\n",
            "4748:\ttotal: 6m 43s\tremaining: 21.3s\n",
            "4749:\ttotal: 6m 43s\tremaining: 21.3s\n",
            "4750:\ttotal: 6m 43s\tremaining: 21.2s\n",
            "4751:\ttotal: 6m 44s\tremaining: 21.1s\n",
            "4752:\ttotal: 6m 44s\tremaining: 21s\n",
            "4753:\ttotal: 6m 44s\tremaining: 20.9s\n",
            "4754:\ttotal: 6m 44s\tremaining: 20.8s\n",
            "4755:\ttotal: 6m 44s\tremaining: 20.7s\n",
            "4756:\ttotal: 6m 44s\tremaining: 20.7s\n",
            "4757:\ttotal: 6m 44s\tremaining: 20.6s\n",
            "4758:\ttotal: 6m 44s\tremaining: 20.5s\n",
            "4759:\ttotal: 6m 44s\tremaining: 20.4s\n",
            "4760:\ttotal: 6m 44s\tremaining: 20.3s\n",
            "4761:\ttotal: 6m 44s\tremaining: 20.2s\n",
            "4762:\ttotal: 6m 45s\tremaining: 20.2s\n",
            "4763:\ttotal: 6m 45s\tremaining: 20.1s\n",
            "4764:\ttotal: 6m 45s\tremaining: 20s\n",
            "4765:\ttotal: 6m 45s\tremaining: 19.9s\n",
            "4766:\ttotal: 6m 45s\tremaining: 19.8s\n",
            "4767:\ttotal: 6m 45s\tremaining: 19.7s\n",
            "4768:\ttotal: 6m 45s\tremaining: 19.6s\n",
            "4769:\ttotal: 6m 45s\tremaining: 19.6s\n",
            "4770:\ttotal: 6m 45s\tremaining: 19.5s\n",
            "4771:\ttotal: 6m 45s\tremaining: 19.4s\n",
            "4772:\ttotal: 6m 45s\tremaining: 19.3s\n",
            "4773:\ttotal: 6m 45s\tremaining: 19.2s\n",
            "4774:\ttotal: 6m 46s\tremaining: 19.1s\n",
            "4775:\ttotal: 6m 46s\tremaining: 19s\n",
            "4776:\ttotal: 6m 46s\tremaining: 19s\n",
            "4777:\ttotal: 6m 46s\tremaining: 18.9s\n",
            "4778:\ttotal: 6m 46s\tremaining: 18.8s\n",
            "4779:\ttotal: 6m 46s\tremaining: 18.7s\n",
            "4780:\ttotal: 6m 46s\tremaining: 18.6s\n",
            "4781:\ttotal: 6m 46s\tremaining: 18.5s\n",
            "4782:\ttotal: 6m 46s\tremaining: 18.5s\n",
            "4783:\ttotal: 6m 46s\tremaining: 18.4s\n",
            "4784:\ttotal: 6m 46s\tremaining: 18.3s\n",
            "4785:\ttotal: 6m 46s\tremaining: 18.2s\n",
            "4786:\ttotal: 6m 47s\tremaining: 18.1s\n",
            "4787:\ttotal: 6m 47s\tremaining: 18s\n",
            "4788:\ttotal: 6m 47s\tremaining: 17.9s\n",
            "4789:\ttotal: 6m 47s\tremaining: 17.9s\n",
            "4790:\ttotal: 6m 47s\tremaining: 17.8s\n",
            "4791:\ttotal: 6m 47s\tremaining: 17.7s\n",
            "4792:\ttotal: 6m 47s\tremaining: 17.6s\n",
            "4793:\ttotal: 6m 47s\tremaining: 17.5s\n",
            "4794:\ttotal: 6m 47s\tremaining: 17.4s\n",
            "4795:\ttotal: 6m 47s\tremaining: 17.3s\n",
            "4796:\ttotal: 6m 47s\tremaining: 17.3s\n",
            "4797:\ttotal: 6m 48s\tremaining: 17.2s\n",
            "4798:\ttotal: 6m 48s\tremaining: 17.1s\n",
            "4799:\ttotal: 6m 48s\tremaining: 17s\n",
            "4800:\ttotal: 6m 48s\tremaining: 16.9s\n",
            "4801:\ttotal: 6m 48s\tremaining: 16.8s\n",
            "4802:\ttotal: 6m 48s\tremaining: 16.8s\n",
            "4803:\ttotal: 6m 48s\tremaining: 16.7s\n",
            "4804:\ttotal: 6m 48s\tremaining: 16.6s\n",
            "4805:\ttotal: 6m 48s\tremaining: 16.5s\n",
            "4806:\ttotal: 6m 48s\tremaining: 16.4s\n",
            "4807:\ttotal: 6m 48s\tremaining: 16.3s\n",
            "4808:\ttotal: 6m 48s\tremaining: 16.2s\n",
            "4809:\ttotal: 6m 49s\tremaining: 16.2s\n",
            "4810:\ttotal: 6m 49s\tremaining: 16.1s\n",
            "4811:\ttotal: 6m 49s\tremaining: 16s\n",
            "4812:\ttotal: 6m 49s\tremaining: 15.9s\n",
            "4813:\ttotal: 6m 49s\tremaining: 15.8s\n",
            "4814:\ttotal: 6m 49s\tremaining: 15.7s\n",
            "4815:\ttotal: 6m 49s\tremaining: 15.6s\n",
            "4816:\ttotal: 6m 49s\tremaining: 15.6s\n",
            "4817:\ttotal: 6m 49s\tremaining: 15.5s\n",
            "4818:\ttotal: 6m 49s\tremaining: 15.4s\n",
            "4819:\ttotal: 6m 49s\tremaining: 15.3s\n",
            "4820:\ttotal: 6m 49s\tremaining: 15.2s\n",
            "4821:\ttotal: 6m 50s\tremaining: 15.1s\n",
            "4822:\ttotal: 6m 50s\tremaining: 15.1s\n",
            "4823:\ttotal: 6m 50s\tremaining: 15s\n",
            "4824:\ttotal: 6m 50s\tremaining: 14.9s\n",
            "4825:\ttotal: 6m 50s\tremaining: 14.8s\n",
            "4826:\ttotal: 6m 50s\tremaining: 14.7s\n",
            "4827:\ttotal: 6m 50s\tremaining: 14.6s\n",
            "4828:\ttotal: 6m 50s\tremaining: 14.5s\n",
            "4829:\ttotal: 6m 50s\tremaining: 14.5s\n",
            "4830:\ttotal: 6m 50s\tremaining: 14.4s\n",
            "4831:\ttotal: 6m 50s\tremaining: 14.3s\n",
            "4832:\ttotal: 6m 50s\tremaining: 14.2s\n",
            "4833:\ttotal: 6m 51s\tremaining: 14.1s\n",
            "4834:\ttotal: 6m 51s\tremaining: 14s\n",
            "4835:\ttotal: 6m 51s\tremaining: 13.9s\n",
            "4836:\ttotal: 6m 51s\tremaining: 13.9s\n",
            "4837:\ttotal: 6m 51s\tremaining: 13.8s\n",
            "4838:\ttotal: 6m 51s\tremaining: 13.7s\n",
            "4839:\ttotal: 6m 51s\tremaining: 13.6s\n",
            "4840:\ttotal: 6m 51s\tremaining: 13.5s\n",
            "4841:\ttotal: 6m 51s\tremaining: 13.4s\n",
            "4842:\ttotal: 6m 51s\tremaining: 13.4s\n",
            "4843:\ttotal: 6m 51s\tremaining: 13.3s\n",
            "4844:\ttotal: 6m 52s\tremaining: 13.2s\n",
            "4845:\ttotal: 6m 52s\tremaining: 13.1s\n",
            "4846:\ttotal: 6m 52s\tremaining: 13s\n",
            "4847:\ttotal: 6m 52s\tremaining: 12.9s\n",
            "4848:\ttotal: 6m 52s\tremaining: 12.8s\n",
            "4849:\ttotal: 6m 52s\tremaining: 12.8s\n",
            "4850:\ttotal: 6m 52s\tremaining: 12.7s\n",
            "4851:\ttotal: 6m 52s\tremaining: 12.6s\n",
            "4852:\ttotal: 6m 52s\tremaining: 12.5s\n",
            "4853:\ttotal: 6m 52s\tremaining: 12.4s\n",
            "4854:\ttotal: 6m 52s\tremaining: 12.3s\n",
            "4855:\ttotal: 6m 52s\tremaining: 12.2s\n",
            "4856:\ttotal: 6m 53s\tremaining: 12.2s\n",
            "4857:\ttotal: 6m 53s\tremaining: 12.1s\n",
            "4858:\ttotal: 6m 53s\tremaining: 12s\n",
            "4859:\ttotal: 6m 53s\tremaining: 11.9s\n",
            "4860:\ttotal: 6m 53s\tremaining: 11.8s\n",
            "4861:\ttotal: 6m 53s\tremaining: 11.7s\n",
            "4862:\ttotal: 6m 53s\tremaining: 11.7s\n",
            "4863:\ttotal: 6m 53s\tremaining: 11.6s\n",
            "4864:\ttotal: 6m 53s\tremaining: 11.5s\n",
            "4865:\ttotal: 6m 53s\tremaining: 11.4s\n",
            "4866:\ttotal: 6m 53s\tremaining: 11.3s\n",
            "4867:\ttotal: 6m 54s\tremaining: 11.2s\n",
            "4868:\ttotal: 6m 54s\tremaining: 11.1s\n",
            "4869:\ttotal: 6m 54s\tremaining: 11.1s\n",
            "4870:\ttotal: 6m 54s\tremaining: 11s\n",
            "4871:\ttotal: 6m 54s\tremaining: 10.9s\n",
            "4872:\ttotal: 6m 54s\tremaining: 10.8s\n",
            "4873:\ttotal: 6m 54s\tremaining: 10.7s\n",
            "4874:\ttotal: 6m 54s\tremaining: 10.6s\n",
            "4875:\ttotal: 6m 54s\tremaining: 10.5s\n",
            "4876:\ttotal: 6m 54s\tremaining: 10.5s\n",
            "4877:\ttotal: 6m 54s\tremaining: 10.4s\n",
            "4878:\ttotal: 6m 54s\tremaining: 10.3s\n",
            "4879:\ttotal: 6m 55s\tremaining: 10.2s\n",
            "4880:\ttotal: 6m 55s\tremaining: 10.1s\n",
            "4881:\ttotal: 6m 55s\tremaining: 10s\n",
            "4882:\ttotal: 6m 55s\tremaining: 9.95s\n",
            "4883:\ttotal: 6m 55s\tremaining: 9.87s\n",
            "4884:\ttotal: 6m 55s\tremaining: 9.78s\n",
            "4885:\ttotal: 6m 55s\tremaining: 9.7s\n",
            "4886:\ttotal: 6m 55s\tremaining: 9.61s\n",
            "4887:\ttotal: 6m 55s\tremaining: 9.53s\n",
            "4888:\ttotal: 6m 55s\tremaining: 9.44s\n",
            "4889:\ttotal: 6m 55s\tremaining: 9.36s\n",
            "4890:\ttotal: 6m 55s\tremaining: 9.27s\n",
            "4891:\ttotal: 6m 56s\tremaining: 9.19s\n",
            "4892:\ttotal: 6m 56s\tremaining: 9.1s\n",
            "4893:\ttotal: 6m 56s\tremaining: 9.02s\n",
            "4894:\ttotal: 6m 56s\tremaining: 8.93s\n",
            "4895:\ttotal: 6m 56s\tremaining: 8.85s\n",
            "4896:\ttotal: 6m 56s\tremaining: 8.76s\n",
            "4897:\ttotal: 6m 56s\tremaining: 8.68s\n",
            "4898:\ttotal: 6m 56s\tremaining: 8.59s\n",
            "4899:\ttotal: 6m 56s\tremaining: 8.51s\n",
            "4900:\ttotal: 6m 56s\tremaining: 8.42s\n",
            "4901:\ttotal: 6m 56s\tremaining: 8.34s\n",
            "4902:\ttotal: 6m 57s\tremaining: 8.25s\n",
            "4903:\ttotal: 6m 57s\tremaining: 8.16s\n",
            "4904:\ttotal: 6m 57s\tremaining: 8.08s\n",
            "4905:\ttotal: 6m 57s\tremaining: 7.99s\n",
            "4906:\ttotal: 6m 57s\tremaining: 7.91s\n",
            "4907:\ttotal: 6m 57s\tremaining: 7.82s\n",
            "4908:\ttotal: 6m 57s\tremaining: 7.74s\n",
            "4909:\ttotal: 6m 57s\tremaining: 7.65s\n",
            "4910:\ttotal: 6m 57s\tremaining: 7.57s\n",
            "4911:\ttotal: 6m 57s\tremaining: 7.48s\n",
            "4912:\ttotal: 6m 57s\tremaining: 7.4s\n",
            "4913:\ttotal: 6m 57s\tremaining: 7.31s\n",
            "4914:\ttotal: 6m 58s\tremaining: 7.23s\n",
            "4915:\ttotal: 6m 58s\tremaining: 7.14s\n",
            "4916:\ttotal: 6m 58s\tremaining: 7.06s\n",
            "4917:\ttotal: 6m 58s\tremaining: 6.97s\n",
            "4918:\ttotal: 6m 58s\tremaining: 6.89s\n",
            "4919:\ttotal: 6m 58s\tremaining: 6.8s\n",
            "4920:\ttotal: 6m 58s\tremaining: 6.72s\n",
            "4921:\ttotal: 6m 58s\tremaining: 6.63s\n",
            "4922:\ttotal: 6m 58s\tremaining: 6.55s\n",
            "4923:\ttotal: 6m 58s\tremaining: 6.46s\n",
            "4924:\ttotal: 6m 58s\tremaining: 6.38s\n",
            "4925:\ttotal: 6m 58s\tremaining: 6.29s\n",
            "4926:\ttotal: 6m 59s\tremaining: 6.21s\n",
            "4927:\ttotal: 6m 59s\tremaining: 6.12s\n",
            "4928:\ttotal: 6m 59s\tremaining: 6.04s\n",
            "4929:\ttotal: 6m 59s\tremaining: 5.95s\n",
            "4930:\ttotal: 6m 59s\tremaining: 5.87s\n",
            "4931:\ttotal: 6m 59s\tremaining: 5.78s\n",
            "4932:\ttotal: 6m 59s\tremaining: 5.7s\n",
            "4933:\ttotal: 6m 59s\tremaining: 5.61s\n",
            "4934:\ttotal: 6m 59s\tremaining: 5.53s\n",
            "4935:\ttotal: 6m 59s\tremaining: 5.44s\n",
            "4936:\ttotal: 6m 59s\tremaining: 5.36s\n",
            "4937:\ttotal: 7m\tremaining: 5.27s\n",
            "4938:\ttotal: 7m\tremaining: 5.19s\n",
            "4939:\ttotal: 7m\tremaining: 5.1s\n",
            "4940:\ttotal: 7m\tremaining: 5.02s\n",
            "4941:\ttotal: 7m\tremaining: 4.93s\n",
            "4942:\ttotal: 7m\tremaining: 4.85s\n",
            "4943:\ttotal: 7m\tremaining: 4.76s\n",
            "4944:\ttotal: 7m\tremaining: 4.68s\n",
            "4945:\ttotal: 7m\tremaining: 4.59s\n",
            "4946:\ttotal: 7m\tremaining: 4.51s\n",
            "4947:\ttotal: 7m\tremaining: 4.42s\n",
            "4948:\ttotal: 7m\tremaining: 4.34s\n",
            "4949:\ttotal: 7m 1s\tremaining: 4.25s\n",
            "4950:\ttotal: 7m 1s\tremaining: 4.17s\n",
            "4951:\ttotal: 7m 1s\tremaining: 4.08s\n",
            "4952:\ttotal: 7m 1s\tremaining: 4s\n",
            "4953:\ttotal: 7m 1s\tremaining: 3.91s\n",
            "4954:\ttotal: 7m 1s\tremaining: 3.83s\n",
            "4955:\ttotal: 7m 1s\tremaining: 3.74s\n",
            "4956:\ttotal: 7m 1s\tremaining: 3.66s\n",
            "4957:\ttotal: 7m 1s\tremaining: 3.57s\n",
            "4958:\ttotal: 7m 1s\tremaining: 3.49s\n",
            "4959:\ttotal: 7m 1s\tremaining: 3.4s\n",
            "4960:\ttotal: 7m 2s\tremaining: 3.32s\n",
            "4961:\ttotal: 7m 2s\tremaining: 3.23s\n",
            "4962:\ttotal: 7m 2s\tremaining: 3.15s\n",
            "4963:\ttotal: 7m 2s\tremaining: 3.06s\n",
            "4964:\ttotal: 7m 2s\tremaining: 2.98s\n",
            "4965:\ttotal: 7m 2s\tremaining: 2.89s\n",
            "4966:\ttotal: 7m 2s\tremaining: 2.81s\n",
            "4967:\ttotal: 7m 2s\tremaining: 2.72s\n",
            "4968:\ttotal: 7m 2s\tremaining: 2.64s\n",
            "4969:\ttotal: 7m 2s\tremaining: 2.55s\n",
            "4970:\ttotal: 7m 2s\tremaining: 2.47s\n",
            "4971:\ttotal: 7m 2s\tremaining: 2.38s\n",
            "4972:\ttotal: 7m 3s\tremaining: 2.3s\n",
            "4973:\ttotal: 7m 3s\tremaining: 2.21s\n",
            "4974:\ttotal: 7m 3s\tremaining: 2.13s\n",
            "4975:\ttotal: 7m 3s\tremaining: 2.04s\n",
            "4976:\ttotal: 7m 3s\tremaining: 1.96s\n",
            "4977:\ttotal: 7m 3s\tremaining: 1.87s\n",
            "4978:\ttotal: 7m 3s\tremaining: 1.79s\n",
            "4979:\ttotal: 7m 3s\tremaining: 1.7s\n",
            "4980:\ttotal: 7m 3s\tremaining: 1.62s\n",
            "4981:\ttotal: 7m 3s\tremaining: 1.53s\n",
            "4982:\ttotal: 7m 3s\tremaining: 1.45s\n",
            "4983:\ttotal: 7m 4s\tremaining: 1.36s\n",
            "4984:\ttotal: 7m 4s\tremaining: 1.28s\n",
            "4985:\ttotal: 7m 4s\tremaining: 1.19s\n",
            "4986:\ttotal: 7m 4s\tremaining: 1.11s\n",
            "4987:\ttotal: 7m 4s\tremaining: 1.02s\n",
            "4988:\ttotal: 7m 4s\tremaining: 936ms\n",
            "4989:\ttotal: 7m 4s\tremaining: 851ms\n",
            "4990:\ttotal: 7m 4s\tremaining: 766ms\n",
            "4991:\ttotal: 7m 4s\tremaining: 681ms\n",
            "4992:\ttotal: 7m 4s\tremaining: 596ms\n",
            "4993:\ttotal: 7m 4s\tremaining: 510ms\n",
            "4994:\ttotal: 7m 4s\tremaining: 425ms\n",
            "4995:\ttotal: 7m 5s\tremaining: 340ms\n",
            "4996:\ttotal: 7m 5s\tremaining: 255ms\n",
            "4997:\ttotal: 7m 5s\tremaining: 170ms\n",
            "4998:\ttotal: 7m 5s\tremaining: 85.1ms\n",
            "4999:\ttotal: 7m 5s\tremaining: 0us\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B91GRbkzUD8i"
      },
      "source": [
        "# 세 모델에서 얻은 예측값들에 적당한 가중치를 주어 앙상블 합니다.\n",
        "ensemble_preds = (CatBoost_final_pred * 0.55) + (XGBC_final_pred * 0.37) + (LGBM_final_pred * 0.08)\n",
        "\n",
        "#앙상블 한 예측값을 저장합니다.\n",
        "sample_submission['voted']= ensemble_preds\n",
        "sample_submission['voted'] = sample_submission['voted'].astype('int') #결과가 실수 형태로 나오는 것이 있어 int형으로 바꿔줍니다.\n",
        "sample_submission.to_csv('test_submit_CAT+XGB+LGBM.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz3JeKxm0qf0"
      },
      "source": [
        "### **4. Auto ML 모델**\n",
        "\n",
        "public(0.6220532941) 657등 (0.7대가 나오지 않아서 아쉽다 ㅠ)\n",
        "\n",
        "private(0.6227340114)\n",
        "\n",
        "참고 : [코드 공유](https://dacon.io/competitions/official/235647/codeshare/1720?page=3&dtype=recent)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skdsNC1JmG46"
      },
      "source": [
        "**Auto ML** 분야는 여러 종류가 있는데요. \n",
        "\n",
        "그 중 Hyperparameter Optimization 분야에서 **Bayesian Optimization**(베이지안 최적화, 베이즈 최적화)를 사용한 코드가 있어 참고해 봤습니다.\n",
        "\n",
        "Bayesian Optimization는 하이퍼 파라미터 튜닝에서 기존의 grid search, random search를 대체하는데 사용 가능합니다.\n",
        "\n",
        "즉, 기본 모델로는 LGBM을 사용하고 그 최적의 하이퍼파라미터 값을 **Bayesian Optimization** 방법으로 찾아내는 모델입니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsTmMwwHra8h",
        "outputId": "131289dc-ff96-4a1a-c91e-59979ebb94a0"
      },
      "source": [
        "#BayesianOptimization를 import 하기위해 필요한 설치 과정\n",
        "pip install bayesian-optimization "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bayesian-optimization\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from bayesian-optimization) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.0.1)\n",
            "Building wheels for collected packages: bayesian-optimization\n",
            "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11687 sha256=ad9b7e79c05ca5a0bce82fa92354cd4d79ea0144c60395b821972e459b11f18f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
            "Successfully built bayesian-optimization\n",
            "Installing collected packages: bayesian-optimization\n",
            "Successfully installed bayesian-optimization-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrvkWvORrB2v"
      },
      "source": [
        "import lightgbm as lgbm\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.metrics import roc_auc_score, make_scorer\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8w2DbNrIq9"
      },
      "source": [
        "# 목적 함수 생성\n",
        "# 목적 함수란 사용할 LGBMClassifier 모델의 성능 함수로 모델의 파라미터 조합을 입력값으로 가집니다. 성능평가는 auc이므로 score값을 return 해 줍니다.\n",
        "# 최적의 값을 탐색하고자 하는 파리미터를 함수에 입력해줍니다.\n",
        "\n",
        "def lgbm_cv(learning_rate, num_leaves, max_depth, min_child_weight, colsample_bytree, feature_fraction, bagging_fraction, lambda_l1, lambda_l2):\n",
        "    model = lgbm.LGBMClassifier(learning_rate=learning_rate,\n",
        "                                n_estimators = 300,\n",
        "                                num_leaves = int(round(num_leaves)),\n",
        "                                max_depth = int(round(max_depth)),\n",
        "                                min_child_weight = int(round(min_child_weight)),\n",
        "                                colsample_bytree = colsample_bytree,\n",
        "                                feature_fraction = max(min(feature_fraction, 1), 0),\n",
        "                                bagging_fraction = max(min(bagging_fraction, 1), 0),\n",
        "                                lambda_l1 = max(lambda_l1, 0),\n",
        "                                lambda_l2 = max(lambda_l2, 0)\n",
        "                               )\n",
        "    scoring = {'roc_auc_score': make_scorer(roc_auc_score)}\n",
        "    result = cross_validate(model, final_train_x, final_train_y, cv=5, scoring=scoring)\n",
        "    auc_score = result[\"test_roc_auc_score\"].mean()\n",
        "    return auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAX6DJJErf_F"
      },
      "source": [
        "# 파라미터의 탐색 대상 구간을 설정 합니다.\n",
        "pbounds = {'learning_rate' : (0.0001, 0.05),    # learning_rate : 보통 0.01~ 정도로 설정합니다. 세부 조정을 위해서는 0.0001~정도로 설정해도 무방합니다.\n",
        "           'num_leaves': (300, 600),            # num_leaves : 250정도로 설정해도 무방합니다. 300~600 정도로 설정했습니다.\n",
        "           'max_depth': (2, 25),                # max_depth : -1 로 설정하면 무한대로 트리가 길어집니다. 9~ 정도로 설정하는게 무방하나 조금 더 넓은 범위로 설정했습니다.\n",
        "           'min_child_weight': (30, 100),        \n",
        "           'colsample_bytree': (0, 0.99),\n",
        "           'feature_fraction': (0.0001, 0.99),  # feature_fraction, bagging_fraction : 0과 1 사이의 범위로 설정했습니다.\n",
        "           'bagging_fraction': (0.0001, 0.99),\n",
        "           'lambda_l1' : (0, 0.99),\n",
        "           'lambda_l2' : (0, 0.99),\n",
        "          }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JRd4cJqrh2l"
      },
      "source": [
        "#객체 생성\n",
        "lgbmBO = BayesianOptimization(f = lgbm_cv, pbounds = pbounds, verbose = 2, random_state = 0 ) #f는 목적 함수, pbounds는 입력값의 탐색 구간"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCJQAPKPrjuA",
        "outputId": "04afe7e0-78a7-41c1-dbf2-db39459f441f"
      },
      "source": [
        "# 반복적으로 베이지안 최적화 수행\n",
        "lgbmBO.maximize(init_points=5, n_iter = 20, acq='ei', xi=0.01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | baggin... | colsam... | featur... | lambda_l1 | lambda_l2 | learni... | max_depth | min_ch... | num_le... |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6853  \u001b[0m | \u001b[0m 0.5434  \u001b[0m | \u001b[0m 0.708   \u001b[0m | \u001b[0m 0.5968  \u001b[0m | \u001b[0m 0.5394  \u001b[0m | \u001b[0m 0.4194  \u001b[0m | \u001b[0m 0.03233 \u001b[0m | \u001b[0m 12.06   \u001b[0m | \u001b[0m 92.42   \u001b[0m | \u001b[0m 589.1   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6843  \u001b[0m | \u001b[0m 0.3797  \u001b[0m | \u001b[0m 0.7838  \u001b[0m | \u001b[0m 0.5237  \u001b[0m | \u001b[0m 0.5624  \u001b[0m | \u001b[0m 0.9163  \u001b[0m | \u001b[0m 0.003645\u001b[0m | \u001b[0m 4.004   \u001b[0m | \u001b[0m 31.42   \u001b[0m | \u001b[0m 549.8   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6805  \u001b[0m | \u001b[0m 0.7704  \u001b[0m | \u001b[0m 0.8613  \u001b[0m | \u001b[0m 0.9688  \u001b[0m | \u001b[0m 0.7912  \u001b[0m | \u001b[0m 0.4569  \u001b[0m | \u001b[0m 0.03905 \u001b[0m | \u001b[0m 4.72    \u001b[0m | \u001b[0m 74.79   \u001b[0m | \u001b[0m 343.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.658   \u001b[0m | \u001b[0m 0.9352  \u001b[0m | \u001b[0m 0.5166  \u001b[0m | \u001b[0m 0.4106  \u001b[0m | \u001b[0m 0.2619  \u001b[0m | \u001b[0m 0.7665  \u001b[0m | \u001b[0m 0.02286 \u001b[0m | \u001b[0m 15.07   \u001b[0m | \u001b[0m 31.32   \u001b[0m | \u001b[0m 485.3   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6583  \u001b[0m | \u001b[0m 0.606   \u001b[0m | \u001b[0m 0.6108  \u001b[0m | \u001b[0m 0.9343  \u001b[0m | \u001b[0m 0.675   \u001b[0m | \u001b[0m 0.3559  \u001b[0m | \u001b[0m 0.02191 \u001b[0m | \u001b[0m 18.05   \u001b[0m | \u001b[0m 34.22   \u001b[0m | \u001b[0m 500.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.6897  \u001b[0m | \u001b[95m 0.7264  \u001b[0m | \u001b[95m 0.8566  \u001b[0m | \u001b[95m 0.6001  \u001b[0m | \u001b[95m 0.9791  \u001b[0m | \u001b[95m 0.7416  \u001b[0m | \u001b[95m 0.01211 \u001b[0m | \u001b[95m 2.361   \u001b[0m | \u001b[95m 34.99   \u001b[0m | \u001b[95m 599.3   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.6916  \u001b[0m | \u001b[95m 0.2944  \u001b[0m | \u001b[95m 0.6667  \u001b[0m | \u001b[95m 0.7443  \u001b[0m | \u001b[95m 0.7415  \u001b[0m | \u001b[95m 0.09578 \u001b[0m | \u001b[95m 0.02954 \u001b[0m | \u001b[95m 2.1     \u001b[0m | \u001b[95m 99.88   \u001b[0m | \u001b[95m 547.4   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.6936  \u001b[0m | \u001b[95m 0.473   \u001b[0m | \u001b[95m 0.6159  \u001b[0m | \u001b[95m 0.8182  \u001b[0m | \u001b[95m 0.7594  \u001b[0m | \u001b[95m 0.69    \u001b[0m | \u001b[95m 0.01599 \u001b[0m | \u001b[95m 3.185   \u001b[0m | \u001b[95m 98.04   \u001b[0m | \u001b[95m 301.8   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.692   \u001b[0m | \u001b[0m 0.5624  \u001b[0m | \u001b[0m 0.5421  \u001b[0m | \u001b[0m 0.9327  \u001b[0m | \u001b[0m 0.9215  \u001b[0m | \u001b[0m 0.3094  \u001b[0m | \u001b[0m 0.009335\u001b[0m | \u001b[0m 2.494   \u001b[0m | \u001b[0m 32.29   \u001b[0m | \u001b[0m 304.2   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6916  \u001b[0m | \u001b[0m 0.8211  \u001b[0m | \u001b[0m 0.9149  \u001b[0m | \u001b[0m 0.7145  \u001b[0m | \u001b[0m 0.9037  \u001b[0m | \u001b[0m 0.7523  \u001b[0m | \u001b[0m 0.03013 \u001b[0m | \u001b[0m 2.171   \u001b[0m | \u001b[0m 99.49   \u001b[0m | \u001b[0m 596.9   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6793  \u001b[0m | \u001b[0m 0.3868  \u001b[0m | \u001b[0m 0.6453  \u001b[0m | \u001b[0m 0.1738  \u001b[0m | \u001b[0m 0.586   \u001b[0m | \u001b[0m 0.435   \u001b[0m | \u001b[0m 0.04782 \u001b[0m | \u001b[0m 24.97   \u001b[0m | \u001b[0m 75.26   \u001b[0m | \u001b[0m 301.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.69    \u001b[0m | \u001b[0m 0.1633  \u001b[0m | \u001b[0m 0.4893  \u001b[0m | \u001b[0m 0.2818  \u001b[0m | \u001b[0m 0.6839  \u001b[0m | \u001b[0m 0.1083  \u001b[0m | \u001b[0m 0.0107  \u001b[0m | \u001b[0m 10.17   \u001b[0m | \u001b[0m 98.01   \u001b[0m | \u001b[0m 305.9   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.644   \u001b[0m | \u001b[0m 0.7841  \u001b[0m | \u001b[0m 0.533   \u001b[0m | \u001b[0m 0.01418 \u001b[0m | \u001b[0m 0.895   \u001b[0m | \u001b[0m 0.4813  \u001b[0m | \u001b[0m 0.04629 \u001b[0m | \u001b[0m 2.361   \u001b[0m | \u001b[0m 74.08   \u001b[0m | \u001b[0m 300.2   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.6604  \u001b[0m | \u001b[0m 0.8183  \u001b[0m | \u001b[0m 0.7035  \u001b[0m | \u001b[0m 0.8282  \u001b[0m | \u001b[0m 0.9124  \u001b[0m | \u001b[0m 0.1033  \u001b[0m | \u001b[0m 0.0131  \u001b[0m | \u001b[0m 23.84   \u001b[0m | \u001b[0m 30.22   \u001b[0m | \u001b[0m 345.5   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.6126  \u001b[0m | \u001b[0m 0.3521  \u001b[0m | \u001b[0m 0.9137  \u001b[0m | \u001b[0m 0.2123  \u001b[0m | \u001b[0m 0.3576  \u001b[0m | \u001b[0m 0.6584  \u001b[0m | \u001b[0m 0.002172\u001b[0m | \u001b[0m 6.186   \u001b[0m | \u001b[0m 99.45   \u001b[0m | \u001b[0m 302.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.6904  \u001b[0m | \u001b[0m 0.2638  \u001b[0m | \u001b[0m 0.5232  \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 0.1616  \u001b[0m | \u001b[0m 0.4035  \u001b[0m | \u001b[0m 0.02906 \u001b[0m | \u001b[0m 2.436   \u001b[0m | \u001b[0m 97.45   \u001b[0m | \u001b[0m 324.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6821  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 454.3   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.6607  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 413.8   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 493.3   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6809  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 80.9    \u001b[0m | \u001b[0m 323.2   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 410.3   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6704  \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 65.16   \u001b[0m | \u001b[0m 420.9   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6607  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 30.0    \u001b[0m | \u001b[0m 364.0   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6882  \u001b[0m | \u001b[0m 0.0001  \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 88.66   \u001b[0m | \u001b[0m 311.7   \u001b[0m |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.6821  \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.99    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 368.2   \u001b[0m |\n",
            "=====================================================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAlsIZ-Zr06T",
        "outputId": "2af86e09-d902-49cb-8fcb-41e123ee31f6"
      },
      "source": [
        "# 찾은 파라미터 값 확인\n",
        "lgbmBO.max"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'params': {'bagging_fraction': 0.4729589655278779,\n",
              "  'colsample_bytree': 0.6158738007642527,\n",
              "  'feature_fraction': 0.8182268598478806,\n",
              "  'lambda_l1': 0.7594444092904203,\n",
              "  'lambda_l2': 0.6899513386599342,\n",
              "  'learning_rate': 0.015987379446646303,\n",
              "  'max_depth': 3.1851686676923165,\n",
              "  'min_child_weight': 98.03887622366321,\n",
              "  'num_leaves': 301.8072068585756},\n",
              " 'target': 0.6935909482114496}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqLxYXJer2R9"
      },
      "source": [
        "#최적의 파라미터 적용\n",
        "fit_lgbm = lgbm.LGBMClassifier(learning_rate=lgbmBO.max['params']['learning_rate'],\n",
        "                               num_leaves = int(round(lgbmBO.max['params']['num_leaves'])),\n",
        "                               max_depth = int(round(lgbmBO.max['params']['max_depth'])),\n",
        "                               min_child_weight = int(round(lgbmBO.max['params']['min_child_weight'])),\n",
        "                               colsample_bytree=lgbmBO.max['params']['colsample_bytree'],\n",
        "                               feature_fraction = max(min(lgbmBO.max['params']['feature_fraction'], 1), 0),\n",
        "                               bagging_fraction = max(min(lgbmBO.max['params']['bagging_fraction'], 1), 0),\n",
        "                               lambda_l1 = lgbmBO.max['params']['lambda_l1'],\n",
        "                               lambda_l2 = lgbmBO.max['params']['lambda_l2']\n",
        "                               )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FT1vC32r8ho",
        "outputId": "c6c0a1bd-b81e-40aa-93d4-3da0e81f6b86"
      },
      "source": [
        "# 이제 똑같이 모델 학습 및 예측을 진행 해 줍니다!\n",
        "model = fit_lgbm.fit(final_train_x,final_train_y)\n",
        "final_pred = model.predict(final_test)\n",
        "sample_submission['voted']=final_pred\n",
        "sample_submission.to_csv('test_submit_AUTO_ML.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}